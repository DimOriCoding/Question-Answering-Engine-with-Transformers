{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02a85c3ee502499e91d41d18f159df37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d82205dc3d64bc191e57490a5fcbe1a",
              "IPY_MODEL_ecdf9a7dfb8349bca6c34a6f923a9bc6",
              "IPY_MODEL_ed0d954efc96468092fc19e0db72ae67"
            ],
            "layout": "IPY_MODEL_e076269eeb6f412dba021cf05f3df594"
          }
        },
        "1d82205dc3d64bc191e57490a5fcbe1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cf3fa2c88914cab926127d0c343c1b3",
            "placeholder": "​",
            "style": "IPY_MODEL_1c202de9b7c64a6c89075222a5d2a182",
            "value": "modules.json: 100%"
          }
        },
        "ecdf9a7dfb8349bca6c34a6f923a9bc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b0b989c63414b8c91e086207e7b8ad0",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da20e22985914cd7bce5c794235d8eb2",
            "value": 349
          }
        },
        "ed0d954efc96468092fc19e0db72ae67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_497dee4f1f2c413fb8dae03590364db1",
            "placeholder": "​",
            "style": "IPY_MODEL_e0c1d44401e2473caeb975908af17323",
            "value": " 349/349 [00:00&lt;00:00, 16.7kB/s]"
          }
        },
        "e076269eeb6f412dba021cf05f3df594": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf3fa2c88914cab926127d0c343c1b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c202de9b7c64a6c89075222a5d2a182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b0b989c63414b8c91e086207e7b8ad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da20e22985914cd7bce5c794235d8eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "497dee4f1f2c413fb8dae03590364db1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c1d44401e2473caeb975908af17323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4ac190bf7444f9f90a1384e27c15f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_89407f02f9f74c7f89b6c2a3d0a0144e",
              "IPY_MODEL_59a6cca8f41c49dab744003f8f52ef7e",
              "IPY_MODEL_d9847f205268469b94f5c7bda52c0fd8"
            ],
            "layout": "IPY_MODEL_453a3c3c4666408e95b9116208e46f61"
          }
        },
        "89407f02f9f74c7f89b6c2a3d0a0144e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cecce0a81f340a3bdc613392376b60b",
            "placeholder": "​",
            "style": "IPY_MODEL_3c45e902f3fa47be852de9e5a696b90b",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "59a6cca8f41c49dab744003f8f52ef7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fc3be6348eb47ac82788608d1a6f6fb",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbe999c46b7f4a96a7fb7f314d3cd981",
            "value": 116
          }
        },
        "d9847f205268469b94f5c7bda52c0fd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4da38e8ed64b15a3b46764343612df",
            "placeholder": "​",
            "style": "IPY_MODEL_9e5054dfdb044f739bbdd90aa9bfc5a3",
            "value": " 116/116 [00:00&lt;00:00, 7.86kB/s]"
          }
        },
        "453a3c3c4666408e95b9116208e46f61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cecce0a81f340a3bdc613392376b60b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c45e902f3fa47be852de9e5a696b90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fc3be6348eb47ac82788608d1a6f6fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe999c46b7f4a96a7fb7f314d3cd981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c4da38e8ed64b15a3b46764343612df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e5054dfdb044f739bbdd90aa9bfc5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9315e7054c34464875043a60e8125bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1b96a5037c54d02b80471ecfedc5420",
              "IPY_MODEL_2614d096a1ce4b4497cd5ad93971b5c4",
              "IPY_MODEL_d6ecfa33fd9e42359e6ad86597bc2bd7"
            ],
            "layout": "IPY_MODEL_cf6f49764442498084ae3915daed6a13"
          }
        },
        "b1b96a5037c54d02b80471ecfedc5420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_821fe2a06e0a412788af33ede62a15b8",
            "placeholder": "​",
            "style": "IPY_MODEL_07e18fd3ccc040f892dadbcd3ba30165",
            "value": "README.md: 100%"
          }
        },
        "2614d096a1ce4b4497cd5ad93971b5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e1f13dabf484bc4841c9c8092f595dd",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ac4cc7354074e17aa92e6f825ed758d",
            "value": 10659
          }
        },
        "d6ecfa33fd9e42359e6ad86597bc2bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a67ad07d38f4ec8a27ef09b063b0c7d",
            "placeholder": "​",
            "style": "IPY_MODEL_8f4ac9b6edd14032a59fc7f8056eeed3",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 580kB/s]"
          }
        },
        "cf6f49764442498084ae3915daed6a13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "821fe2a06e0a412788af33ede62a15b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07e18fd3ccc040f892dadbcd3ba30165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e1f13dabf484bc4841c9c8092f595dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ac4cc7354074e17aa92e6f825ed758d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a67ad07d38f4ec8a27ef09b063b0c7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f4ac9b6edd14032a59fc7f8056eeed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77f2a3822fdd4a6ea115eb7929a857de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e5afdad084f6488aa5cdb691c208dab1",
              "IPY_MODEL_e5772b9ef92946989b759571ab19cb72",
              "IPY_MODEL_6dc792df2d8243349a91b464215495e0"
            ],
            "layout": "IPY_MODEL_d4b9115ed3c04ffcac67173cc188b08b"
          }
        },
        "e5afdad084f6488aa5cdb691c208dab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bc9b11a5b3c4325b240bdfd952383f5",
            "placeholder": "​",
            "style": "IPY_MODEL_35ab160fe48f44029e4c6367a901e8bf",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "e5772b9ef92946989b759571ab19cb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8162dcd14f864ce59c439e249df9c134",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6860149ea683451a97d0a9f10fb90bcd",
            "value": 53
          }
        },
        "6dc792df2d8243349a91b464215495e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13663e05b0e2400e950c46aa8cde616f",
            "placeholder": "​",
            "style": "IPY_MODEL_e0d0a96d29044bad81bbec15e6d51365",
            "value": " 53.0/53.0 [00:00&lt;00:00, 2.01kB/s]"
          }
        },
        "d4b9115ed3c04ffcac67173cc188b08b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bc9b11a5b3c4325b240bdfd952383f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35ab160fe48f44029e4c6367a901e8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8162dcd14f864ce59c439e249df9c134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6860149ea683451a97d0a9f10fb90bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13663e05b0e2400e950c46aa8cde616f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0d0a96d29044bad81bbec15e6d51365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d2bb14401c94d36aad5fcf1732f0a7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9981e75af484111b8db4e6526bfd143",
              "IPY_MODEL_1e1984255e27400b9fc34bc8c1d3b055",
              "IPY_MODEL_0d2bfd18e6264e5aadb18cc3e3199789"
            ],
            "layout": "IPY_MODEL_ca2a9f68a80e40c88e3046d82126d45d"
          }
        },
        "d9981e75af484111b8db4e6526bfd143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12b9a24cbfe94d9bb29f1c4d1621a12a",
            "placeholder": "​",
            "style": "IPY_MODEL_9dee82c36f5a49d8882dfe480b4617f7",
            "value": "config.json: 100%"
          }
        },
        "1e1984255e27400b9fc34bc8c1d3b055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_509c8e232d5b4e58b1c1a836e432be17",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fac1a6fbb61d41719cea984f4c8c295a",
            "value": 612
          }
        },
        "0d2bfd18e6264e5aadb18cc3e3199789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9e4a7605f54328a19cbbcd7fc44533",
            "placeholder": "​",
            "style": "IPY_MODEL_858ced4db8884a57964e905b7007c5f4",
            "value": " 612/612 [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "ca2a9f68a80e40c88e3046d82126d45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12b9a24cbfe94d9bb29f1c4d1621a12a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dee82c36f5a49d8882dfe480b4617f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "509c8e232d5b4e58b1c1a836e432be17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fac1a6fbb61d41719cea984f4c8c295a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef9e4a7605f54328a19cbbcd7fc44533": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "858ced4db8884a57964e905b7007c5f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5346e15626d4e02ab84c5343b073863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3c33ae9ee2c4ed187b99e7db1643965",
              "IPY_MODEL_40970dffd76c49a9b30cf3eb159027f3",
              "IPY_MODEL_1d056f79881f48be88cd5f2886ec26b0"
            ],
            "layout": "IPY_MODEL_5db4af3786804143bdd47f2afddd6af6"
          }
        },
        "f3c33ae9ee2c4ed187b99e7db1643965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74362e6383a24f4aac7ed4c4b4e28c57",
            "placeholder": "​",
            "style": "IPY_MODEL_4e3c0a2b472a425d8b32cdf166ad1c00",
            "value": "model.safetensors: 100%"
          }
        },
        "40970dffd76c49a9b30cf3eb159027f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c08542712bff492dbf4ef8bffbc84baf",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da3dd0e16d6f48588971562793ccd3a9",
            "value": 90868376
          }
        },
        "1d056f79881f48be88cd5f2886ec26b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5658f83ba5f34e1b8a3c223ba886fcb5",
            "placeholder": "​",
            "style": "IPY_MODEL_2d7b4db0eaa4449b80b709c79e18128c",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 345MB/s]"
          }
        },
        "5db4af3786804143bdd47f2afddd6af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74362e6383a24f4aac7ed4c4b4e28c57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e3c0a2b472a425d8b32cdf166ad1c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c08542712bff492dbf4ef8bffbc84baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da3dd0e16d6f48588971562793ccd3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5658f83ba5f34e1b8a3c223ba886fcb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d7b4db0eaa4449b80b709c79e18128c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b453eb9d6604cf2837a33579c7dd0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76d7281927fd46e398a9870ee40a90d0",
              "IPY_MODEL_200604c494c1484fa07ab30c97ac795e",
              "IPY_MODEL_97a3ec985d8a4e0e8adc0ccbc3be3084"
            ],
            "layout": "IPY_MODEL_ef4547afc66744e49ed7f317f847bfb6"
          }
        },
        "76d7281927fd46e398a9870ee40a90d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_411f3ef0560342e79a6b09aba3cf8f75",
            "placeholder": "​",
            "style": "IPY_MODEL_97930828967743ca81ab83f195f844ed",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "200604c494c1484fa07ab30c97ac795e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9d60977c0b43aeb9f5f9949312a5e5",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3cac1493c8e4c1993d38b6bb9cdec9b",
            "value": 350
          }
        },
        "97a3ec985d8a4e0e8adc0ccbc3be3084": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d383ae1e15ef444fb46532475d89eec2",
            "placeholder": "​",
            "style": "IPY_MODEL_525241df4b8b4d9baa42cf78cd700f61",
            "value": " 350/350 [00:00&lt;00:00, 25.3kB/s]"
          }
        },
        "ef4547afc66744e49ed7f317f847bfb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "411f3ef0560342e79a6b09aba3cf8f75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97930828967743ca81ab83f195f844ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b9d60977c0b43aeb9f5f9949312a5e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3cac1493c8e4c1993d38b6bb9cdec9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d383ae1e15ef444fb46532475d89eec2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "525241df4b8b4d9baa42cf78cd700f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88c5deaffe304e0d9f51fefd17707a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74d205becaac4cbc947adfb3e359c303",
              "IPY_MODEL_d7d78790b6c942b7838084e3d427c5bf",
              "IPY_MODEL_eef9b53b01a944d99d7a1a97c7a953b5"
            ],
            "layout": "IPY_MODEL_00121d3575bc4d369ff1077b55581539"
          }
        },
        "74d205becaac4cbc947adfb3e359c303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bf060ba2ad345599cf1c2e64a76d6cf",
            "placeholder": "​",
            "style": "IPY_MODEL_a8c6b9f3bdae42f1b3e79d03ea1e86e7",
            "value": "vocab.txt: 100%"
          }
        },
        "d7d78790b6c942b7838084e3d427c5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_042c5314658e44c09be4537538fec21b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e9855ab2f144ea18ca3811041cf92d7",
            "value": 231508
          }
        },
        "eef9b53b01a944d99d7a1a97c7a953b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38a7b1473f8b40e2bdade91d874c14d7",
            "placeholder": "​",
            "style": "IPY_MODEL_fa611c0b708c484391aab5652d2e0cd3",
            "value": " 232k/232k [00:00&lt;00:00, 12.8MB/s]"
          }
        },
        "00121d3575bc4d369ff1077b55581539": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bf060ba2ad345599cf1c2e64a76d6cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8c6b9f3bdae42f1b3e79d03ea1e86e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "042c5314658e44c09be4537538fec21b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e9855ab2f144ea18ca3811041cf92d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38a7b1473f8b40e2bdade91d874c14d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa611c0b708c484391aab5652d2e0cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4996c40a096e4381903ec74cf4d76601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65b9a4fafd814d7caf780050cce3be49",
              "IPY_MODEL_d20f28e52c444eccb1674e620b9a8096",
              "IPY_MODEL_de25cf27b8ee44ebb7a695a233699c9c"
            ],
            "layout": "IPY_MODEL_486c97457f1c46bdaa9eb6f4b9be7074"
          }
        },
        "65b9a4fafd814d7caf780050cce3be49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5af8937f55141109dd0de5a2760431f",
            "placeholder": "​",
            "style": "IPY_MODEL_9f7f6c68b0624e11882dc6e0db880dbb",
            "value": "tokenizer.json: 100%"
          }
        },
        "d20f28e52c444eccb1674e620b9a8096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f96ffdc09eb348fba7f80d8fd060a14a",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4908636e378f48869183a1aaefa08571",
            "value": 466247
          }
        },
        "de25cf27b8ee44ebb7a695a233699c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039ae91111e940b38656f4c3aa90e6b5",
            "placeholder": "​",
            "style": "IPY_MODEL_9667e61afb6d4645a0debeaecd517803",
            "value": " 466k/466k [00:00&lt;00:00, 2.04MB/s]"
          }
        },
        "486c97457f1c46bdaa9eb6f4b9be7074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5af8937f55141109dd0de5a2760431f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f7f6c68b0624e11882dc6e0db880dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f96ffdc09eb348fba7f80d8fd060a14a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4908636e378f48869183a1aaefa08571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "039ae91111e940b38656f4c3aa90e6b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9667e61afb6d4645a0debeaecd517803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d58dd3a6a3444adbc7f391551cb2c36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d4d6c128e4444959168819ef3d86b0a",
              "IPY_MODEL_1f1da9ec6448422184742a3015acd058",
              "IPY_MODEL_002fe3170f0b42848866099a36e7a88d"
            ],
            "layout": "IPY_MODEL_f98a8a69ef2a4bdaa48a8e8342d63484"
          }
        },
        "8d4d6c128e4444959168819ef3d86b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ad1aeebb3a4427b24138b961cc8b29",
            "placeholder": "​",
            "style": "IPY_MODEL_0aff26835d4449489e44497ea1d8aadc",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1f1da9ec6448422184742a3015acd058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7782722376724b12afd3e683f36dc235",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83b5e4a33d0d419f9d1e8d6b69bb7f26",
            "value": 112
          }
        },
        "002fe3170f0b42848866099a36e7a88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ed9090b5b644de9a0f2905c40eda59d",
            "placeholder": "​",
            "style": "IPY_MODEL_ee2621e2feca4462b86893db26b55163",
            "value": " 112/112 [00:00&lt;00:00, 7.60kB/s]"
          }
        },
        "f98a8a69ef2a4bdaa48a8e8342d63484": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9ad1aeebb3a4427b24138b961cc8b29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aff26835d4449489e44497ea1d8aadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7782722376724b12afd3e683f36dc235": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83b5e4a33d0d419f9d1e8d6b69bb7f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ed9090b5b644de9a0f2905c40eda59d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee2621e2feca4462b86893db26b55163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3835aa78818f4b62b228d9e8977480a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a2cac23c759472d8dd1b622f35a879b",
              "IPY_MODEL_e1104e2a8c244444bd22b3b964044e7d",
              "IPY_MODEL_48457419cc65489c82e282af6ad091db"
            ],
            "layout": "IPY_MODEL_95d82b1a4ee34ec1baa245dddb0bb1b5"
          }
        },
        "4a2cac23c759472d8dd1b622f35a879b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1db129742794d87a798d465db8ef79f",
            "placeholder": "​",
            "style": "IPY_MODEL_2e380ffd4b9744e2902c67ebd9d053a1",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "e1104e2a8c244444bd22b3b964044e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f08b11cf83d4bc8ac030b8bdbf82b00",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57edbb0764aa45d9b6e605e79f3be1f8",
            "value": 190
          }
        },
        "48457419cc65489c82e282af6ad091db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66f9617499294a96988b789b3a44e383",
            "placeholder": "​",
            "style": "IPY_MODEL_95058673750f45abb32186014fe93507",
            "value": " 190/190 [00:00&lt;00:00, 14.0kB/s]"
          }
        },
        "95d82b1a4ee34ec1baa245dddb0bb1b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1db129742794d87a798d465db8ef79f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e380ffd4b9744e2902c67ebd9d053a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f08b11cf83d4bc8ac030b8bdbf82b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57edbb0764aa45d9b6e605e79f3be1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "66f9617499294a96988b789b3a44e383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95058673750f45abb32186014fe93507": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**I import some useful libraries in python.**"
      ],
      "metadata": {
        "id": "ggdLFhm797TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unidecode\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import csv\n",
        "import difflib\n",
        "from unidecode import unidecode\n",
        "import random\n",
        "import torch\n",
        "import torch.backends.cudnn\n",
        "from numpy.random import MT19937\n",
        "from numpy.random import RandomState, SeedSequence\n",
        "from google.colab import drive\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "from transformers import BertTokenizerFast\n",
        "import sys"
      ],
      "metadata": {
        "id": "oAd_kR_CBw5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d756e3d9-5b13-4a3c-cd19-67b8729c9ba2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/235.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/235.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq_L6JJI-A4O"
      },
      "source": [
        "**I mount google drive because all the files (for example .csv) that i used for the implementation of my thesis are saved on my google drive.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uzGnnyA-1paw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7154ad4-7062-4b2b-cfc2-675deb3cc504"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6s1AFdo-FBL"
      },
      "source": [
        "**Check of the device that it is used for the implementation of the notebooks of this thesis, that is determined from google colab.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device available for running: \")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "G0cXT79V1smj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0849bb-c2e8-4c75-b7c6-3a7de3d33e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device available for running: \n",
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXfSTaYC6Xc5"
      },
      "source": [
        "**Reading of the created datasets (for both the SimpleQuestions dataset that includes all training, validation and test questions and the SimpleQuestions subset that includes only answerable over wikidata questions) as .csv file.  With the same way the corresponding test file that contains the questions with their relation id, entity id, answer id and answer label and is used for testing the QA engines is read as .csv file.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = pd.read_csv(\"drive/MyDrive/train_dataset.csv\", sep = ',')\n",
        "validation_dataset = pd.read_csv(\"drive/MyDrive/valid_dataset.csv\", sep = ',')\n",
        "test_dataset = pd.read_csv(\"drive/MyDrive/test_dataset.csv\", sep = ',')\n",
        "print(train_dataset)\n",
        "print(validation_dataset)\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "id": "Cr7o_6892AyX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe814d59-da31-4086-f408-ff2206e1b815"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       entity_id      entity_label relation_id  \\\n",
            "0        Q126399       Warner Bros        R272   \n",
            "1         Q12439           Detroit         R19   \n",
            "2       Q7370831          Q7370831        P162   \n",
            "3       Q6817891       Mera Shikar        P364   \n",
            "4          Q1297           Chicago        R276   \n",
            "...          ...               ...         ...   \n",
            "34369  Q16093542    Anthony Bailey         P27   \n",
            "34370    Q325741     Homi K Bhabha        P737   \n",
            "34371   Q1062702  video game music        R136   \n",
            "34372    Q926822  Gaston Filgueira         P21   \n",
            "34373    Q336286          defender        R413   \n",
            "\n",
            "                                                Question  \n",
            "0                  what movie is produced by warner bros  \n",
            "1                      who is a musician born in detroit  \n",
            "2                who produced the film rough house rosie  \n",
            "3      what is the language in which mera shikar was ...  \n",
            "4      Whats the name of a battle that happened in ch...  \n",
            "...                                                  ...  \n",
            "34369          What is the nationality of anthony bailey  \n",
            "34370    who was homi k bhabha especially influenced by   \n",
            "34371             which artist composes video game music  \n",
            "34372                    What gender is gaston filgueira  \n",
            "34373                      what player played a defender  \n",
            "\n",
            "[34374 rows x 4 columns]\n",
            "     entity_id            entity_label relation_id  \\\n",
            "0     Q3541144      JW Marriott Panama        P138   \n",
            "1      Q318926           Sasha Vujacic         P19   \n",
            "2     Q2568216       Wiebke Carolsfeld         R57   \n",
            "3     Q2275923  Seymour Parker Gilbert        P106   \n",
            "4     Q2856873        Antoine de Fevin         P20   \n",
            "...        ...                     ...         ...   \n",
            "4862  Q3709870          Herby Fortunat        P413   \n",
            "4863   Q150804             The Pianist        P136   \n",
            "4864  Q1343857                Jon Seda         P19   \n",
            "4865  Q2981169       Nikolaj Frobenius        P106   \n",
            "4866      Q174               Sao Paulo         R19   \n",
            "\n",
            "                                               Question  \n",
            "0     Who was the trump ocean club international hot...  \n",
            "1                          where was sasha vujacic born  \n",
            "2          What is a film directed by wiebke carolsfeld  \n",
            "3            What was Seymour Parker Gilbert profession  \n",
            "4         in what french city did antoine de fevin die   \n",
            "...                                                 ...  \n",
            "4862  which position did herby fortunat play in foot...  \n",
            "4863       what kind of film is the pianist (2002 film)  \n",
            "4864                     where was jon seda given birth  \n",
            "4865               What is nikolaj frobenius profession  \n",
            "4866         who is a person that was born in sao paulo  \n",
            "\n",
            "[4867 rows x 4 columns]\n",
            "      entity_id            entity_label relation_id  \\\n",
            "0      Q5487302          Harder  Faster        P136   \n",
            "1     Q16330302             Alex Golfis         P19   \n",
            "2     Q16225521                Phil Hay         R58   \n",
            "3      Q7358590           Roger Marquis         P20   \n",
            "4       Q154335              Yves Klein        P509   \n",
            "...         ...                     ...         ...   \n",
            "9956   Q1447249          Doctor Faustus        P170   \n",
            "9957     Q34863           Oklahoma City        R276   \n",
            "9958    Q582715             2974 Holden         P31   \n",
            "9959    Q582147  Snow Falling on Cedars        P136   \n",
            "9960    Q458750         Lucille Clifton         P27   \n",
            "\n",
            "                                               Question  \n",
            "0                  Which genre of album is harderfaster  \n",
            "1                     what city was alex golfis born in  \n",
            "2                   what film is by the writer phil hay  \n",
            "3                           Where did roger marquis die  \n",
            "4             what was the cause of death of yves klein  \n",
            "...                                                 ...  \n",
            "9956  who was the creator of the fictional character...  \n",
            "9957  what a college sporting event that took place ...  \n",
            "9958               what celestial object is 2974 holden  \n",
            "9959  what is the film genre for snow falling on cedars  \n",
            "9960                what nationality is lucille clifton  \n",
            "\n",
            "[9961 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answerable_dataset = pd.read_csv(\"drive/MyDrive/train_answerable_questions_dataset.csv\", sep = ',')\n",
        "validation_answerable_dataset = pd.read_csv(\"drive/MyDrive/valid_answerable_questions_dataset.csv\", sep = ',')\n",
        "test_answerable_dataset = pd.read_csv(\"drive/MyDrive/test_answerable_dataset.csv\", sep = ',')\n",
        "print(train_answerable_dataset)\n",
        "print(validation_answerable_dataset)\n",
        "print(test_answerable_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx8VOMAm6ni8",
        "outputId": "5ddf5117-b4ac-4591-f0d4-72012d46d23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       entity_id      entity_label relation_id  \\\n",
            "0         Q12439           Detroit         R19   \n",
            "1       Q6817891       Mera Shikar        P364   \n",
            "2          Q1297           Chicago        R276   \n",
            "3        Q193592        midfielder        R413   \n",
            "4       Q6849115     Mike Twellman        P413   \n",
            "...          ...               ...         ...   \n",
            "19476    Q223960    mountain tapir        P171   \n",
            "19477   Q1535153    superhero film        R136   \n",
            "19478    Q157443       comedy film        R136   \n",
            "19479  Q16093542    Anthony Bailey         P27   \n",
            "19480    Q926822  Gaston Filgueira         P21   \n",
            "\n",
            "                                                Question  \n",
            "0                      who is a musician born in detroit  \n",
            "1      what is the language in which mera shikar was ...  \n",
            "2      Whats the name of a battle that happened in ch...  \n",
            "3              what player plays the position midfielder  \n",
            "4         what is the position that  mike twellman plays  \n",
            "...                                                  ...  \n",
            "19476  what classification does  mountain tapir come ...  \n",
            "19477   What a superhero movie that premiered on toonami  \n",
            "19478  What is the name of a comedy film that is also...  \n",
            "19479          What is the nationality of anthony bailey  \n",
            "19480                    What gender is gaston filgueira  \n",
            "\n",
            "[19481 rows x 4 columns]\n",
            "     entity_id            entity_label relation_id  \\\n",
            "0      Q318926           Sasha Vujacic         P19   \n",
            "1     Q2568216       Wiebke Carolsfeld         R57   \n",
            "2     Q2275923  Seymour Parker Gilbert        P106   \n",
            "3     Q2856873        Antoine de Fevin         P20   \n",
            "4      Q522966           Jamie Hewlett        P106   \n",
            "...        ...                     ...         ...   \n",
            "2816  Q7111404             OutNumbered        P178   \n",
            "2817  Q3480757          Seumas O'Kelly         P21   \n",
            "2818  Q3709870          Herby Fortunat        P413   \n",
            "2819  Q2981169       Nikolaj Frobenius        P106   \n",
            "2820      Q174               Sao Paulo         R19   \n",
            "\n",
            "                                               Question  \n",
            "0                          where was sasha vujacic born  \n",
            "1          What is a film directed by wiebke carolsfeld  \n",
            "2            What was Seymour Parker Gilbert profession  \n",
            "3         in what french city did antoine de fevin die   \n",
            "4                      What job does jamie hewlett have  \n",
            "...                                                 ...  \n",
            "2816                          who developed outnumbered  \n",
            "2817                  what is the sex of seumas o'kelly  \n",
            "2818  which position did herby fortunat play in foot...  \n",
            "2819               What is nikolaj frobenius profession  \n",
            "2820         who is a person that was born in sao paulo  \n",
            "\n",
            "[2821 rows x 4 columns]\n",
            "     entity_id       entity_label relation_id  \\\n",
            "0     Q7358590      Roger Marquis         P20   \n",
            "1      Q154335         Yves Klein        P509   \n",
            "2     Q2747238       Carlos Gomez        P413   \n",
            "3       Q62498  Engelbert Zaschka         P21   \n",
            "4      Q182485      Pee Wee Reese        P413   \n",
            "...        ...                ...         ...   \n",
            "5617     Q1492          Barcelona         R19   \n",
            "5618  Q2870425           Jun Lana       R1431   \n",
            "5619   Q445899    Gunnar Johansen         P19   \n",
            "5620   Q582715        2974 Holden         P31   \n",
            "5621   Q458750    Lucille Clifton         P27   \n",
            "\n",
            "                                               Question  \n",
            "0                           Where did roger marquis die  \n",
            "1             what was the cause of death of yves klein  \n",
            "2                  What position does carlos gomez play  \n",
            "3                  how does engelbert zaschka identify   \n",
            "4     what position does pee wee reese play in baseball  \n",
            "...                                                 ...  \n",
            "5617  Who is a notable figure that was born in barce...  \n",
            "5618          what films have been produced by jun lana  \n",
            "5619          Where was gunnar johansen born in Denmark  \n",
            "5620               what celestial object is 2974 holden  \n",
            "5621                what nationality is lucille clifton  \n",
            "\n",
            "[5622 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_questions_list = pd.read_csv(\"drive/MyDrive/Questions_testing_with_answers.txt\", sep = ',', names=['Question','entity_id', 'relation_id','answer_id', 'answer_label'])\n",
        "print(testing_questions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kviIObIHmHZI",
        "outputId": "4c2034fe-1573-48d9-dd0f-e955bd2c5a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Question  entity_id relation_id  \\\n",
            "0   Which home is an example of italianate archite...    Q615196        R149   \n",
            "1           what type of object is 25049 christofnorn   Q1753907         P31   \n",
            "2                 Which person was born in liverpool?     Q24826         R19   \n",
            "3       What film genre is twilight considered to be?    Q160071        P136   \n",
            "4   which type of film is the bitter tea of genera...    Q568239        P136   \n",
            "5                What is the gender of Athina Maximou  Q12873135         P21   \n",
            "6                        Name an Rolling Stones album     Q11036        R175   \n",
            "7               Who directed woody meets davy crewcut   Q8033685         P57   \n",
            "8   who was the first NSW female Minister of Educa...     Q12078        R509   \n",
            "9             What position does denis shcherbak play   Q4528782        P413   \n",
            "10  which country does the show un refugio para el...   Q1068093        P495   \n",
            "11  what alternative rock band from Chicago is the...   Q2071360        P175   \n",
            "12  who is the artist that performed on the album ...   Q7410135        P175   \n",
            "13                   where john brewster jr. was born   Q6223118         P19   \n",
            "14                        what is a multiplayer game?   Q6895044        R404   \n",
            "15         which company produced hot enough for june  Q12124859        P272   \n",
            "16  is jose figueroa alcorta from argentina or cos...    Q442729         P27   \n",
            "17  What kind of game is microsoft international s...   Q3312381        P136   \n",
            "18              who is the composer of the song liar?   Q1049271         P86   \n",
            "19     Joshua Kimmich is member of which sports team?  Q13865408         P54   \n",
            "20  What is the name of a folk rock singer (or gro...    Q186472        R136   \n",
            "21                             Who was born in dakar?      Q3718         R19   \n",
            "22                   where did edward i. edwards died    Q436902         P20   \n",
            "23                    What is the sex of david swift?   Q5240208         P21   \n",
            "24     What language is mission to caracas written in   Q6878840        P364   \n",
            "25          what genre is the album why is there air?   Q7997809        P136   \n",
            "26                 what is chad mustard's nationality   Q5066318         P27   \n",
            "27       what is an instrument played by carl jackson   Q5040368       P1303   \n",
            "28             Which is Aristotle Onassis profession?    Q180455        P106   \n",
            "29          what genre of music does bo diddley play?    Q208881        P136   \n",
            "30  Which genre of music was the album duck rock l...    Q910692        P136   \n",
            "31   what is Michael Ballack's country of nationality     Q11948         P27   \n",
            "32  what football position does dorin dickerson pl...   Q3037050        P413   \n",
            "33    which country is purple people eater filmed in?   Q3410974        P495   \n",
            "34        idris phillips follows this major religion.  Q16192877        P140   \n",
            "35             what instrument does ashwin sood play?   Q4806196       P1303   \n",
            "36         Where was gunnar johansen born in Denmark?    Q445899         P19   \n",
            "37  What is the country of origin of the show tok!...   Q7813436        P495   \n",
            "38  What is the political ideology behind the germ...    Q560777       P1142   \n",
            "39  Name an territorial entity which is contained ...        Q21        P150   \n",
            "40                    what is a silent film from 1927    Q226730        R136   \n",
            "41  The power rangers dino thunder game was publis...  Q11888796        P123   \n",
            "42  which was the country of citizehship of christ...   Q2966640         P27   \n",
            "43            Which position was David Beckham played     Q10520        P413   \n",
            "44  what is the second level division of the divis...   Q1801175         P17   \n",
            "45        Which film was directed by ian iqbal rashid  Q15461094         R57   \n",
            "46  Which genre of book is bin laden: the man who ...   Q4913778        P136   \n",
            "47           which country does dany saadia belong to   Q5221412         P27   \n",
            "48                            what is largemouth bass    Q755105        P105   \n",
            "49  does british music band crawler play blues-roc...   Q2774245        P136   \n",
            "50    what river does the neville island bridge cross   Q7004736        P177   \n",
            "51  what was the country of origin of the tv show ...   Q7508530        P495   \n",
            "52    Which notable person has Rome as place of death       Q220         P20   \n",
            "53  what is the category of the celestial object 1...    Q137259         P31   \n",
            "54        what is a city in yolo county in california    Q109709        R131   \n",
            "55  which place was named after john radcliffe (en...    Q922508        R138   \n",
            "56                What is Albert Einstein occupation?       Q937        P106   \n",
            "57  which is the film's crying freeman country of ...    Q657981        P495   \n",
            "58  what kind of music is played on film life and ...   Q6545041        P136   \n",
            "59             what's the name of an documentary film     Q93204        R136   \n",
            "\n",
            "    answer_id                              answer_label  \n",
            "0    Q6265419                John and Maria Adams House  \n",
            "1       Q3863                                asteroid\\t  \n",
            "2       Q2632                               Ringo Starr  \n",
            "3    Q1054574                              romance film  \n",
            "4     Q130232                                drama film  \n",
            "5    Q6581072                                    female  \n",
            "6      Q31933                             Metamorphosis  \n",
            "7    Q2310245                                 Alex Lovy  \n",
            "8    Q7934181                         Virginia Chadwick  \n",
            "9     Q193592                                midfielder  \n",
            "10        Q96                                    Mexico  \n",
            "11    Q736107                                     OK Go  \n",
            "12    Q585470                       Simian Mobile Disco  \n",
            "13   Q2572461                                   Hampton  \n",
            "14   Q3552034  Untold Legends: Brotherhood of the Blade  \n",
            "15   Q1535788                         Rank Organisation  \n",
            "16       Q414                                 Argentina  \n",
            "17    Q868217                         sports video game  \n",
            "18     Q15869                           Freddie Mercury  \n",
            "19     Q15789                          FC Bayern Munich  \n",
            "20       Q633                                Neil Young  \n",
            "21   Q3032934                           Djibril Diawara  \n",
            "22     Q26339                              Jersey City   \n",
            "23   Q6581097                                      male  \n",
            "24       Q150                                    French  \n",
            "25    Q145806                           stand-up comedy  \n",
            "26        Q30                  United States of America  \n",
            "27      Q6607                                    guitar  \n",
            "28    Q500251                               ship-owner   \n",
            "29      Q7749                             rock and roll  \n",
            "30    Q187760                                  new wave  \n",
            "31       Q183                                   Germany  \n",
            "32    Q918224                             wide receiver  \n",
            "33        Q30                  United States of America  \n",
            "34       Q432                                     Islam  \n",
            "35    Q128309                                  drum kit  \n",
            "36      Q1748                                Copenhagen  \n",
            "37       Q928                               Philippines  \n",
            "38    Q821102                            progressivism   \n",
            "39     Q47967                        North West England  \n",
            "40  Q12037390             The Lovers of an Old Criminal  \n",
            "41    Q580866                                       THQ  \n",
            "42        Q16                                    Canada  \n",
            "43    Q193592                               midfielder   \n",
            "44       Q155                                    Brazil  \n",
            "45   Q2628332                             Touch of Pink  \n",
            "46     Q36279                                 biography  \n",
            "47        Q96                                   Mexico   \n",
            "48      Q7432                                   species  \n",
            "49    Q193355                                blues-rock  \n",
            "50      Q4915                                Ohio River  \n",
            "51        Q30                  United States of America  \n",
            "52      Q1048                             Julius Caesar  \n",
            "53      Q3863                                  asteroid  \n",
            "54   Q1368039                                   Esparto  \n",
            "55   Q6254080                  John Radcliffe Hospital   \n",
            "56    Q169470                                 physicist  \n",
            "57        Q17                                     Japan  \n",
            "58    Q183504                                indie rock  \n",
            "59     Q24258                          Visions of Light  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu10tYmCmXyq"
      },
      "source": [
        "**Check if the test file with the questions that is used for testing the QA engines, the SimpleQuestions training, validation and test dataset have at least one line with null value. This issues both for SimpleQuestions dataset that includes only answerable over wikidata questions and for the corresponding dataset that includes all the questions.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.dropna(inplace = True)\n",
        "validation_dataset.dropna(inplace = True)\n",
        "test_dataset.dropna(inplace = True)\n",
        "print(train_dataset)\n",
        "print(validation_dataset)\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "id": "o2sZdANX2C0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20466f95-f55a-4504-e366-21d66b39b1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       entity_id      entity_label relation_id  \\\n",
            "0        Q126399       Warner Bros        R272   \n",
            "1         Q12439           Detroit         R19   \n",
            "2       Q7370831          Q7370831        P162   \n",
            "3       Q6817891       Mera Shikar        P364   \n",
            "4          Q1297           Chicago        R276   \n",
            "...          ...               ...         ...   \n",
            "34369  Q16093542    Anthony Bailey         P27   \n",
            "34370    Q325741     Homi K Bhabha        P737   \n",
            "34371   Q1062702  video game music        R136   \n",
            "34372    Q926822  Gaston Filgueira         P21   \n",
            "34373    Q336286          defender        R413   \n",
            "\n",
            "                                                Question  \n",
            "0                  what movie is produced by warner bros  \n",
            "1                      who is a musician born in detroit  \n",
            "2                who produced the film rough house rosie  \n",
            "3      what is the language in which mera shikar was ...  \n",
            "4      Whats the name of a battle that happened in ch...  \n",
            "...                                                  ...  \n",
            "34369          What is the nationality of anthony bailey  \n",
            "34370    who was homi k bhabha especially influenced by   \n",
            "34371             which artist composes video game music  \n",
            "34372                    What gender is gaston filgueira  \n",
            "34373                      what player played a defender  \n",
            "\n",
            "[34373 rows x 4 columns]\n",
            "     entity_id            entity_label relation_id  \\\n",
            "0     Q3541144      JW Marriott Panama        P138   \n",
            "1      Q318926           Sasha Vujacic         P19   \n",
            "2     Q2568216       Wiebke Carolsfeld         R57   \n",
            "3     Q2275923  Seymour Parker Gilbert        P106   \n",
            "4     Q2856873        Antoine de Fevin         P20   \n",
            "...        ...                     ...         ...   \n",
            "4862  Q3709870          Herby Fortunat        P413   \n",
            "4863   Q150804             The Pianist        P136   \n",
            "4864  Q1343857                Jon Seda         P19   \n",
            "4865  Q2981169       Nikolaj Frobenius        P106   \n",
            "4866      Q174               Sao Paulo         R19   \n",
            "\n",
            "                                               Question  \n",
            "0     Who was the trump ocean club international hot...  \n",
            "1                          where was sasha vujacic born  \n",
            "2          What is a film directed by wiebke carolsfeld  \n",
            "3            What was Seymour Parker Gilbert profession  \n",
            "4         in what french city did antoine de fevin die   \n",
            "...                                                 ...  \n",
            "4862  which position did herby fortunat play in foot...  \n",
            "4863       what kind of film is the pianist (2002 film)  \n",
            "4864                     where was jon seda given birth  \n",
            "4865               What is nikolaj frobenius profession  \n",
            "4866         who is a person that was born in sao paulo  \n",
            "\n",
            "[4867 rows x 4 columns]\n",
            "      entity_id            entity_label relation_id  \\\n",
            "0      Q5487302          Harder  Faster        P136   \n",
            "1     Q16330302             Alex Golfis         P19   \n",
            "2     Q16225521                Phil Hay         R58   \n",
            "3      Q7358590           Roger Marquis         P20   \n",
            "4       Q154335              Yves Klein        P509   \n",
            "...         ...                     ...         ...   \n",
            "9956   Q1447249          Doctor Faustus        P170   \n",
            "9957     Q34863           Oklahoma City        R276   \n",
            "9958    Q582715             2974 Holden         P31   \n",
            "9959    Q582147  Snow Falling on Cedars        P136   \n",
            "9960    Q458750         Lucille Clifton         P27   \n",
            "\n",
            "                                               Question  \n",
            "0                  Which genre of album is harderfaster  \n",
            "1                     what city was alex golfis born in  \n",
            "2                   what film is by the writer phil hay  \n",
            "3                           Where did roger marquis die  \n",
            "4             what was the cause of death of yves klein  \n",
            "...                                                 ...  \n",
            "9956  who was the creator of the fictional character...  \n",
            "9957  what a college sporting event that took place ...  \n",
            "9958               what celestial object is 2974 holden  \n",
            "9959  what is the film genre for snow falling on cedars  \n",
            "9960                what nationality is lucille clifton  \n",
            "\n",
            "[9961 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answerable_dataset.dropna(inplace = True)\n",
        "validation_answerable_dataset.dropna(inplace = True)\n",
        "test_answerable_dataset.dropna(inplace = True)\n",
        "print(train_answerable_dataset)\n",
        "print(validation_answerable_dataset)\n",
        "print(test_answerable_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cr70dv665CQ",
        "outputId": "7a42b565-ad7d-48f3-c10c-c1d30c90175d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       entity_id      entity_label relation_id  \\\n",
            "0         Q12439           Detroit         R19   \n",
            "1       Q6817891       Mera Shikar        P364   \n",
            "2          Q1297           Chicago        R276   \n",
            "3        Q193592        midfielder        R413   \n",
            "4       Q6849115     Mike Twellman        P413   \n",
            "...          ...               ...         ...   \n",
            "19476    Q223960    mountain tapir        P171   \n",
            "19477   Q1535153    superhero film        R136   \n",
            "19478    Q157443       comedy film        R136   \n",
            "19479  Q16093542    Anthony Bailey         P27   \n",
            "19480    Q926822  Gaston Filgueira         P21   \n",
            "\n",
            "                                                Question  \n",
            "0                      who is a musician born in detroit  \n",
            "1      what is the language in which mera shikar was ...  \n",
            "2      Whats the name of a battle that happened in ch...  \n",
            "3              what player plays the position midfielder  \n",
            "4         what is the position that  mike twellman plays  \n",
            "...                                                  ...  \n",
            "19476  what classification does  mountain tapir come ...  \n",
            "19477   What a superhero movie that premiered on toonami  \n",
            "19478  What is the name of a comedy film that is also...  \n",
            "19479          What is the nationality of anthony bailey  \n",
            "19480                    What gender is gaston filgueira  \n",
            "\n",
            "[19481 rows x 4 columns]\n",
            "     entity_id            entity_label relation_id  \\\n",
            "0      Q318926           Sasha Vujacic         P19   \n",
            "1     Q2568216       Wiebke Carolsfeld         R57   \n",
            "2     Q2275923  Seymour Parker Gilbert        P106   \n",
            "3     Q2856873        Antoine de Fevin         P20   \n",
            "4      Q522966           Jamie Hewlett        P106   \n",
            "...        ...                     ...         ...   \n",
            "2816  Q7111404             OutNumbered        P178   \n",
            "2817  Q3480757          Seumas O'Kelly         P21   \n",
            "2818  Q3709870          Herby Fortunat        P413   \n",
            "2819  Q2981169       Nikolaj Frobenius        P106   \n",
            "2820      Q174               Sao Paulo         R19   \n",
            "\n",
            "                                               Question  \n",
            "0                          where was sasha vujacic born  \n",
            "1          What is a film directed by wiebke carolsfeld  \n",
            "2            What was Seymour Parker Gilbert profession  \n",
            "3         in what french city did antoine de fevin die   \n",
            "4                      What job does jamie hewlett have  \n",
            "...                                                 ...  \n",
            "2816                          who developed outnumbered  \n",
            "2817                  what is the sex of seumas o'kelly  \n",
            "2818  which position did herby fortunat play in foot...  \n",
            "2819               What is nikolaj frobenius profession  \n",
            "2820         who is a person that was born in sao paulo  \n",
            "\n",
            "[2821 rows x 4 columns]\n",
            "     entity_id       entity_label relation_id  \\\n",
            "0     Q7358590      Roger Marquis         P20   \n",
            "1      Q154335         Yves Klein        P509   \n",
            "2     Q2747238       Carlos Gomez        P413   \n",
            "3       Q62498  Engelbert Zaschka         P21   \n",
            "4      Q182485      Pee Wee Reese        P413   \n",
            "...        ...                ...         ...   \n",
            "5617     Q1492          Barcelona         R19   \n",
            "5618  Q2870425           Jun Lana       R1431   \n",
            "5619   Q445899    Gunnar Johansen         P19   \n",
            "5620   Q582715        2974 Holden         P31   \n",
            "5621   Q458750    Lucille Clifton         P27   \n",
            "\n",
            "                                               Question  \n",
            "0                           Where did roger marquis die  \n",
            "1             what was the cause of death of yves klein  \n",
            "2                  What position does carlos gomez play  \n",
            "3                  how does engelbert zaschka identify   \n",
            "4     what position does pee wee reese play in baseball  \n",
            "...                                                 ...  \n",
            "5617  Who is a notable figure that was born in barce...  \n",
            "5618          what films have been produced by jun lana  \n",
            "5619          Where was gunnar johansen born in Denmark  \n",
            "5620               what celestial object is 2974 holden  \n",
            "5621                what nationality is lucille clifton  \n",
            "\n",
            "[5622 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_questions_list.dropna(inplace = True)\n",
        "print(testing_questions_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ns-0N772mMXd",
        "outputId": "790cf6e0-51f5-4297-d673-4ccf367b36ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             Question  entity_id relation_id  \\\n",
            "0   Which home is an example of italianate archite...    Q615196        R149   \n",
            "1           what type of object is 25049 christofnorn   Q1753907         P31   \n",
            "2                 Which person was born in liverpool?     Q24826         R19   \n",
            "3       What film genre is twilight considered to be?    Q160071        P136   \n",
            "4   which type of film is the bitter tea of genera...    Q568239        P136   \n",
            "5                What is the gender of Athina Maximou  Q12873135         P21   \n",
            "6                        Name an Rolling Stones album     Q11036        R175   \n",
            "7               Who directed woody meets davy crewcut   Q8033685         P57   \n",
            "8   who was the first NSW female Minister of Educa...     Q12078        R509   \n",
            "9             What position does denis shcherbak play   Q4528782        P413   \n",
            "10  which country does the show un refugio para el...   Q1068093        P495   \n",
            "11  what alternative rock band from Chicago is the...   Q2071360        P175   \n",
            "12  who is the artist that performed on the album ...   Q7410135        P175   \n",
            "13                   where john brewster jr. was born   Q6223118         P19   \n",
            "14                        what is a multiplayer game?   Q6895044        R404   \n",
            "15         which company produced hot enough for june  Q12124859        P272   \n",
            "16  is jose figueroa alcorta from argentina or cos...    Q442729         P27   \n",
            "17  What kind of game is microsoft international s...   Q3312381        P136   \n",
            "18              who is the composer of the song liar?   Q1049271         P86   \n",
            "19     Joshua Kimmich is member of which sports team?  Q13865408         P54   \n",
            "20  What is the name of a folk rock singer (or gro...    Q186472        R136   \n",
            "21                             Who was born in dakar?      Q3718         R19   \n",
            "22                   where did edward i. edwards died    Q436902         P20   \n",
            "23                    What is the sex of david swift?   Q5240208         P21   \n",
            "24     What language is mission to caracas written in   Q6878840        P364   \n",
            "25          what genre is the album why is there air?   Q7997809        P136   \n",
            "26                 what is chad mustard's nationality   Q5066318         P27   \n",
            "27       what is an instrument played by carl jackson   Q5040368       P1303   \n",
            "28             Which is Aristotle Onassis profession?    Q180455        P106   \n",
            "29          what genre of music does bo diddley play?    Q208881        P136   \n",
            "30  Which genre of music was the album duck rock l...    Q910692        P136   \n",
            "31   what is Michael Ballack's country of nationality     Q11948         P27   \n",
            "32  what football position does dorin dickerson pl...   Q3037050        P413   \n",
            "33    which country is purple people eater filmed in?   Q3410974        P495   \n",
            "34        idris phillips follows this major religion.  Q16192877        P140   \n",
            "35             what instrument does ashwin sood play?   Q4806196       P1303   \n",
            "36         Where was gunnar johansen born in Denmark?    Q445899         P19   \n",
            "37  What is the country of origin of the show tok!...   Q7813436        P495   \n",
            "38  What is the political ideology behind the germ...    Q560777       P1142   \n",
            "39  Name an territorial entity which is contained ...        Q21        P150   \n",
            "40                    what is a silent film from 1927    Q226730        R136   \n",
            "41  The power rangers dino thunder game was publis...  Q11888796        P123   \n",
            "42  which was the country of citizehship of christ...   Q2966640         P27   \n",
            "43            Which position was David Beckham played     Q10520        P413   \n",
            "44  what is the second level division of the divis...   Q1801175         P17   \n",
            "45        Which film was directed by ian iqbal rashid  Q15461094         R57   \n",
            "46  Which genre of book is bin laden: the man who ...   Q4913778        P136   \n",
            "47           which country does dany saadia belong to   Q5221412         P27   \n",
            "48                            what is largemouth bass    Q755105        P105   \n",
            "49  does british music band crawler play blues-roc...   Q2774245        P136   \n",
            "50    what river does the neville island bridge cross   Q7004736        P177   \n",
            "51  what was the country of origin of the tv show ...   Q7508530        P495   \n",
            "52    Which notable person has Rome as place of death       Q220         P20   \n",
            "53  what is the category of the celestial object 1...    Q137259         P31   \n",
            "54        what is a city in yolo county in california    Q109709        R131   \n",
            "55  which place was named after john radcliffe (en...    Q922508        R138   \n",
            "56                What is Albert Einstein occupation?       Q937        P106   \n",
            "57  which is the film's crying freeman country of ...    Q657981        P495   \n",
            "58  what kind of music is played on film life and ...   Q6545041        P136   \n",
            "59             what's the name of an documentary film     Q93204        R136   \n",
            "\n",
            "    answer_id                              answer_label  \n",
            "0    Q6265419                John and Maria Adams House  \n",
            "1       Q3863                                asteroid\\t  \n",
            "2       Q2632                               Ringo Starr  \n",
            "3    Q1054574                              romance film  \n",
            "4     Q130232                                drama film  \n",
            "5    Q6581072                                    female  \n",
            "6      Q31933                             Metamorphosis  \n",
            "7    Q2310245                                 Alex Lovy  \n",
            "8    Q7934181                         Virginia Chadwick  \n",
            "9     Q193592                                midfielder  \n",
            "10        Q96                                    Mexico  \n",
            "11    Q736107                                     OK Go  \n",
            "12    Q585470                       Simian Mobile Disco  \n",
            "13   Q2572461                                   Hampton  \n",
            "14   Q3552034  Untold Legends: Brotherhood of the Blade  \n",
            "15   Q1535788                         Rank Organisation  \n",
            "16       Q414                                 Argentina  \n",
            "17    Q868217                         sports video game  \n",
            "18     Q15869                           Freddie Mercury  \n",
            "19     Q15789                          FC Bayern Munich  \n",
            "20       Q633                                Neil Young  \n",
            "21   Q3032934                           Djibril Diawara  \n",
            "22     Q26339                              Jersey City   \n",
            "23   Q6581097                                      male  \n",
            "24       Q150                                    French  \n",
            "25    Q145806                           stand-up comedy  \n",
            "26        Q30                  United States of America  \n",
            "27      Q6607                                    guitar  \n",
            "28    Q500251                               ship-owner   \n",
            "29      Q7749                             rock and roll  \n",
            "30    Q187760                                  new wave  \n",
            "31       Q183                                   Germany  \n",
            "32    Q918224                             wide receiver  \n",
            "33        Q30                  United States of America  \n",
            "34       Q432                                     Islam  \n",
            "35    Q128309                                  drum kit  \n",
            "36      Q1748                                Copenhagen  \n",
            "37       Q928                               Philippines  \n",
            "38    Q821102                            progressivism   \n",
            "39     Q47967                        North West England  \n",
            "40  Q12037390             The Lovers of an Old Criminal  \n",
            "41    Q580866                                       THQ  \n",
            "42        Q16                                    Canada  \n",
            "43    Q193592                               midfielder   \n",
            "44       Q155                                    Brazil  \n",
            "45   Q2628332                             Touch of Pink  \n",
            "46     Q36279                                 biography  \n",
            "47        Q96                                   Mexico   \n",
            "48      Q7432                                   species  \n",
            "49    Q193355                                blues-rock  \n",
            "50      Q4915                                Ohio River  \n",
            "51        Q30                  United States of America  \n",
            "52      Q1048                             Julius Caesar  \n",
            "53      Q3863                                  asteroid  \n",
            "54   Q1368039                                   Esparto  \n",
            "55   Q6254080                  John Radcliffe Hospital   \n",
            "56    Q169470                                 physicist  \n",
            "57        Q17                                     Japan  \n",
            "58    Q183504                                indie rock  \n",
            "59     Q24258                          Visions of Light  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P743BCFh69j-"
      },
      "source": [
        "**Creation of the corresponding lists containing the questions, the entity labels, the relation ids and the entity ids of the corresponding SimpleQuestions datasets (training, validation, test), either this dataset includes answerable and answerable questions over wikidata questions or only answerable questions over wikidata.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_entity_labels = train_dataset['entity_label'].to_list()\n",
        "validation_entity_labels = validation_dataset['entity_label'].to_list()\n",
        "test_entity_labels = test_dataset['entity_label'].to_list()\n",
        "train_entityids = train_dataset['entity_id'].to_list()\n",
        "validation_entityids = validation_dataset['entity_id'].to_list()\n",
        "test_entityids = test_dataset['entity_id'].to_list()\n",
        "train_relationids = train_dataset['relation_id'].to_list()\n",
        "validation_relationids = validation_dataset['relation_id'].to_list()\n",
        "test_relationids = test_dataset['relation_id'].to_list()\n",
        "train_questions = train_dataset['Question'].to_list()\n",
        "validation_questions = validation_dataset['Question'].to_list()\n",
        "test_questions = test_dataset['Question'].to_list()\n",
        "print(len(train_entity_labels), len(train_entityids), len(train_relationids), len(train_questions))"
      ],
      "metadata": {
        "id": "vI5FwsPC2NAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7065f286-8850-4886-85ac-56b21db6408e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34373 34373 34373 34373\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_answerable_entity_labels = train_answerable_dataset['entity_label'].to_list()\n",
        "validation_answerable_entity_labels = validation_answerable_dataset['entity_label'].to_list()\n",
        "test_answerable_entity_labels = test_answerable_dataset['entity_label'].to_list()\n",
        "train_answerable_entityids = train_answerable_dataset['entity_id'].to_list()\n",
        "validation_answerable_entityids = validation_answerable_dataset['entity_id'].to_list()\n",
        "test_answerable_entityids = test_answerable_dataset['entity_id'].to_list()\n",
        "train_answerable_relationids = train_answerable_dataset['relation_id'].to_list()\n",
        "validation_answerable_relationids = validation_answerable_dataset['relation_id'].to_list()\n",
        "test_answerable_relationids = test_answerable_dataset['relation_id'].to_list()\n",
        "train_answerable_questions = train_answerable_dataset['Question'].to_list()\n",
        "validation_answerable_questions = validation_answerable_dataset['Question'].to_list()\n",
        "test_answerable_questions = test_answerable_dataset['Question'].to_list()\n",
        "print(len(train_answerable_entity_labels), len(train_answerable_entityids), len(train_answerable_relationids), len(train_answerable_questions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkHF10zt7EA6",
        "outputId": "0383883b-5751-4fcf-a9c5-a353a31e5e9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19481 19481 19481 19481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDTORRL2jLUl"
      },
      "source": [
        "**Creation of the corresponding lists containing the questions, the entity labels, the relation ids and the entity ids of the corresponding test .txt file that includes the questions that are used in order to test QA engine.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_questions = testing_questions_list['Question'].to_list()\n",
        "testing_questions_entity_ids = testing_questions_list['entity_id'].to_list()\n",
        "testing_questions_relation_ids = testing_questions_list['relation_id'].to_list()\n",
        "testing_questions_answer_ids = testing_questions_list['answer_id'].to_list()\n",
        "testing_questions_answer_labels = testing_questions_list['answer_label'].to_list()\n",
        "print(len(testing_questions),len(testing_questions_relation_ids),len(testing_questions_entity_ids),len(testing_questions_answer_ids),len(testing_questions_answer_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDdjft-pjaio",
        "outputId": "d0a59d49-309d-4360-ae05-b0f38204db64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60 60 60 60 60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The preprocessing for each question is made by creating the function preprocessing, which takes as argument the text (in this case the question) and performs accent removal, as well as punctuation mark removal (period, question mark, exclamation mark), s removal with apostrophe('s) and comma(,) removal.Finally this function, which is shown below, returns the original text with the above mentioned processing.**"
      ],
      "metadata": {
        "id": "qck83aX4BwQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Preprocessing(text):\n",
        "    text = unidecode(text.replace(\"?\", \"\").replace(\"'s\", \"\").replace(\".\", \"\").replace(\"!\", \"\").replace(\",\", \"\"))\n",
        "    return text"
      ],
      "metadata": {
        "id": "Qoq8GhWO4FTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xuaijVb-5JP"
      },
      "source": [
        "**The maximum question length that is observed in SimpleQuestions training, validation and test dataset is found below.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Below the max questions length is found for all questions.\n",
        "quests = train_questions + validation_questions + test_questions\n",
        "print(len(quests), len(train_questions), len(validation_questions))\n",
        "# Printing concatenated list\n",
        "q_lengths = []\n",
        "for s in range(len(quests)): #padding\n",
        "    q_lengths.append(len(quests[s].split()))\n",
        "print(max(q_lengths))#Max question length"
      ],
      "metadata": {
        "id": "LyKLMtom5MlV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a305042-6f65-42bd-e65e-0b878451de28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49201 34373 4867\n",
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Below the max questions length is found for all questions.\n",
        "#quests = pd.concat([train_dataset[\"Question\"], validation_dataset[\"Question\"]], ignore_index = True)\n",
        "quests_answerable = train_answerable_questions + validation_answerable_questions + test_answerable_questions\n",
        "print(len(quests_answerable), len(train_answerable_questions), len(validation_answerable_questions))\n",
        "# Printing concatenated list\n",
        "q_lengths_answerable = []\n",
        "for s in range(len(quests_answerable)): #padding\n",
        "    q_lengths_answerable.append(len(quests_answerable[s].split()))\n",
        "print(max(q_lengths_answerable))#Max question length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c45f2a-2112-4902-fe03-d3101639251d",
        "id": "b85K-oG57a4O"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27924 19481 2821\n",
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1mRqtpMtpOj"
      },
      "source": [
        "**Installation of the library of Sentence Transformers and loading of their models.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "similarity_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "PwClVP1F1uqa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "02a85c3ee502499e91d41d18f159df37",
            "1d82205dc3d64bc191e57490a5fcbe1a",
            "ecdf9a7dfb8349bca6c34a6f923a9bc6",
            "ed0d954efc96468092fc19e0db72ae67",
            "e076269eeb6f412dba021cf05f3df594",
            "4cf3fa2c88914cab926127d0c343c1b3",
            "1c202de9b7c64a6c89075222a5d2a182",
            "3b0b989c63414b8c91e086207e7b8ad0",
            "da20e22985914cd7bce5c794235d8eb2",
            "497dee4f1f2c413fb8dae03590364db1",
            "e0c1d44401e2473caeb975908af17323",
            "f4ac190bf7444f9f90a1384e27c15f74",
            "89407f02f9f74c7f89b6c2a3d0a0144e",
            "59a6cca8f41c49dab744003f8f52ef7e",
            "d9847f205268469b94f5c7bda52c0fd8",
            "453a3c3c4666408e95b9116208e46f61",
            "4cecce0a81f340a3bdc613392376b60b",
            "3c45e902f3fa47be852de9e5a696b90b",
            "7fc3be6348eb47ac82788608d1a6f6fb",
            "cbe999c46b7f4a96a7fb7f314d3cd981",
            "7c4da38e8ed64b15a3b46764343612df",
            "9e5054dfdb044f739bbdd90aa9bfc5a3",
            "c9315e7054c34464875043a60e8125bf",
            "b1b96a5037c54d02b80471ecfedc5420",
            "2614d096a1ce4b4497cd5ad93971b5c4",
            "d6ecfa33fd9e42359e6ad86597bc2bd7",
            "cf6f49764442498084ae3915daed6a13",
            "821fe2a06e0a412788af33ede62a15b8",
            "07e18fd3ccc040f892dadbcd3ba30165",
            "9e1f13dabf484bc4841c9c8092f595dd",
            "2ac4cc7354074e17aa92e6f825ed758d",
            "2a67ad07d38f4ec8a27ef09b063b0c7d",
            "8f4ac9b6edd14032a59fc7f8056eeed3",
            "77f2a3822fdd4a6ea115eb7929a857de",
            "e5afdad084f6488aa5cdb691c208dab1",
            "e5772b9ef92946989b759571ab19cb72",
            "6dc792df2d8243349a91b464215495e0",
            "d4b9115ed3c04ffcac67173cc188b08b",
            "3bc9b11a5b3c4325b240bdfd952383f5",
            "35ab160fe48f44029e4c6367a901e8bf",
            "8162dcd14f864ce59c439e249df9c134",
            "6860149ea683451a97d0a9f10fb90bcd",
            "13663e05b0e2400e950c46aa8cde616f",
            "e0d0a96d29044bad81bbec15e6d51365",
            "1d2bb14401c94d36aad5fcf1732f0a7f",
            "d9981e75af484111b8db4e6526bfd143",
            "1e1984255e27400b9fc34bc8c1d3b055",
            "0d2bfd18e6264e5aadb18cc3e3199789",
            "ca2a9f68a80e40c88e3046d82126d45d",
            "12b9a24cbfe94d9bb29f1c4d1621a12a",
            "9dee82c36f5a49d8882dfe480b4617f7",
            "509c8e232d5b4e58b1c1a836e432be17",
            "fac1a6fbb61d41719cea984f4c8c295a",
            "ef9e4a7605f54328a19cbbcd7fc44533",
            "858ced4db8884a57964e905b7007c5f4",
            "e5346e15626d4e02ab84c5343b073863",
            "f3c33ae9ee2c4ed187b99e7db1643965",
            "40970dffd76c49a9b30cf3eb159027f3",
            "1d056f79881f48be88cd5f2886ec26b0",
            "5db4af3786804143bdd47f2afddd6af6",
            "74362e6383a24f4aac7ed4c4b4e28c57",
            "4e3c0a2b472a425d8b32cdf166ad1c00",
            "c08542712bff492dbf4ef8bffbc84baf",
            "da3dd0e16d6f48588971562793ccd3a9",
            "5658f83ba5f34e1b8a3c223ba886fcb5",
            "2d7b4db0eaa4449b80b709c79e18128c",
            "8b453eb9d6604cf2837a33579c7dd0b4",
            "76d7281927fd46e398a9870ee40a90d0",
            "200604c494c1484fa07ab30c97ac795e",
            "97a3ec985d8a4e0e8adc0ccbc3be3084",
            "ef4547afc66744e49ed7f317f847bfb6",
            "411f3ef0560342e79a6b09aba3cf8f75",
            "97930828967743ca81ab83f195f844ed",
            "1b9d60977c0b43aeb9f5f9949312a5e5",
            "e3cac1493c8e4c1993d38b6bb9cdec9b",
            "d383ae1e15ef444fb46532475d89eec2",
            "525241df4b8b4d9baa42cf78cd700f61",
            "88c5deaffe304e0d9f51fefd17707a7d",
            "74d205becaac4cbc947adfb3e359c303",
            "d7d78790b6c942b7838084e3d427c5bf",
            "eef9b53b01a944d99d7a1a97c7a953b5",
            "00121d3575bc4d369ff1077b55581539",
            "2bf060ba2ad345599cf1c2e64a76d6cf",
            "a8c6b9f3bdae42f1b3e79d03ea1e86e7",
            "042c5314658e44c09be4537538fec21b",
            "7e9855ab2f144ea18ca3811041cf92d7",
            "38a7b1473f8b40e2bdade91d874c14d7",
            "fa611c0b708c484391aab5652d2e0cd3",
            "4996c40a096e4381903ec74cf4d76601",
            "65b9a4fafd814d7caf780050cce3be49",
            "d20f28e52c444eccb1674e620b9a8096",
            "de25cf27b8ee44ebb7a695a233699c9c",
            "486c97457f1c46bdaa9eb6f4b9be7074",
            "d5af8937f55141109dd0de5a2760431f",
            "9f7f6c68b0624e11882dc6e0db880dbb",
            "f96ffdc09eb348fba7f80d8fd060a14a",
            "4908636e378f48869183a1aaefa08571",
            "039ae91111e940b38656f4c3aa90e6b5",
            "9667e61afb6d4645a0debeaecd517803",
            "9d58dd3a6a3444adbc7f391551cb2c36",
            "8d4d6c128e4444959168819ef3d86b0a",
            "1f1da9ec6448422184742a3015acd058",
            "002fe3170f0b42848866099a36e7a88d",
            "f98a8a69ef2a4bdaa48a8e8342d63484",
            "e9ad1aeebb3a4427b24138b961cc8b29",
            "0aff26835d4449489e44497ea1d8aadc",
            "7782722376724b12afd3e683f36dc235",
            "83b5e4a33d0d419f9d1e8d6b69bb7f26",
            "8ed9090b5b644de9a0f2905c40eda59d",
            "ee2621e2feca4462b86893db26b55163",
            "3835aa78818f4b62b228d9e8977480a4",
            "4a2cac23c759472d8dd1b622f35a879b",
            "e1104e2a8c244444bd22b3b964044e7d",
            "48457419cc65489c82e282af6ad091db",
            "95d82b1a4ee34ec1baa245dddb0bb1b5",
            "f1db129742794d87a798d465db8ef79f",
            "2e380ffd4b9744e2902c67ebd9d053a1",
            "3f08b11cf83d4bc8ac030b8bdbf82b00",
            "57edbb0764aa45d9b6e605e79f3be1f8",
            "66f9617499294a96988b789b3a44e383",
            "95058673750f45abb32186014fe93507"
          ]
        },
        "outputId": "83d3125b-fdb5-4eb9-a110-c2dec2bc95c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/171.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m163.8/171.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.7.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "02a85c3ee502499e91d41d18f159df37"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4ac190bf7444f9f90a1384e27c15f74"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9315e7054c34464875043a60e8125bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77f2a3822fdd4a6ea115eb7929a857de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d2bb14401c94d36aad5fcf1732f0a7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5346e15626d4e02ab84c5343b073863"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8b453eb9d6604cf2837a33579c7dd0b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88c5deaffe304e0d9f51fefd17707a7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4996c40a096e4381903ec74cf4d76601"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d58dd3a6a3444adbc7f391551cb2c36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3835aa78818f4b62b228d9e8977480a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of the relation vocabulary that includes all the unique entity ids of the SimpleQuestions training and validation dataset through function relation_vocabulary. Also the index of each unique relation id of the relation vocabulary in this vocabulary is found through the function find_relations_index.**"
      ],
      "metadata": {
        "id": "KWsXKM9ZX8st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create relation vocabulary for each question of train and validation dataset\n",
        "def relation_vocabulary(relation_column_dataset):\n",
        "  relation_vocabulary = []\n",
        "   #In order to have the unique relation ids it is important to check if an relation id is already in the relation_vocabulary\n",
        "  for relation in range(len(relation_column_dataset)):\n",
        "    g = 0\n",
        "    for i in range(len(relation_vocabulary)):\n",
        "      if relation_column_dataset[relation] != relation_vocabulary[i]: #relation is not found yet\n",
        "        g += 1\n",
        "      else:\n",
        "       continue\n",
        "    if g == len(relation_vocabulary) and relation_column_dataset[relation] not in relation_vocabulary:\n",
        "      relation_vocabulary.append(relation_column_dataset[relation]) #The relation id is not inside the relation vocabulary\n",
        "      #which has some relations already or the relation vocaulary has no relations\n",
        "  return relation_vocabulary\n",
        "\n",
        "def find_relation_index(relation_vocabulary,relation_ids_column):\n",
        "  relations_count = []\n",
        "  for relation in range(len(relation_ids_column)):\n",
        "        relations_count.append(relation_vocabulary.index(relation_ids_column[relation]))\n",
        "\n",
        "  return relations_count\n",
        "relation_ids = train_relationids + validation_relationids\n",
        "relation_answerable_ids = train_answerable_relationids + validation_answerable_relationids\n",
        "rel_vocab = relation_vocabulary(relation_ids)\n",
        "rel_answerable_vocab = relation_vocabulary(relation_answerable_ids)\n",
        "print(len(rel_vocab), rel_vocab)\n",
        "print(len(rel_answerable_vocab), rel_answerable_vocab)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_Ly38khX3NE",
        "outputId": "6e8ab074-b054-44dd-bc9e-bc73f18f95b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129 ['R272', 'R19', 'P162', 'P364', 'R276', 'R413', 'R607', 'P413', 'R136', 'P27', 'P21', 'P136', 'P738', 'R106', 'P196', 'P175', 'R175', 'R50', 'P344', 'P641', 'P19', 'P421', 'R421', 'R57', 'P170', 'R17', 'P287', 'P86', 'R58', 'R86', 'P1142', 'P20', 'P58', 'P264', 'P131', 'P106', 'P172', 'P495', 'P150', 'R131', 'R509', 'P119', 'R1303', 'P50', 'R40', 'P1303', 'P61', 'R172', 'P57', 'P140', 'P179', 'R344', 'P1040', 'P509', 'P138', 'P397', 'P407', 'P398', 'P272', 'R264', 'P403', 'P31', 'P607', 'R287', 'R162', 'R641', 'R404', 'P1408', 'R178', 'R279', 'P123', 'P59', 'P40', 'P276', 'P1431', 'P178', 'P737', 'R179', 'P17', 'P171', 'R170', 'P144', 'P112', 'R105', 'R676', 'R59', 'P113', 'P155', 'P289', 'R149', 'P404', 'P710', 'P676', 'P149', 'R1040', 'R177', 'R119', 'P279', 'R21', 'R112', 'R31', 'R138', 'P53', 'R123', 'P65', 'P156', 'P177', 'R144', 'R1431', 'P81', 'P115', 'P105', 'P800', 'R171', 'P1029', 'R115', 'P84', 'R1142', 'P376', 'R376', 'P1308', 'P826', 'R161', 'R289', 'R176', 'P189', 'P176', 'P361', 'R361']\n",
            "125 ['R19', 'P364', 'R276', 'R413', 'P413', 'R136', 'P27', 'P21', 'R106', 'P196', 'P175', 'R175', 'R50', 'P344', 'P136', 'P641', 'P19', 'P421', 'R57', 'P170', 'R17', 'P86', 'R58', 'R86', 'P1142', 'P58', 'P131', 'P495', 'P150', 'R131', 'P119', 'R1303', 'P50', 'R40', 'P61', 'R172', 'P264', 'P57', 'P179', 'P509', 'R509', 'P20', 'P138', 'P397', 'R344', 'P106', 'P272', 'P403', 'P31', 'P607', 'P407', 'P140', 'R162', 'R641', 'R404', 'P172', 'R178', 'R421', 'P123', 'P59', 'P40', 'P276', 'P178', 'R272', 'P737', 'R179', 'P398', 'P17', 'P1303', 'P144', 'P112', 'R170', 'R105', 'R59', 'P113', 'R607', 'P155', 'P162', 'R149', 'P404', 'R1040', 'R177', 'P710', 'P1408', 'R119', 'R21', 'R112', 'R138', 'P676', 'R123', 'P149', 'R264', 'P65', 'P177', 'R144', 'P53', 'R31', 'R287', 'P115', 'P105', 'P1040', 'P156', 'P289', 'R171', 'P1029', 'R115', 'P171', 'R1431', 'P1431', 'P376', 'R676', 'R1142', 'P84', 'R376', 'P826', 'R161', 'P287', 'P81', 'P800', 'P279', 'R176', 'R289', 'P189', 'P176', 'R279']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z88qZ4F0Yk1A"
      },
      "source": [
        "**Custom function for the cosine similarity metric between two encodings.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VDSj-g6T159"
      },
      "outputs": [],
      "source": [
        "# Custom function for cosine similarity\n",
        "def cosine_similarity(encoding1, encoding2):\n",
        "  return np.dot(encoding1, encoding2) / (np.linalg.norm(encoding1) * np.linalg.norm(encoding2)) if np.linalg.norm(encoding1) * np.linalg.norm(encoding2) != 0 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function that contributes to the preservation of the reproducibility.**"
      ],
      "metadata": {
        "id": "RByge7zW_Xd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To preserve reproducibility\n",
        "SEED = 42\n",
        "def set_seed(SEED):\n",
        " random.seed(SEED)# Set python seed for custom operators.\n",
        " torch.manual_seed(SEED)\n",
        " np.random.seed(SEED)\n",
        " torch.cuda.manual_seed_all(SEED)\n",
        " torch.backends.cudnn.benchmark = False\n",
        " torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "stzqiIG-29VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QcZw8-y_gqz"
      },
      "source": [
        "****Construction and initialization of the neural network for the prediction of the relation for each question.****"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0SM-IwilDWm"
      },
      "outputs": [],
      "source": [
        "class BertRelationsClassifier(nn.Module):\n",
        "  def __init__(self, activation, dropout_prob, rel_vocab_len):\n",
        "    super(BertRelationsClassifier, self).__init__()\n",
        "    activations = {\n",
        "        \"ELU\" : nn.ELU,\n",
        "        \"LeakyReLU\"    : nn.LeakyReLU,\n",
        "        \"Softplus\"     : nn.Softplus,\n",
        "        \"Tanhshrink\"     : nn.Tanhshrink\n",
        " }\n",
        "    self.bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "    self.rel_vocab_len = rel_vocab_len\n",
        "    self.device = device\n",
        "    self.fc = nn.Linear(768, self.rel_vocab_len , device = self.device)\n",
        "    self.activation_type = activation\n",
        "    self.activation = activations[self.activation_type]()\n",
        "    self.dropout_probability = dropout_prob\n",
        "    self.dropout = nn.Dropout(self.dropout_probability)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "        out = self.bert_model(input_ids, attention_mask)\n",
        "        out = self.fc(out[1])#CLS token-pooled output\n",
        "        out = self.activation(out)\n",
        "        out = self.dropout(out)\n",
        "        out = self.softmax(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2II_6L1geGnJ"
      },
      "source": [
        "****Construction and initialization of the neural network for the prediction of the entity span start and entity span end indexes for each question.****"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YPHSd9mVj0U"
      },
      "outputs": [],
      "source": [
        "class BertEntitySpanClassifier(nn.Module):\n",
        "  def __init__(self, activation, dropout_prob, max_quest_len):\n",
        "    super(BertEntitySpanClassifier, self).__init__()\n",
        "    self.bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "# Whether the model returns all hidden-states.\n",
        "    activations = {\n",
        "        \"ELU\" : nn.ELU,\n",
        "        \"LeakyReLU\"    : nn.LeakyReLU,\n",
        "        \"Softplus\"     : nn.Softplus,\n",
        "        \"Tanhshrink\"     : nn.Tanhshrink\n",
        " }\n",
        "    self.activation_type = activation\n",
        "    self.activation = activations[self.activation_type]()\n",
        "    self.max_length = max_quest_len\n",
        "    self.dropout_probability = dropout_prob\n",
        "    self.start_head = nn.Sequential(\n",
        "          nn.Linear(768, self.max_length),\n",
        "          self.activation,\n",
        "          nn.Dropout(p=self.dropout_probability),\n",
        "          nn.Flatten(),\n",
        "          nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "    self.end_head = nn.Sequential(\n",
        "          nn.Linear(768, self.max_length),\n",
        "          self.activation,\n",
        "          nn.Dropout(p=self.dropout_probability),\n",
        "          nn.Flatten(),\n",
        "          nn.Softmax(dim=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, input_ids, att_mask):\n",
        "    out = self.bert_model(input_ids, att_mask)\n",
        "    out = out[0]\n",
        "    out_start = self.start_head(out)\n",
        "    out_end = self.end_head(out)\n",
        "    return out_start , out_end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQFFdCrOdvao"
      },
      "source": [
        "**Loading of the Transformers BERT tokenizer BertTokenizerFast.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "ejSVRyIO1jC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The SPARQLWrapper library is downloaded, which contributes to the generation of SPARQL queries, in order to find the entity labels.**"
      ],
      "metadata": {
        "id": "hFJkXmdTAIgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sparqlwrapper\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON, CSV\n",
        "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent= \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1]))"
      ],
      "metadata": {
        "id": "dkOBqNsuXVf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a162f7a5-61c9-4f61-f52b-8d1e9c23cfaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sparqlwrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting rdflib>=6.1.1 (from sparqlwrapper)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/531.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m522.2/531.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib>=6.1.1->sparqlwrapper)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=6.1.1->sparqlwrapper) (3.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->sparqlwrapper) (1.16.0)\n",
            "Installing collected packages: isodate, rdflib, sparqlwrapper\n",
            "Successfully installed isodate-0.6.1 rdflib-7.0.0 sparqlwrapper-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KXA4d0qn7U-"
      },
      "source": [
        "**QUESTION ANSEWRING ENGINE**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I create the get\\_entity\\_id function which involves creating a SPARQL query that, given an entity label, finds and extracts its corresponding entity id.**"
      ],
      "metadata": {
        "id": "YU52zZL6Adxw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHhZ84c1qiK6"
      },
      "outputs": [],
      "source": [
        "def get_entity_id(entity_label):\n",
        "    sparql = SPARQLWrapper('https://query.wikidata.org/sparql', agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1]))\n",
        "    sparql.setQuery(\"\"\"\n",
        "    SELECT distinct ?item ?itemLabel ?itemDescription\n",
        "    WHERE\n",
        "    {\n",
        "     ?item ?label \"%s\"@en.\n",
        "     ?article schema:about ?item .\n",
        "     ?article schema:inLanguage \"en\" .\n",
        "     ?article schema:isPartOf <https://en.wikipedia.org/>.\n",
        "     SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
        "    }\"\"\"  % (entity_label.title()))\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    results = sparql.query().convert()\n",
        "    entityids = []\n",
        "    for result in results[\"results\"][\"bindings\"]:\n",
        "        entityids.append(result[\"item\"][\"value\"].split(sep='/')[-1])\n",
        "    return entityids"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of two dictionaries, where the first one named Endict will have as keys the entity labels of the SimpleQuestions training and validation dataset and as values the corresponding entity ids of the SimpleQuestions training and validation dataset and the other one named quests will have as keys the entity labels of the SimpleQuestions training and validation dataset and as values the corresponding encoding vectors from the similarity model of Sentence Transformer for each entity label of the SimpleQuestions training and validation dataset.**"
      ],
      "metadata": {
        "id": "4zih63V2sMkR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tICJ39Qq02jJ"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary with entity labels as keys and entity_ids as values\n",
        "entity_ids = train_entityids + validation_entityids + test_entityids\n",
        "entity_labels = train_entity_labels + validation_entity_labels + test_entity_labels\n",
        "Endict = {}\n",
        "for h in range(len(entity_ids)):\n",
        "  label = entity_labels[h]\n",
        "  id = entity_ids[h]\n",
        "  Endict[label] = id\n",
        "entities = list(Endict.keys())\n",
        "quests = {}\n",
        "# Create a dictionary with Sentence transfomer embeddings for each entity label.\n",
        "for entity_label, id in Endict.items():\n",
        "    quest = similarity_model.encode(entity_label)\n",
        "    quests[entity_label] = quest"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I create the function question\\_encoding that takes as arguments the question and the corresponding tokenizer, in this case BertTokenizerFast.\n",
        "Finally the function question\\_encoding encodes the given question through the command tokenizer.encode\\_plus(). Also this function calls the Preprocessing function in order to make the preprocessing of each question (described in the previous cell with text). The ids and masks resulting from the corresponding encoding are returned.**\n",
        "\n",
        "**Creation of the function find\\_closest\\_match that takes as arguments the entity label, the dictionary Endict with keys the entity labels and values the entity ids, a list of all keys of Endict, and if Sentence Transformer library is used the dictionary entity\\_quests with keys the entity labels and values the encodings obtained for each entity label through the pretrained similarity model of Sentence Transformer.**\n",
        "\n",
        "**Through this function the entity id for the entity of a question is found either through spacy library or cosine similarity metric or jaccard similarity metric between the entity label of a user question and the list of Endict keys, i.e the entity labels of the SimpleQuestions training and validation dataset (or the corresponding encodings if the Sentence Transformer similarity model is used) and the more similar entity label is returned, if the entity id for the entity of a query cannot be found through the get\\_entity\\_id function. In this case the entity id of the entity that has the best cosine similarity score with the entity for which we are looking for the entity id is returned, if available**"
      ],
      "metadata": {
        "id": "OcL-FvuACYC9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip98QfoDBgGo"
      },
      "outputs": [],
      "source": [
        "def question_encoding(question,tokenizer):\n",
        "    question = Preprocessing(question)\n",
        "    ids = []\n",
        "    mask = []\n",
        "    # Encode the question\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        text = question,\n",
        "        return_attention_mask=True,\n",
        "        add_special_tokens=False\n",
        "    )\n",
        "\n",
        "    ids.append(encoding['input_ids'])\n",
        "    mask.append(encoding['attention_mask'])\n",
        "\n",
        "    return torch.tensor(ids), torch.tensor(mask)\n",
        "\n",
        "\n",
        "\n",
        "def find_closest_match(entity_label, Endict, entities, quests, similarity_model):\n",
        "      ent = similarity_model.encode(entity_label)\n",
        "      similarity_scores = {}\n",
        "      # Find similarity scores between entity and each entity in dictionary\n",
        "      for ent_label, Ent in quests.items():\n",
        "          similarity_scores[ent_label] = cosine_similarity(ent,Ent)\n",
        "      Q = dict(sorted(similarity_scores.items(), key = lambda x: x[1], reverse = True))\n",
        "      EntitiesList = [key for key in Q]\n",
        "      if EntitiesList != []:\n",
        "        entityid = Endict[EntitiesList[0]]\n",
        "        print(\"Cosine similarity metric is used!\")\n",
        "        return entityid\n",
        "      else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of functions to predict entity span start index, entity span end index and relation index. The function for predicting the entity span start index and entity span end index takes as arguments the ids and the mask resulting from the encoding of the question via the question\\_encoding function, the aforementioned dictionaries Endict and entity\\_quests, the pretrained model of the Sentence Transformer similarity model, the entity\\_model\\_path, i.e. the path where the best parameters for the best predictive model of entity span start index and entity span end index are stored, the activation function for the best predictive model of entity start index and entity end index, the dropout probability, dropout\\_prob and the SEED number which helps to have the same and reproducible answers. The predictions for entity span start index and entity span end index, are returned by this function.**\n",
        "\n",
        "**Also in the case that for a QA engine i do not use the Sentence Transformers similarity model, i.e for the QA engine include either only spacy library or jaccard similarity metric, the function entity\\_prediction does not have the dictionary quests and the Sentence Transformers similarity model as arguments.**\n"
      ],
      "metadata": {
        "id": "MhvWXX6XC12d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gljy3RHN2jr0"
      },
      "outputs": [],
      "source": [
        "def entity_prediction(ids, mask, Endict, entities, tokenizer, quests, similarity_model, max_question_length, activation, entity_model_path, dropout_prob, SEED):\n",
        "    #Loading the best model for entity span prediction\n",
        "    set_seed(SEED)\n",
        "    entity_model = BertEntitySpanClassifier(activation, dropout_prob, max_question_length).to(device)\n",
        "    entity_model.load_state_dict(torch.load(entity_model_path))\n",
        "    entity_model.eval()\n",
        "    y_start, y_end = entity_model(ids, mask)\n",
        "    y_pred_start = torch.argmax(y_start, dim=1)\n",
        "    y_pred_end = torch.argmax(y_end, dim=1)\n",
        "    entity = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(ids[0][y_pred_start.item():y_pred_end.item()+1]))\n",
        "    print(entity)\n",
        "    if entity in Endict:\n",
        "        return Endict[entity]\n",
        "    else:\n",
        "        entityid = get_entity_id(entity)\n",
        "\n",
        "        if entityid != []:\n",
        "            return entityid[0]\n",
        "    # Fallback to the most similar from the dictionary\n",
        "    return find_closest_match(entity, Endict, entities, quests, similarity_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correspondingly the function for the prediction of relation index, takes as arguments the ids and mask resulting from the encoding of the question through the question\\_encoding function, the length of the relation vocabulary, the relation\\_model\\_path, i.e. the path where the best parameters for the best prediction model of relation index are stored, the activation function of the best prediction model of relation index prediction,the dropout probability, dropout\\_prob and the SEED number. The prediction for the relation index gives through the relation vocabulary which relation id is in the question. This relation index is returned.**"
      ],
      "metadata": {
        "id": "Uo65lfKdC99O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relation_prediction(ids, mask, rel_vocab, rel_vocab_len, activation_relation, dropout_prob, relation_model_path, SEED):\n",
        "    set_seed(SEED)\n",
        "    relation_model = BertRelationsClassifier(activation_relation, dropout_prob, rel_vocab_len).to(device)\n",
        "    relation_model.load_state_dict(torch.load(relation_model_path))\n",
        "    relation_model.eval()\n",
        "    rel = relation_model(ids, mask).to(device)\n",
        "    rel_pred = torch.argmax(rel, dim=1)\n",
        "    relation = rel_vocab[rel_pred]\n",
        "    return relation"
      ],
      "metadata": {
        "id": "oQs8hjvDj4tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To extract the final answer or answers for each question, i create the function named answer which takes as arguments the question itself, the dictionaries Endict, the dictionary entity\\_quests if the Sentence Transformer similarity model is used, the tokenizer BertTokenizerFast, the pretrained similarity model of the Sentence Transformer if the cosine similarity metric is used, the entity\\_model\\_path, i.e. the path where the best parameters for the each one of the models created of entity start index and entity end index are stored, the relation vocabulary, the relation\\_model\\_path, i.e. the path where the best parameters for the best prediction model of the relation index are stored, the activation function of the best prediction model  of the relation index, the activation functions of the best prediction models of the entity start index and entity end index  and the dropout probability, dropout\\_prob.**\n",
        "\n",
        "**Also the answer function calls the aforementioned function question\\_encoding in order to encode the question and get the ids and the mask that are needed for the functions entity\\_prediction and relation\\_prediction, which are also called from the function answer. This function returns a boolean value which shows if a question has an totally correct answer and also a boolean value which shows if a question has answer(s) either correct or incorrect or both of them, regardless if these answers include the expected answer of a question.  Additionally the answers of this question, with the limitation of maximum 15 answers, are printed.**"
      ],
      "metadata": {
        "id": "3VzGDzDoDFB7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMpEcnd1Bkpe"
      },
      "outputs": [],
      "source": [
        "def get_answer(entityid, relation):\n",
        "    sparql = SPARQLWrapper('https://query.wikidata.org/sparql', agent = \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1]))\n",
        "    if entityid is not None:\n",
        "     if (relation[0] == 'P'):\n",
        "        query = \"\"\"\n",
        "        SELECT ?item ?itemLabel\n",
        "        WHERE\n",
        "        {\n",
        "          wd:\"\"\" + entityid + \"\"\" wdt:\"\"\" + relation + \"\"\" ?item.\n",
        "          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
        "        }\"\"\"\n",
        "     else:\n",
        "        relation = relation.replace('R', 'P')\n",
        "        query = \"\"\"\n",
        "        SELECT ?item ?itemLabel\n",
        "        WHERE\n",
        "        {\n",
        "          ?item wdt:\"\"\" + relation + \"\"\" wd:\"\"\" + entityid + \"\"\".\n",
        "          SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n",
        "        }\"\"\"\n",
        "     sparql.setQuery(query)\n",
        "     sparql.setReturnFormat(JSON)\n",
        "     results = sparql.query().convert()\n",
        "     return results[\"results\"][\"bindings\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2kdKj6XkG2F"
      },
      "outputs": [],
      "source": [
        "def answer(question, Endict, entities, rel_vocab, rel_vocab_len, tokenizer, quests, similarity_model, max_question_length, activation_relation, activation_entity, relation_model_path, entity_model_path, dropout_prob, SEED, real_answer, real_entity_id, real_relation_id):\n",
        "    #Boolean variables that denotes if a question is answered\n",
        "    question_answered = 0\n",
        "    question_correct_answered = 0\n",
        "    #Encode question\n",
        "    ids, mask = question_encoding(question, tokenizer)\n",
        "    ids = ids.to(device)\n",
        "    mask = mask.to(device)\n",
        "    # Loading the best model for relation prediction and predict relation id\n",
        "    relation = relation_prediction(ids, mask, rel_vocab, rel_vocab_len, activation_relation, dropout_prob, relation_model_path, SEED)\n",
        "    print(relation)\n",
        "    # Loading the best model for entity span prediction and predict entity id\n",
        "    entity = entity_prediction(ids, mask, Endict, entities, tokenizer, quests, similarity_model, max_question_length, activation_entity, entity_model_path, dropout_prob, SEED)\n",
        "    print(entity)\n",
        "    real_ans = similarity_model.encode(real_answer)\n",
        "    if entity == None:\n",
        "        print(\"Sorry, no answer available\")\n",
        "    else:\n",
        "        answers = get_answer(entity, relation)\n",
        "        if answers == []:\n",
        "          print(\"Sorry, no answer available\")\n",
        "        else:\n",
        "          model_answers = []\n",
        "          for iter, answer in enumerate(answers):\n",
        "             if iter == 15:\n",
        "                break\n",
        "             model_answers.append(answer[\"itemLabel\"][\"value\"])\n",
        "          answer_similarity_scores = {}\n",
        "          for iter, answer in enumerate(model_answers):\n",
        "              ans = similarity_model.encode(answer)\n",
        "              answer_similarity_scores[answer] = cosine_similarity(real_ans,ans)\n",
        "          Answers_sorted = dict(sorted(answer_similarity_scores.items(), key = lambda x: x[1], reverse = True))\n",
        "          best_similarity_scores = list(Answers_sorted.values())\n",
        "          best_answers_sorted = list(Answers_sorted.keys())\n",
        "          # Print the answers occured from best model parameters\n",
        "          # and the similarity scores of each answer with the expected answer\n",
        "          for sorted_answer in range(len(best_answers_sorted)):\n",
        "            print('answer: ', best_answers_sorted[sorted_answer],',','similarity score with the expected answer: {:.2f}'.format(best_similarity_scores[sorted_answer]))\n",
        "          if best_similarity_scores != []:\n",
        "            min_similarity_answer_score = min(best_similarity_scores)\n",
        "            max_similarity_answer_score = max(best_similarity_scores)\n",
        "          if entity != real_entity_id and relation != real_relation_id:\n",
        "             print(\"The question is not answered correctly!\")\n",
        "          elif entity == real_entity_id and relation == real_relation_id:\n",
        "            if (max_similarity_answer_score > 0.8 and len(best_answers_sorted) == 1) or (max_similarity_answer_score > 0.8 and min_similarity_answer_score > 0.05 and len(best_answers_sorted) > 1):\n",
        "             question_correct_answered = 1\n",
        "             print(\"The question is answered correctly!\")\n",
        "            else:\n",
        "             question_answered = 1\n",
        "             print(\"The question is answered with either only correct answers or only incorrect answers or with both of them,\\nwhich are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\\nregardless if the expected answer is one of the possible correct answers or not!\")\n",
        "          else:\n",
        "            if (max_similarity_answer_score > 0.8 and len(best_answers_sorted) == 1) or (max_similarity_answer_score > 0.8 and min_similarity_answer_score > 0.05 and len(best_answers_sorted) > 1):\n",
        "             question_correct_answered = 1\n",
        "             print(\"The question is answered correctly, although either entity id or relation id is not predicted correctly!\")\n",
        "            else:\n",
        "             question_answered = 1\n",
        "             print(\"The question is answered with either only correct answers or only incorrect answers or with both of them,\\nwhich are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\\nregardless if the expected answer is one of the possible correct answers or not!\")\n",
        "    return question_correct_answered, question_answered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6rqxFWdDdKe"
      },
      "source": [
        "**Question Answering engine for all the questions (answerable, non-answerable over wikidata), with the best papameters for each methodology.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e85f69-f0f3-46e9-a14c-b95fdac0eef9",
        "id": "EyP63RgAIzy0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the question answering engine. Type exit to quit\n",
            "Which home is an example of italianate architecture?\n",
            "R149\n",
            "italianate architecture\n",
            "Cosine similarity metric is used!\n",
            "Q615196\n",
            "answer:  Fairfield House , similarity score with the expected answer: 0.46\n",
            "answer:  Osborne House , similarity score with the expected answer: 0.41\n",
            "answer:  Hugh Glenn House , similarity score with the expected answer: 0.40\n",
            "answer:  Houses at 37–47 North Fifth Street , similarity score with the expected answer: 0.38\n",
            "answer:  Chatsworth House , similarity score with the expected answer: 0.37\n",
            "answer:  Royal Albert Hall , similarity score with the expected answer: 0.35\n",
            "answer:  Campbell-Rumsey House , similarity score with the expected answer: 0.34\n",
            "answer:  Casa Rosada , similarity score with the expected answer: 0.30\n",
            "answer:  Robinson-Schwenn Building , similarity score with the expected answer: 0.26\n",
            "answer:  Lower East Side Tenement Museum , similarity score with the expected answer: 0.21\n",
            "answer:  Criterion Hotel , similarity score with the expected answer: 0.20\n",
            "answer:  Palacio de los Leones , similarity score with the expected answer: 0.18\n",
            "answer:  Houghton County Courthouse , similarity score with the expected answer: 0.18\n",
            "answer:  Balch Hotel , similarity score with the expected answer: 0.16\n",
            "answer:  Tweed Courthouse , similarity score with the expected answer: 0.15\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what type of object is 25049 christofnorn\n",
            "P31\n",
            "25049 christofnorn\n",
            "Q1753907\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which person was born in liverpool?\n",
            "R19\n",
            "liverpool\n",
            "Q24826\n",
            "answer:  Ringo Starr , similarity score with the expected answer: 1.00\n",
            "answer:  Keith Newton , similarity score with the expected answer: 0.38\n",
            "answer:  Miles Jackson-Lipkin , similarity score with the expected answer: 0.38\n",
            "answer:  Toni Duggan , similarity score with the expected answer: 0.34\n",
            "answer:  Simon Rattle , similarity score with the expected answer: 0.32\n",
            "answer:  Kevin Nolan , similarity score with the expected answer: 0.31\n",
            "answer:  Adam F , similarity score with the expected answer: 0.30\n",
            "answer:  Richard Laurence Millington Synge , similarity score with the expected answer: 0.28\n",
            "answer:  David Johnson , similarity score with the expected answer: 0.28\n",
            "answer:  David Weatherall , similarity score with the expected answer: 0.28\n",
            "answer:  James Heneghan , similarity score with the expected answer: 0.26\n",
            "answer:  Adam Morgan , similarity score with the expected answer: 0.22\n",
            "answer:  William Ewart Gladstone , similarity score with the expected answer: 0.22\n",
            "answer:  Gertrud Luckner , similarity score with the expected answer: 0.20\n",
            "answer:  Zarqa Nawaz , similarity score with the expected answer: 0.14\n",
            "The question is answered correctly!\n",
            "What film genre is twilight considered to be?\n",
            "P136\n",
            "twilight\n",
            "Q44523\n",
            "answer:  romantic fiction , similarity score with the expected answer: 0.71\n",
            "answer:  young adult fiction , similarity score with the expected answer: 0.49\n",
            "answer:  vampire fiction , similarity score with the expected answer: 0.47\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which type of film is the bitter tea of general yen?\n",
            "P136\n",
            "the bitter tea of general yen\n",
            "Cosine similarity metric is used!\n",
            "Q568239\n",
            "answer:  drama film , similarity score with the expected answer: 1.00\n",
            "answer:  film based on literature , similarity score with the expected answer: 0.66\n",
            "answer:  romance film , similarity score with the expected answer: 0.65\n",
            "The question is answered correctly!\n",
            "What is the gender of Athina Maximou\n",
            "P21\n",
            "athina maximou\n",
            "Cosine similarity metric is used!\n",
            "Q757820\n",
            "answer:  male , similarity score with the expected answer: 0.73\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Name an Rolling Stones album\n",
            "R175\n",
            "rolling stones\n",
            "Q11036\n",
            "answer:  Metamorphosis , similarity score with the expected answer: 1.00\n",
            "answer:  Heart of Stone , similarity score with the expected answer: 0.29\n",
            "answer:  Flowers , similarity score with the expected answer: 0.25\n",
            "answer:  Through the Past, Darkly (Big Hits Vol. 2) , similarity score with the expected answer: 0.22\n",
            "answer:  The Last Time , similarity score with the expected answer: 0.15\n",
            "answer:  GRRR! , similarity score with the expected answer: 0.14\n",
            "answer:  More Hot Rocks , similarity score with the expected answer: 0.14\n",
            "answer:  (I Can't Get No) Satisfaction , similarity score with the expected answer: 0.13\n",
            "answer:  Jump Back: The Best of The Rolling Stones , similarity score with the expected answer: 0.13\n",
            "answer:  Live Licks , similarity score with the expected answer: 0.13\n",
            "answer:  Angie , similarity score with the expected answer: 0.12\n",
            "answer:  Rarities 1971–2003 , similarity score with the expected answer: 0.11\n",
            "answer:  Sucking in the Seventies , similarity score with the expected answer: 0.09\n",
            "answer:  No Security , similarity score with the expected answer: 0.06\n",
            "answer:  Fingerprint File , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Who directed woody meets davy crewcut\n",
            "P57\n",
            "woody meets davy crewcut\n",
            "Q8033685\n",
            "answer:  Alex Lovy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "who was the first NSW female Minister of Education died from cancer\n",
            "R509\n",
            "from cancer\n",
            "Cosine similarity metric is used!\n",
            "Q12078\n",
            "answer:  Kathleen Lonsdale , similarity score with the expected answer: 0.46\n",
            "answer:  Jude Milhon , similarity score with the expected answer: 0.39\n",
            "answer:  Ivory Joe Hunter , similarity score with the expected answer: 0.36\n",
            "answer:  Ivo Lapenna , similarity score with the expected answer: 0.33\n",
            "answer:  Henriette Avram , similarity score with the expected answer: 0.31\n",
            "answer:  Danielle Bunten Berry , similarity score with the expected answer: 0.29\n",
            "answer:  Georges Brassens , similarity score with the expected answer: 0.28\n",
            "answer:  Harry Mulisch , similarity score with the expected answer: 0.28\n",
            "answer:  Marcel Doret , similarity score with the expected answer: 0.28\n",
            "answer:  Juan Antonio Rios , similarity score with the expected answer: 0.26\n",
            "answer:  Michel Rocard , similarity score with the expected answer: 0.24\n",
            "answer:  Robert Mugabe , similarity score with the expected answer: 0.23\n",
            "answer:  Yann-Fañch Kemener , similarity score with the expected answer: 0.12\n",
            "answer:  Pierre Desproges , similarity score with the expected answer: 0.09\n",
            "answer:  Elder Paisios of Mount Athos , similarity score with the expected answer: 0.00\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What position does denis shcherbak play\n",
            "P413\n",
            "denis shcherbak\n",
            "Q4528782\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does the show un refugio para el amor originate from\n",
            "P495\n",
            "un refugio para el amor\n",
            "Cosine similarity metric is used!\n",
            "Q1068093\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what alternative rock band from Chicago is the author of of the blue colour of the sky\n",
            "R136\n",
            "alternative rock band from chicago\n",
            "Cosine similarity metric is used!\n",
            "Q11366\n",
            "answer:  Ride , similarity score with the expected answer: 0.26\n",
            "answer:  Howl , similarity score with the expected answer: 0.22\n",
            "answer:  Linkin Park , similarity score with the expected answer: 0.21\n",
            "answer:  Red Hot Chili Peppers , similarity score with the expected answer: 0.18\n",
            "answer:  Tame Impala , similarity score with the expected answer: 0.18\n",
            "answer:  Coheed and Cambria , similarity score with the expected answer: 0.17\n",
            "answer:  Mark Hoppus , similarity score with the expected answer: 0.15\n",
            "answer:  Black Francis , similarity score with the expected answer: 0.14\n",
            "answer:  Birds of Tokyo , similarity score with the expected answer: 0.12\n",
            "answer:  U2 , similarity score with the expected answer: 0.09\n",
            "answer:  David Bowie , similarity score with the expected answer: 0.06\n",
            "answer:  Neil Young , similarity score with the expected answer: 0.06\n",
            "answer:  Tom DeLonge , similarity score with the expected answer: 0.04\n",
            "answer:  Kurt Cobain , similarity score with the expected answer: 0.04\n",
            "answer:  Kevin Rudolf , similarity score with the expected answer: 0.03\n",
            "The question is not answered correctly!\n",
            "who is the artist that performed on the album sample and hold: attack decay sustain release?\n",
            "P175\n",
            "sample and hold : attack\n",
            "Cosine similarity metric is used!\n",
            "Q7410135\n",
            "answer:  Simian Mobile Disco , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "where john brewster jr. was born\n",
            "P19\n",
            "john brewster jr\n",
            "Cosine similarity metric is used!\n",
            "Q6223118\n",
            "answer:  Hampton , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a multiplayer game?\n",
            "R136\n",
            "multiplayer game\n",
            "Cosine similarity metric is used!\n",
            "Q6895044\n",
            "answer:  Wings 2 , similarity score with the expected answer: 0.29\n",
            "answer:  Ariokan , similarity score with the expected answer: 0.15\n",
            "answer:  NearGlobal , similarity score with the expected answer: 0.06\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which company produced hot enough for june\n",
            "P272\n",
            "hot enough for june\n",
            "Cosine similarity metric is used!\n",
            "Q12124859\n",
            "answer:  Rank Organisation , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "is jose figueroa alcorta from argentina or costa rica\n",
            "P27\n",
            "jose figueroa alcorta\n",
            "Q442729\n",
            "answer:  Argentina , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What kind of game is microsoft international soccer 2000\n",
            "P136\n",
            "microsoft international soccer 2000\n",
            "Q3312381\n",
            "answer:  association football video game , similarity score with the expected answer: 0.81\n",
            "The question is answered correctly!\n",
            "who is the composer of the song liar?\n",
            "P86\n",
            "liar\n",
            "Q124707535\n",
            "Sorry, no answer available\n",
            "Joshua Kimmich is member of which sports team?\n",
            "P1303\n",
            "joshua kimmich\n",
            "Q13865408\n",
            "Sorry, no answer available\n",
            "What is the name of a folk rock singer (or group)?\n",
            "R136\n",
            "folk rock\n",
            "Q186472\n",
            "answer:  Neil Young , similarity score with the expected answer: 1.00\n",
            "answer:  Paul Simon , similarity score with the expected answer: 0.53\n",
            "answer:  Bob Dylan , similarity score with the expected answer: 0.48\n",
            "answer:  Alan Stivell , similarity score with the expected answer: 0.44\n",
            "answer:  Leonard Cohen , similarity score with the expected answer: 0.44\n",
            "answer:  Marcus Mumford , similarity score with the expected answer: 0.39\n",
            "answer:  Amy Macdonald , similarity score with the expected answer: 0.37\n",
            "answer:  George Harrison , similarity score with the expected answer: 0.36\n",
            "answer:  The Beatles , similarity score with the expected answer: 0.31\n",
            "answer:  Led Zeppelin , similarity score with the expected answer: 0.28\n",
            "answer:  Cher , similarity score with the expected answer: 0.22\n",
            "answer:  Tri Yann , similarity score with the expected answer: 0.22\n",
            "answer:  Denez Prigent , similarity score with the expected answer: 0.16\n",
            "answer:  Tsvety , similarity score with the expected answer: 0.10\n",
            "answer:  Iļģi , similarity score with the expected answer: 0.06\n",
            "The question is answered correctly!\n",
            "Who was born in dakar?\n",
            "R19\n",
            "dakar\n",
            "Q181336\n",
            "Sorry, no answer available\n",
            "where did edward i. edwards died\n",
            "P20\n",
            "edward i edwards\n",
            "Cosine similarity metric is used!\n",
            "Q436902\n",
            "answer:  Jersey City , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the sex of david swift?\n",
            "P21\n",
            "david swift\n",
            "Q5240208\n",
            "answer:  male , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What language is mission to caracas written in\n",
            "P364\n",
            "mission to caracas\n",
            "Cosine similarity metric is used!\n",
            "Q6878840\n",
            "answer:  French , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what genre is the album why is there air?\n",
            "P136\n",
            "why is there air\n",
            "Cosine similarity metric is used!\n",
            "Q7997809\n",
            "answer:  stand-up comedy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is chad mustard's nationality\n",
            "P27\n",
            "chad mustard\n",
            "Q5066318\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is an instrument played by carl jackson\n",
            "P1303\n",
            "carl jackson\n",
            "Q5040368\n",
            "answer:  guitar , similarity score with the expected answer: 1.00\n",
            "answer:  mandolin , similarity score with the expected answer: 0.62\n",
            "answer:  banjo , similarity score with the expected answer: 0.57\n",
            "The question is answered correctly!\n",
            "Which is Aristotle Onassis profession?\n",
            "P106\n",
            "aristotle onassis\n",
            "Q180455\n",
            "answer:  ship-owner , similarity score with the expected answer: 1.00\n",
            "answer:  businessperson , similarity score with the expected answer: 0.45\n",
            "answer:  entrepreneur , similarity score with the expected answer: 0.33\n",
            "The question is answered correctly!\n",
            "what genre of music does bo diddley play?\n",
            "P136\n",
            "bo diddley\n",
            "Q10431795\n",
            "Sorry, no answer available\n",
            "Which genre of music was the album duck rock labeled?\n",
            "P136\n",
            "duck rock\n",
            "Q910692\n",
            "answer:  new wave , similarity score with the expected answer: 1.00\n",
            "answer:  rock music , similarity score with the expected answer: 0.27\n",
            "answer:  hip hop music , similarity score with the expected answer: 0.16\n",
            "The question is answered correctly!\n",
            "what is Michael Ballack's country of nationality\n",
            "P27\n",
            "michael ballack\n",
            "Q11948\n",
            "answer:  Germany , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what football position does dorin dickerson play at?\n",
            "P413\n",
            "dorin dickerson\n",
            "Q3037050\n",
            "answer:  wide receiver , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country is purple people eater filmed in?\n",
            "P495\n",
            "purple people eater\n",
            "Q3410974\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "idris phillips follows this major religion.\n",
            "P140\n",
            "idris phillips\n",
            "Q16192877\n",
            "answer:  Islam , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what instrument does ashwin sood play?\n",
            "P1303\n",
            "ashwin sood\n",
            "Q4806196\n",
            "answer:  drum kit , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Where was gunnar johansen born in Denmark?\n",
            "P19\n",
            "gunnar johansen\n",
            "Q445899\n",
            "answer:  Copenhagen , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the country of origin of the show tok! tok! tok! isang milyon pasok!\n",
            "P495\n",
            "tok\n",
            "Q394900\n",
            "Sorry, no answer available\n",
            "What is the political ideology behind the german free-minded party?\n",
            "P1142\n",
            "german free - minded party\n",
            "Cosine similarity metric is used!\n",
            "Q560777\n",
            "answer:  progressivism , similarity score with the expected answer: 1.00\n",
            "answer:  liberalism , similarity score with the expected answer: 0.42\n",
            "answer:  laicism , similarity score with the expected answer: 0.31\n",
            "The question is answered correctly!\n",
            "Name an territorial entity which is contained in England\n",
            "R17\n",
            "england\n",
            "Q21\n",
            "answer:  Cornish English , similarity score with the expected answer: 0.39\n",
            "answer:  Fawcett family , similarity score with the expected answer: 0.17\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what is a silent film from 1927\n",
            "R136\n",
            "silent film\n",
            "Q226730\n",
            "answer:  Modern Times , similarity score with the expected answer: 0.34\n",
            "answer:  King of the Circus , similarity score with the expected answer: 0.28\n",
            "answer:  The Broken Coin , similarity score with the expected answer: 0.28\n",
            "answer:  The Green Archer , similarity score with the expected answer: 0.26\n",
            "answer:  The Hawk's Trail , similarity score with the expected answer: 0.25\n",
            "answer:  The Pleasure Garden , similarity score with the expected answer: 0.24\n",
            "answer:  The Screaming Shadow , similarity score with the expected answer: 0.24\n",
            "answer:  Daredevil Jack , similarity score with the expected answer: 0.21\n",
            "answer:  Baseball and Bloomers , similarity score with the expected answer: 0.19\n",
            "answer:  Das wandernde Bild , similarity score with the expected answer: 0.19\n",
            "answer:  Eugene Onegin , similarity score with the expected answer: 0.19\n",
            "answer:  Symphonie diagonale , similarity score with the expected answer: 0.18\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.16\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.12\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.09\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "The power rangers dino thunder game was published by what American company?\n",
            "P123\n",
            "the power rangers dino thunder\n",
            "Cosine similarity metric is used!\n",
            "Q11888796\n",
            "answer:  THQ , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which was the country of citizehship of christopher robinson\n",
            "P495\n",
            "citizehship of christopher robinson\n",
            "Cosine similarity metric is used!\n",
            "Q370264\n",
            "Sorry, no answer available\n",
            "Which position was David Beckham played\n",
            "P413\n",
            "david beckham\n",
            "Q10520\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is the second level division of the division crixas do tocantins\n",
            "P17\n",
            "crixas do to\n",
            "Cosine similarity metric is used!\n",
            "Q1801175\n",
            "answer:  Brazil , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which film was directed by ian iqbal rashid\n",
            "R57\n",
            "ian iqbal rashid\n",
            "Q15461094\n",
            "answer:  Touch of Pink , similarity score with the expected answer: 1.00\n",
            "answer:  How She Move , similarity score with the expected answer: 0.23\n",
            "The question is answered correctly!\n",
            "Which genre of book is bin laden: the man who declared war on america?\n",
            "P136\n",
            "bin laden : the man who declared war on\n",
            "Cosine similarity metric is used!\n",
            "Q4913778\n",
            "answer:  biography , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does dany saadia belong to\n",
            "P27\n",
            "dany saadia\n",
            "Q5221412\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is largemouth bass\n",
            "P171\n",
            "largemouth bass\n",
            "Q755105\n",
            "answer:  Micropterus , similarity score with the expected answer: 0.29\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "does british music band crawler play blues-rock or classical\n",
            "P136\n",
            "crawler\n",
            "Q108882180\n",
            "Sorry, no answer available\n",
            "what river does the neville island bridge cross\n",
            "P276\n",
            "neville island bridge\n",
            "Q7004736\n",
            "Sorry, no answer available\n",
            "what was the country of origin of the tv show sidewalks entertainment\n",
            "P495\n",
            "sidewalks entertainment\n",
            "Q7508530\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which notable person has Rome as place of death\n",
            "P20\n",
            "rome\n",
            "Q220\n",
            "Sorry, no answer available\n",
            "what is the category of the celestial object 1241 dysona\n",
            "P31\n",
            "1241 dysona\n",
            "Q137259\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a city in yolo county in california\n",
            "R131\n",
            "yolo county\n",
            "Q109709\n",
            "answer:  Coast Starlight , similarity score with the expected answer: 0.23\n",
            "answer:  Capitol Corridor , similarity score with the expected answer: 0.20\n",
            "answer:  California State Route 84 , similarity score with the expected answer: 0.16\n",
            "answer:  California State Route 16 , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 5 in California , similarity score with the expected answer: 0.15\n",
            "answer:  West Sacramento , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 505 , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 113 , similarity score with the expected answer: 0.14\n",
            "answer:  Davis , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 275 , similarity score with the expected answer: 0.13\n",
            "answer:  California State Route 128 , similarity score with the expected answer: 0.11\n",
            "answer:  Interstate 80 in California , similarity score with the expected answer: 0.10\n",
            "answer:  Woodland , similarity score with the expected answer: 0.10\n",
            "answer:  California State Route 45 , similarity score with the expected answer: 0.07\n",
            "answer:  U.S. Route 50 in California , similarity score with the expected answer: -0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which place was named after john radcliffe (english physician)\n",
            "R138\n",
            "john radcliffe\n",
            "Q922508\n",
            "answer:  John Radcliffe Hospital , similarity score with the expected answer: 1.00\n",
            "answer:  Radcliffe Infirmary , similarity score with the expected answer: 0.74\n",
            "answer:  Radcliffe Camera , similarity score with the expected answer: 0.58\n",
            "answer:  The Radcliffe Trust , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Square , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Science Library , similarity score with the expected answer: 0.52\n",
            "answer:  Radcliffe Quadrangle , similarity score with the expected answer: 0.49\n",
            "answer:  Radcliffe Observatory , similarity score with the expected answer: 0.48\n",
            "The question is answered correctly!\n",
            "What is Albert Einstein occupation?\n",
            "P106\n",
            "albert einstein\n",
            "Q937\n",
            "answer:  physicist , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which is the film's crying freeman country of origin?\n",
            "P495\n",
            "crying freeman\n",
            "Q1117884\n",
            "answer:  Japan , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "what kind of music is played on film life and death of an american fourtracker\n",
            "P86\n",
            "life and death of an american\n",
            "Cosine similarity metric is used!\n",
            "Q6545041\n",
            "Sorry, no answer available\n",
            "what's the name of an documentary film\n",
            "R136\n",
            "documentary film\n",
            "Q93204\n",
            "answer:  Visions of Light , similarity score with the expected answer: 1.00\n",
            "answer:  Special Effects: Anything Can Happen , similarity score with the expected answer: 0.36\n",
            "answer:  Fellini: A Director's Notebook , similarity score with the expected answer: 0.24\n",
            "answer:  The Clowns , similarity score with the expected answer: 0.23\n",
            "answer:  Isle of Flowers , similarity score with the expected answer: 0.20\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.19\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.19\n",
            "answer:  Kony 2012 , similarity score with the expected answer: 0.18\n",
            "answer:  Black Box BRD , similarity score with the expected answer: 0.17\n",
            "answer:  ¿¡Revolución!? , similarity score with the expected answer: 0.15\n",
            "answer:  Farewell to Enrico Berlinguer , similarity score with the expected answer: 0.12\n",
            "answer:  The Revolution Will Not Be Televised , similarity score with the expected answer: 0.12\n",
            "answer:  We Live in Public , similarity score with the expected answer: 0.11\n",
            "answer:  Frat Party at the Pankake Festival , similarity score with the expected answer: 0.11\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.07\n",
            "The question is answered correctly!\n",
            "exit\n",
            "39\n",
            "10\n",
            "60\n",
            "The percentage of the test questions that are answered correct is: 65.00%\n",
            "The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\n",
            "regardless if the expected answer is one of these correct answer(s) or not: 16.67%\n"
          ]
        }
      ],
      "source": [
        "#Question Answering engine\n",
        "activation_relation_best_parameters_path = 'drive/MyDrive/Relation_indexes_models_best_parameters/All_Questions/ELU/relation_prediction_span_encoded_ignoring_questions_ELU.pt'\n",
        "activation_entity_best_parameters_path =  \"drive/MyDrive/Entity_span_indexes_models_best_parameters/All_Questions/ELU/entity_span_encoded_prediction_ignoring_questions_ELU.pt\"\n",
        "print('This is the question answering engine. Type exit to quit')\n",
        "dropout_prob = 0.3\n",
        "count_test_questions_total = 0\n",
        "count_test_questions_correct_answered = 0\n",
        "count_test_questions_answered = 0\n",
        "while(1):\n",
        "  question = input()\n",
        "  if question == \"exit\":\n",
        "    break;\n",
        "  else:\n",
        "    count_test_questions_total += 1\n",
        "  #Find the real answer, relation id and entity id of the input question from the corresponding .txt file.\n",
        "  for i in range(len(testing_questions)):\n",
        "    if testing_questions[i] == question:\n",
        "      real_question_answer_label = testing_questions_answer_labels[i]\n",
        "      real_question_entity_id = testing_questions_entity_ids[i]\n",
        "      real_question_relation_id = testing_questions_relation_ids[i]\n",
        "      break\n",
        "  question_correct_answered, question_answered = answer(question, Endict, entities, rel_vocab, len(rel_vocab), tokenizer, quests, similarity_model, max(q_lengths), \"ELU\", \"ELU\", activation_relation_best_parameters_path, activation_entity_best_parameters_path, dropout_prob, SEED, real_question_answer_label, real_question_entity_id, real_question_relation_id)\n",
        "  if question_correct_answered == 1:\n",
        "    count_test_questions_correct_answered += 1\n",
        "  if question_answered == 1:\n",
        "    count_test_questions_answered += 1\n",
        "print(count_test_questions_correct_answered)\n",
        "print(count_test_questions_answered)\n",
        "print(count_test_questions_total)\n",
        "print(\"The percentage of the test questions that are answered correct is: {:.2f}%\".format((count_test_questions_correct_answered/count_test_questions_total)*100))\n",
        "print(\"The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\\nregardless if the expected answer is one of these correct answer(s) or not: {:.2f}%\".format((count_test_questions_answered/count_test_questions_total)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67843597-9fcc-41d4-a269-3d480222ab5d",
        "id": "znHM3I79I4M5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the question answering engine. Type exit to quit\n",
            "Which home is an example of italianate architecture?\n",
            "R149\n",
            "italianate architecture\n",
            "Cosine similarity metric is used!\n",
            "Q615196\n",
            "answer:  Fairfield House , similarity score with the expected answer: 0.46\n",
            "answer:  Osborne House , similarity score with the expected answer: 0.41\n",
            "answer:  Hugh Glenn House , similarity score with the expected answer: 0.40\n",
            "answer:  Houses at 37–47 North Fifth Street , similarity score with the expected answer: 0.38\n",
            "answer:  Chatsworth House , similarity score with the expected answer: 0.37\n",
            "answer:  Royal Albert Hall , similarity score with the expected answer: 0.35\n",
            "answer:  Campbell-Rumsey House , similarity score with the expected answer: 0.34\n",
            "answer:  Casa Rosada , similarity score with the expected answer: 0.30\n",
            "answer:  Robinson-Schwenn Building , similarity score with the expected answer: 0.26\n",
            "answer:  Lower East Side Tenement Museum , similarity score with the expected answer: 0.21\n",
            "answer:  Criterion Hotel , similarity score with the expected answer: 0.20\n",
            "answer:  Palacio de los Leones , similarity score with the expected answer: 0.18\n",
            "answer:  Houghton County Courthouse , similarity score with the expected answer: 0.18\n",
            "answer:  Balch Hotel , similarity score with the expected answer: 0.16\n",
            "answer:  Tweed Courthouse , similarity score with the expected answer: 0.15\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what type of object is 25049 christofnorn\n",
            "P31\n",
            "25049 christofnorn\n",
            "Q1753907\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which person was born in liverpool?\n",
            "R19\n",
            "liverpool\n",
            "Q24826\n",
            "answer:  Ringo Starr , similarity score with the expected answer: 1.00\n",
            "answer:  Keith Newton , similarity score with the expected answer: 0.38\n",
            "answer:  Miles Jackson-Lipkin , similarity score with the expected answer: 0.38\n",
            "answer:  Toni Duggan , similarity score with the expected answer: 0.34\n",
            "answer:  Simon Rattle , similarity score with the expected answer: 0.32\n",
            "answer:  Kevin Nolan , similarity score with the expected answer: 0.31\n",
            "answer:  Adam F , similarity score with the expected answer: 0.30\n",
            "answer:  Richard Laurence Millington Synge , similarity score with the expected answer: 0.28\n",
            "answer:  David Johnson , similarity score with the expected answer: 0.28\n",
            "answer:  David Weatherall , similarity score with the expected answer: 0.28\n",
            "answer:  James Heneghan , similarity score with the expected answer: 0.26\n",
            "answer:  Adam Morgan , similarity score with the expected answer: 0.22\n",
            "answer:  William Ewart Gladstone , similarity score with the expected answer: 0.22\n",
            "answer:  Gertrud Luckner , similarity score with the expected answer: 0.20\n",
            "answer:  Zarqa Nawaz , similarity score with the expected answer: 0.14\n",
            "The question is answered correctly!\n",
            "What film genre is twilight considered to be?\n",
            "P136\n",
            "twilight\n",
            "Q44523\n",
            "answer:  romantic fiction , similarity score with the expected answer: 0.71\n",
            "answer:  young adult fiction , similarity score with the expected answer: 0.49\n",
            "answer:  vampire fiction , similarity score with the expected answer: 0.47\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which type of film is the bitter tea of general yen?\n",
            "P136\n",
            "the bitter tea of general yen\n",
            "Cosine similarity metric is used!\n",
            "Q568239\n",
            "answer:  drama film , similarity score with the expected answer: 1.00\n",
            "answer:  film based on literature , similarity score with the expected answer: 0.66\n",
            "answer:  romance film , similarity score with the expected answer: 0.65\n",
            "The question is answered correctly!\n",
            "What is the gender of Athina Maximou\n",
            "P21\n",
            "athina maximou\n",
            "Cosine similarity metric is used!\n",
            "Q757820\n",
            "answer:  male , similarity score with the expected answer: 0.73\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Name an Rolling Stones album\n",
            "R136\n",
            "rolling stones\n",
            "Q11036\n",
            "Sorry, no answer available\n",
            "Who directed woody meets davy crewcut\n",
            "P57\n",
            "woody meets davy crewcut\n",
            "Q8033685\n",
            "answer:  Alex Lovy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "who was the first NSW female Minister of Education died from cancer\n",
            "R509\n",
            "cancer\n",
            "Q12078\n",
            "answer:  Mildred Scheel , similarity score with the expected answer: 0.31\n",
            "answer:  Peter Rühmkorf , similarity score with the expected answer: 0.27\n",
            "answer:  Michael Karoli , similarity score with the expected answer: 0.27\n",
            "answer:  Anton Diffring , similarity score with the expected answer: 0.27\n",
            "answer:  Heinz Lammerding , similarity score with the expected answer: 0.23\n",
            "answer:  Konrad Wolf , similarity score with the expected answer: 0.23\n",
            "answer:  Hans Fruhstorfer , similarity score with the expected answer: 0.22\n",
            "answer:  Rudolf Wolters , similarity score with the expected answer: 0.20\n",
            "answer:  Manfred Stolpe , similarity score with the expected answer: 0.18\n",
            "answer:  Mady Rahl , similarity score with the expected answer: 0.17\n",
            "answer:  Markus Beyer , similarity score with the expected answer: 0.15\n",
            "answer:  Irmtraud Morgner , similarity score with the expected answer: 0.13\n",
            "answer:  Hans-Joachim Bohlmann , similarity score with the expected answer: 0.11\n",
            "answer:  Helma Sanders-Brahms , similarity score with the expected answer: 0.08\n",
            "answer:  Gabriele Kröcher-Tiedemann , similarity score with the expected answer: -0.04\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What position does denis shcherbak play\n",
            "P413\n",
            "denis shcherbak\n",
            "Q4528782\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does the show un refugio para el amor originate from\n",
            "P495\n",
            "un refugio para el amor\n",
            "Cosine similarity metric is used!\n",
            "Q1068093\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what alternative rock band from Chicago is the author of of the blue colour of the sky\n",
            "R136\n",
            "alternative rock\n",
            "Q11366\n",
            "answer:  Ride , similarity score with the expected answer: 0.26\n",
            "answer:  Howl , similarity score with the expected answer: 0.22\n",
            "answer:  Linkin Park , similarity score with the expected answer: 0.21\n",
            "answer:  Red Hot Chili Peppers , similarity score with the expected answer: 0.18\n",
            "answer:  Tame Impala , similarity score with the expected answer: 0.18\n",
            "answer:  Coheed and Cambria , similarity score with the expected answer: 0.17\n",
            "answer:  Mark Hoppus , similarity score with the expected answer: 0.15\n",
            "answer:  Black Francis , similarity score with the expected answer: 0.14\n",
            "answer:  Birds of Tokyo , similarity score with the expected answer: 0.12\n",
            "answer:  U2 , similarity score with the expected answer: 0.09\n",
            "answer:  David Bowie , similarity score with the expected answer: 0.06\n",
            "answer:  Neil Young , similarity score with the expected answer: 0.06\n",
            "answer:  Tom DeLonge , similarity score with the expected answer: 0.04\n",
            "answer:  Kurt Cobain , similarity score with the expected answer: 0.04\n",
            "answer:  Kevin Rudolf , similarity score with the expected answer: 0.03\n",
            "The question is not answered correctly!\n",
            "who is the artist that performed on the album sample and hold: attack decay sustain release?\n",
            "P175\n",
            "sample and hold : attack\n",
            "Cosine similarity metric is used!\n",
            "Q7410135\n",
            "answer:  Simian Mobile Disco , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "where john brewster jr. was born\n",
            "P19\n",
            "john brewster jr\n",
            "Cosine similarity metric is used!\n",
            "Q6223118\n",
            "answer:  Hampton , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a multiplayer game?\n",
            "R404\n",
            "a multiplayer game\n",
            "Cosine similarity metric is used!\n",
            "Q6895044\n",
            "answer:  Heroes of Might and Magic V: Tribes of the East , similarity score with the expected answer: 0.55\n",
            "answer:  Commandos 2: Men of Courage , similarity score with the expected answer: 0.49\n",
            "answer:  Heroes of Might and Magic V: Hammers of Fate , similarity score with the expected answer: 0.45\n",
            "answer:  Heroes of Might and Magic V , similarity score with the expected answer: 0.42\n",
            "answer:  Uncharted 2: Among Thieves , similarity score with the expected answer: 0.41\n",
            "answer:  Civilization III , similarity score with the expected answer: 0.40\n",
            "answer:  Civilization IV , similarity score with the expected answer: 0.37\n",
            "answer:  Uncharted 3: Drake's Deception , similarity score with the expected answer: 0.34\n",
            "answer:  Civilization V , similarity score with the expected answer: 0.32\n",
            "answer:  Super Mario Bros. , similarity score with the expected answer: 0.27\n",
            "answer:  Donkey Kong , similarity score with the expected answer: 0.27\n",
            "answer:  Freedom Force vs the 3rd Reich , similarity score with the expected answer: 0.22\n",
            "answer:  Grand Theft Auto V , similarity score with the expected answer: 0.17\n",
            "answer:  Need for Speed: Shift , similarity score with the expected answer: 0.11\n",
            "answer:  Football Manager , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which company produced hot enough for june\n",
            "P272\n",
            "hot enough for june\n",
            "Cosine similarity metric is used!\n",
            "Q12124859\n",
            "answer:  Rank Organisation , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "is jose figueroa alcorta from argentina or costa rica\n",
            "P27\n",
            "jose figueroa alcorta\n",
            "Q442729\n",
            "answer:  Argentina , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What kind of game is microsoft international soccer 2000\n",
            "P136\n",
            "microsoft international soccer 2000\n",
            "Q3312381\n",
            "answer:  association football video game , similarity score with the expected answer: 0.81\n",
            "The question is answered correctly!\n",
            "who is the composer of the song liar?\n",
            "P86\n",
            "liar\n",
            "Q6540228\n",
            "Sorry, no answer available\n",
            "Joshua Kimmich is member of which sports team?\n",
            "P641\n",
            "joshua kimmich\n",
            "Q13865408\n",
            "answer:  association football , similarity score with the expected answer: 0.50\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the name of a folk rock singer (or group)?\n",
            "R136\n",
            "folk rock\n",
            "Q186472\n",
            "answer:  Neil Young , similarity score with the expected answer: 1.00\n",
            "answer:  Paul Simon , similarity score with the expected answer: 0.53\n",
            "answer:  Bob Dylan , similarity score with the expected answer: 0.48\n",
            "answer:  Alan Stivell , similarity score with the expected answer: 0.44\n",
            "answer:  Leonard Cohen , similarity score with the expected answer: 0.44\n",
            "answer:  Marcus Mumford , similarity score with the expected answer: 0.39\n",
            "answer:  Amy Macdonald , similarity score with the expected answer: 0.37\n",
            "answer:  George Harrison , similarity score with the expected answer: 0.36\n",
            "answer:  The Beatles , similarity score with the expected answer: 0.31\n",
            "answer:  Led Zeppelin , similarity score with the expected answer: 0.28\n",
            "answer:  Cher , similarity score with the expected answer: 0.22\n",
            "answer:  Tri Yann , similarity score with the expected answer: 0.22\n",
            "answer:  Denez Prigent , similarity score with the expected answer: 0.16\n",
            "answer:  Tsvety , similarity score with the expected answer: 0.10\n",
            "answer:  Iļģi , similarity score with the expected answer: 0.06\n",
            "The question is answered correctly!\n",
            "Who was born in dakar?\n",
            "R19\n",
            "dakar\n",
            "Q3718\n",
            "answer:  Mamadou Diabang , similarity score with the expected answer: 0.50\n",
            "answer:  Lamine Diack , similarity score with the expected answer: 0.41\n",
            "answer:  Bineta Diedhiou , similarity score with the expected answer: 0.40\n",
            "answer:  Abdoul Mbaye , similarity score with the expected answer: 0.38\n",
            "answer:  Patrick Vieira , similarity score with the expected answer: 0.38\n",
            "answer:  Pape Abdou Camara , similarity score with the expected answer: 0.37\n",
            "answer:  Mouhamadou Dabo , similarity score with the expected answer: 0.36\n",
            "answer:  Idrissa Gueye , similarity score with the expected answer: 0.35\n",
            "answer:  Pape Alioune Diouf , similarity score with the expected answer: 0.34\n",
            "answer:  José Brito , similarity score with the expected answer: 0.34\n",
            "answer:  Mansour Gueye , similarity score with the expected answer: 0.33\n",
            "answer:  Patrice Evra , similarity score with the expected answer: 0.33\n",
            "answer:  Mame Biram Diouf , similarity score with the expected answer: 0.32\n",
            "answer:  Boniface N'Dong , similarity score with the expected answer: 0.27\n",
            "answer:  Henri Saivet , similarity score with the expected answer: 0.25\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "where did edward i. edwards died\n",
            "P20\n",
            "edward i edwards\n",
            "Cosine similarity metric is used!\n",
            "Q436902\n",
            "answer:  Jersey City , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the sex of david swift?\n",
            "P21\n",
            "david swift\n",
            "Q5240208\n",
            "answer:  male , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What language is mission to caracas written in\n",
            "P364\n",
            "mission to caracas\n",
            "Cosine similarity metric is used!\n",
            "Q6878840\n",
            "answer:  French , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what genre is the album why is there air?\n",
            "P136\n",
            "why is there air\n",
            "Cosine similarity metric is used!\n",
            "Q7997809\n",
            "answer:  stand-up comedy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is chad mustard's nationality\n",
            "P27\n",
            "chad mustard\n",
            "Q5066318\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is an instrument played by carl jackson\n",
            "P1303\n",
            "carl jackson\n",
            "Q5040368\n",
            "answer:  guitar , similarity score with the expected answer: 1.00\n",
            "answer:  mandolin , similarity score with the expected answer: 0.62\n",
            "answer:  banjo , similarity score with the expected answer: 0.57\n",
            "The question is answered correctly!\n",
            "Which is Aristotle Onassis profession?\n",
            "P106\n",
            "aristotle onassis\n",
            "Q180455\n",
            "answer:  ship-owner , similarity score with the expected answer: 1.00\n",
            "answer:  businessperson , similarity score with the expected answer: 0.45\n",
            "answer:  entrepreneur , similarity score with the expected answer: 0.33\n",
            "The question is answered correctly!\n",
            "what genre of music does bo diddley play?\n",
            "P136\n",
            "bo diddley\n",
            "Q10431795\n",
            "Sorry, no answer available\n",
            "Which genre of music was the album duck rock labeled?\n",
            "P136\n",
            "duck rock\n",
            "Q910692\n",
            "answer:  new wave , similarity score with the expected answer: 1.00\n",
            "answer:  rock music , similarity score with the expected answer: 0.27\n",
            "answer:  hip hop music , similarity score with the expected answer: 0.16\n",
            "The question is answered correctly!\n",
            "what is Michael Ballack's country of nationality\n",
            "P27\n",
            "michael ballack\n",
            "Q11948\n",
            "answer:  Germany , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what football position does dorin dickerson play at?\n",
            "P413\n",
            "dorin dickerson\n",
            "Q3037050\n",
            "answer:  wide receiver , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country is purple people eater filmed in?\n",
            "P495\n",
            "purple people eater\n",
            "Q3410974\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "idris phillips follows this major religion.\n",
            "P140\n",
            "idris phillips\n",
            "Q16192877\n",
            "answer:  Islam , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what instrument does ashwin sood play?\n",
            "P1303\n",
            "ashwin sood\n",
            "Q4806196\n",
            "answer:  drum kit , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Where was gunnar johansen born in Denmark?\n",
            "P19\n",
            "gunnar johansen\n",
            "Q445899\n",
            "answer:  Copenhagen , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the country of origin of the show tok! tok! tok! isang milyon pasok!\n",
            "P495\n",
            "tok tok to\n",
            "Cosine similarity metric is used!\n",
            "Q2300687\n",
            "answer:  Japan , similarity score with the expected answer: 0.60\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the political ideology behind the german free-minded party?\n",
            "P1142\n",
            "german free - minded party\n",
            "Cosine similarity metric is used!\n",
            "Q560777\n",
            "answer:  progressivism , similarity score with the expected answer: 1.00\n",
            "answer:  liberalism , similarity score with the expected answer: 0.42\n",
            "answer:  laicism , similarity score with the expected answer: 0.31\n",
            "The question is answered correctly!\n",
            "Name an territorial entity which is contained in England\n",
            "R17\n",
            "england\n",
            "Q21\n",
            "answer:  Cornish English , similarity score with the expected answer: 0.39\n",
            "answer:  Fawcett family , similarity score with the expected answer: 0.17\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what is a silent film from 1927\n",
            "R136\n",
            "silent film\n",
            "Q226730\n",
            "answer:  Modern Times , similarity score with the expected answer: 0.34\n",
            "answer:  King of the Circus , similarity score with the expected answer: 0.28\n",
            "answer:  The Broken Coin , similarity score with the expected answer: 0.28\n",
            "answer:  The Green Archer , similarity score with the expected answer: 0.26\n",
            "answer:  The Hawk's Trail , similarity score with the expected answer: 0.25\n",
            "answer:  The Pleasure Garden , similarity score with the expected answer: 0.24\n",
            "answer:  The Screaming Shadow , similarity score with the expected answer: 0.24\n",
            "answer:  Daredevil Jack , similarity score with the expected answer: 0.21\n",
            "answer:  Baseball and Bloomers , similarity score with the expected answer: 0.19\n",
            "answer:  Das wandernde Bild , similarity score with the expected answer: 0.19\n",
            "answer:  Eugene Onegin , similarity score with the expected answer: 0.19\n",
            "answer:  Symphonie diagonale , similarity score with the expected answer: 0.18\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.16\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.12\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.09\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "The power rangers dino thunder game was published by what American company?\n",
            "P123\n",
            "the power rangers dino thunder\n",
            "Cosine similarity metric is used!\n",
            "Q11888796\n",
            "answer:  THQ , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which was the country of citizehship of christopher robinson\n",
            "P27\n",
            "citizehship of christopher robinson\n",
            "Cosine similarity metric is used!\n",
            "Q370264\n",
            "answer:  Canada , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "Which position was David Beckham played\n",
            "P413\n",
            "david beckham\n",
            "Q10520\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is the second level division of the division crixas do tocantins\n",
            "P17\n",
            "crixas do to\n",
            "Cosine similarity metric is used!\n",
            "Q1801175\n",
            "answer:  Brazil , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which film was directed by ian iqbal rashid\n",
            "R57\n",
            "ian iqbal rashid\n",
            "Q15461094\n",
            "answer:  Touch of Pink , similarity score with the expected answer: 1.00\n",
            "answer:  How She Move , similarity score with the expected answer: 0.23\n",
            "The question is answered correctly!\n",
            "Which genre of book is bin laden: the man who declared war on america?\n",
            "P136\n",
            "bin laden : the man who declared war on\n",
            "Cosine similarity metric is used!\n",
            "Q4913778\n",
            "answer:  biography , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does dany saadia belong to\n",
            "P27\n",
            "dany saadia\n",
            "Q5221412\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is largemouth bass\n",
            "R136\n",
            "largemouth bass\n",
            "Q755105\n",
            "Sorry, no answer available\n",
            "does british music band crawler play blues-rock or classical\n",
            "P136\n",
            "crawler\n",
            "Q108882180\n",
            "Sorry, no answer available\n",
            "what river does the neville island bridge cross\n",
            "R177\n",
            "neville island bridge\n",
            "Q7004736\n",
            "Sorry, no answer available\n",
            "what was the country of origin of the tv show sidewalks entertainment\n",
            "P495\n",
            "sidewalks entertainment\n",
            "Q7508530\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which notable person has Rome as place of death\n",
            "P20\n",
            "rome\n",
            "Q220\n",
            "Sorry, no answer available\n",
            "what is the category of the celestial object 1241 dysona\n",
            "P31\n",
            "1241 dysona\n",
            "Q137259\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a city in yolo county in california\n",
            "R131\n",
            "yolo county\n",
            "Q109709\n",
            "answer:  Coast Starlight , similarity score with the expected answer: 0.23\n",
            "answer:  Capitol Corridor , similarity score with the expected answer: 0.20\n",
            "answer:  California State Route 84 , similarity score with the expected answer: 0.16\n",
            "answer:  California State Route 16 , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 5 in California , similarity score with the expected answer: 0.15\n",
            "answer:  West Sacramento , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 505 , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 113 , similarity score with the expected answer: 0.14\n",
            "answer:  Davis , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 275 , similarity score with the expected answer: 0.13\n",
            "answer:  California State Route 128 , similarity score with the expected answer: 0.11\n",
            "answer:  Interstate 80 in California , similarity score with the expected answer: 0.10\n",
            "answer:  Woodland , similarity score with the expected answer: 0.10\n",
            "answer:  California State Route 45 , similarity score with the expected answer: 0.07\n",
            "answer:  U.S. Route 50 in California , similarity score with the expected answer: -0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which place was named after john radcliffe (english physician)\n",
            "R138\n",
            "john radcliffe\n",
            "Q922508\n",
            "answer:  John Radcliffe Hospital , similarity score with the expected answer: 1.00\n",
            "answer:  Radcliffe Infirmary , similarity score with the expected answer: 0.74\n",
            "answer:  Radcliffe Camera , similarity score with the expected answer: 0.58\n",
            "answer:  The Radcliffe Trust , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Square , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Science Library , similarity score with the expected answer: 0.52\n",
            "answer:  Radcliffe Quadrangle , similarity score with the expected answer: 0.49\n",
            "answer:  Radcliffe Observatory , similarity score with the expected answer: 0.48\n",
            "The question is answered correctly!\n",
            "What is Albert Einstein occupation?\n",
            "P106\n",
            "albert einstein\n",
            "Q937\n",
            "answer:  physicist , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which is the film's crying freeman country of origin?\n",
            "P495\n",
            "crying freeman\n",
            "Q1117884\n",
            "answer:  Japan , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "what kind of music is played on film life and death of an american fourtracker\n",
            "P136\n",
            "film life and death of an american\n",
            "Cosine similarity metric is used!\n",
            "Q18648361\n",
            "answer:  drama film , similarity score with the expected answer: 0.36\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what's the name of an documentary film\n",
            "R136\n",
            "documentary film\n",
            "Q93204\n",
            "answer:  Visions of Light , similarity score with the expected answer: 1.00\n",
            "answer:  Special Effects: Anything Can Happen , similarity score with the expected answer: 0.36\n",
            "answer:  Fellini: A Director's Notebook , similarity score with the expected answer: 0.24\n",
            "answer:  The Clowns , similarity score with the expected answer: 0.23\n",
            "answer:  Isle of Flowers , similarity score with the expected answer: 0.20\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.19\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.19\n",
            "answer:  Kony 2012 , similarity score with the expected answer: 0.18\n",
            "answer:  Black Box BRD , similarity score with the expected answer: 0.17\n",
            "answer:  ¿¡Revolución!? , similarity score with the expected answer: 0.15\n",
            "answer:  Farewell to Enrico Berlinguer , similarity score with the expected answer: 0.12\n",
            "answer:  The Revolution Will Not Be Televised , similarity score with the expected answer: 0.12\n",
            "answer:  We Live in Public , similarity score with the expected answer: 0.11\n",
            "answer:  Frat Party at the Pankake Festival , similarity score with the expected answer: 0.11\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.07\n",
            "The question is answered correctly!\n",
            "exit\n",
            "40\n",
            "12\n",
            "60\n",
            "The percentage of the test questions that are answered correct is: 66.67%\n",
            "The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\n",
            "regardless if the expected answer is one of these correct answer(s) or not: 20.00%\n"
          ]
        }
      ],
      "source": [
        "#Question Answering engine\n",
        "activation_relation_best_parameters_path = 'drive/MyDrive/Relation_indexes_models_best_parameters/All_Questions/ELU/relation_prediction_span_encoded_not_ignoring_questions_ELU.pt'\n",
        "activation_entity_best_parameters_path =  \"drive/MyDrive/Entity_span_indexes_models_best_parameters/All_Questions/Softplus/entity_span_encoded_prediction_not_ignoring_questions_Softplus.pt\"\n",
        "print('This is the question answering engine. Type exit to quit')\n",
        "dropout_prob = 0.3\n",
        "count_test_questions_total = 0\n",
        "count_test_questions_correct_answered = 0\n",
        "count_test_questions_answered = 0\n",
        "while(1):\n",
        "  question = input()\n",
        "  if question == \"exit\":\n",
        "    break;\n",
        "  else:\n",
        "    count_test_questions_total += 1\n",
        "  #Find the real answer, relation id and entity id of the input question from the corresponding .txt file.\n",
        "  for i in range(len(testing_questions)):\n",
        "    if testing_questions[i] == question:\n",
        "      real_question_answer_label = testing_questions_answer_labels[i]\n",
        "      real_question_entity_id = testing_questions_entity_ids[i]\n",
        "      real_question_relation_id = testing_questions_relation_ids[i]\n",
        "      break\n",
        "  question_correct_answered, question_answered = answer(question, Endict, entities, rel_vocab, len(rel_vocab), tokenizer, quests, similarity_model, max(q_lengths), \"ELU\", \"Softplus\", activation_relation_best_parameters_path, activation_entity_best_parameters_path, dropout_prob, SEED, real_question_answer_label, real_question_entity_id, real_question_relation_id)\n",
        "  if question_correct_answered == 1:\n",
        "    count_test_questions_correct_answered += 1\n",
        "  if question_answered == 1:\n",
        "    count_test_questions_answered += 1\n",
        "print(count_test_questions_correct_answered)\n",
        "print(count_test_questions_answered)\n",
        "print(count_test_questions_total)\n",
        "print(\"The percentage of the test questions that are answered correct is: {:.2f}%\".format((count_test_questions_correct_answered/count_test_questions_total)*100))\n",
        "print(\"The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\\nregardless if the expected answer is one of these correct answer(s) or not: {:.2f}%\".format((count_test_questions_answered/count_test_questions_total)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f92a51d-f20c-474b-f10e-2c3a2d0ea7e6",
        "id": "r0YtOlU-TkCV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the question answering engine. Type exit to quit\n",
            "Which home is an example of italianate architecture?\n",
            "R149\n",
            "italianate architecture\n",
            "Cosine similarity metric is used!\n",
            "Q615196\n",
            "answer:  Fairfield House , similarity score with the expected answer: 0.46\n",
            "answer:  Osborne House , similarity score with the expected answer: 0.41\n",
            "answer:  Hugh Glenn House , similarity score with the expected answer: 0.40\n",
            "answer:  Houses at 37–47 North Fifth Street , similarity score with the expected answer: 0.38\n",
            "answer:  Chatsworth House , similarity score with the expected answer: 0.37\n",
            "answer:  Royal Albert Hall , similarity score with the expected answer: 0.35\n",
            "answer:  Campbell-Rumsey House , similarity score with the expected answer: 0.34\n",
            "answer:  Casa Rosada , similarity score with the expected answer: 0.30\n",
            "answer:  Robinson-Schwenn Building , similarity score with the expected answer: 0.26\n",
            "answer:  Lower East Side Tenement Museum , similarity score with the expected answer: 0.21\n",
            "answer:  Criterion Hotel , similarity score with the expected answer: 0.20\n",
            "answer:  Palacio de los Leones , similarity score with the expected answer: 0.18\n",
            "answer:  Houghton County Courthouse , similarity score with the expected answer: 0.18\n",
            "answer:  Balch Hotel , similarity score with the expected answer: 0.16\n",
            "answer:  Tweed Courthouse , similarity score with the expected answer: 0.15\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what type of object is 25049 christofnorn\n",
            "P31\n",
            "25049 christofnorn\n",
            "Q1753907\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which person was born in liverpool?\n",
            "R19\n",
            "liverpool\n",
            "Q24826\n",
            "answer:  George Stubbs , similarity score with the expected answer: 0.39\n",
            "answer:  Tristan Jones , similarity score with the expected answer: 0.36\n",
            "answer:  Michael Ball , similarity score with the expected answer: 0.35\n",
            "answer:  Charles Nicholson , similarity score with the expected answer: 0.33\n",
            "answer:  Charles Brabin , similarity score with the expected answer: 0.32\n",
            "answer:  Stan Brittain , similarity score with the expected answer: 0.32\n",
            "answer:  Coleen Rooney , similarity score with the expected answer: 0.32\n",
            "answer:  Richard Kenneth Brummitt , similarity score with the expected answer: 0.30\n",
            "answer:  Steve Coppell , similarity score with the expected answer: 0.29\n",
            "answer:  Robert Robinson , similarity score with the expected answer: 0.28\n",
            "answer:  Steve Smith , similarity score with the expected answer: 0.23\n",
            "answer:  Phil Thompson , similarity score with the expected answer: 0.18\n",
            "answer:  Natasha Jonas , similarity score with the expected answer: 0.15\n",
            "answer:  Natasha Hamilton , similarity score with the expected answer: 0.14\n",
            "answer:  Konstantinos Paspatis , similarity score with the expected answer: 0.14\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What film genre is twilight considered to be?\n",
            "P136\n",
            "twilight\n",
            "Q44523\n",
            "answer:  romantic fiction , similarity score with the expected answer: 0.71\n",
            "answer:  young adult fiction , similarity score with the expected answer: 0.49\n",
            "answer:  vampire fiction , similarity score with the expected answer: 0.47\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which type of film is the bitter tea of general yen?\n",
            "P136\n",
            "the bitter tea of general yen\n",
            "Cosine similarity metric is used!\n",
            "Q568239\n",
            "answer:  drama film , similarity score with the expected answer: 1.00\n",
            "answer:  film based on literature , similarity score with the expected answer: 0.66\n",
            "answer:  romance film , similarity score with the expected answer: 0.65\n",
            "The question is answered correctly!\n",
            "What is the gender of Athina Maximou\n",
            "P21\n",
            "athina maximou\n",
            "Cosine similarity metric is used!\n",
            "Q757820\n",
            "answer:  male , similarity score with the expected answer: 0.73\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Name an Rolling Stones album\n",
            "R136\n",
            "rolling stones\n",
            "Q11036\n",
            "Sorry, no answer available\n",
            "Who directed woody meets davy crewcut\n",
            "P57\n",
            "woody meets davy crewcut\n",
            "Q8033685\n",
            "answer:  Alex Lovy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "who was the first NSW female Minister of Education died from cancer\n",
            "R509\n",
            "from cancer\n",
            "Cosine similarity metric is used!\n",
            "Q12078\n",
            "answer:  Kathleen Lonsdale , similarity score with the expected answer: 0.46\n",
            "answer:  Jude Milhon , similarity score with the expected answer: 0.39\n",
            "answer:  Ivory Joe Hunter , similarity score with the expected answer: 0.36\n",
            "answer:  Ivo Lapenna , similarity score with the expected answer: 0.33\n",
            "answer:  Henriette Avram , similarity score with the expected answer: 0.31\n",
            "answer:  Danielle Bunten Berry , similarity score with the expected answer: 0.29\n",
            "answer:  Georges Brassens , similarity score with the expected answer: 0.28\n",
            "answer:  Harry Mulisch , similarity score with the expected answer: 0.28\n",
            "answer:  Marcel Doret , similarity score with the expected answer: 0.28\n",
            "answer:  Juan Antonio Rios , similarity score with the expected answer: 0.26\n",
            "answer:  Michel Rocard , similarity score with the expected answer: 0.24\n",
            "answer:  Robert Mugabe , similarity score with the expected answer: 0.23\n",
            "answer:  Yann-Fañch Kemener , similarity score with the expected answer: 0.12\n",
            "answer:  Pierre Desproges , similarity score with the expected answer: 0.09\n",
            "answer:  Elder Paisios of Mount Athos , similarity score with the expected answer: 0.00\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What position does denis shcherbak play\n",
            "P413\n",
            "denis shcherbak\n",
            "Q4528782\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does the show un refugio para el amor originate from\n",
            "P495\n",
            "un refugio para el amor\n",
            "Cosine similarity metric is used!\n",
            "Q1068093\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what alternative rock band from Chicago is the author of of the blue colour of the sky\n",
            "R136\n",
            "alternative rock\n",
            "Q11366\n",
            "answer:  Ride , similarity score with the expected answer: 0.26\n",
            "answer:  Howl , similarity score with the expected answer: 0.22\n",
            "answer:  Linkin Park , similarity score with the expected answer: 0.21\n",
            "answer:  Red Hot Chili Peppers , similarity score with the expected answer: 0.18\n",
            "answer:  Tame Impala , similarity score with the expected answer: 0.18\n",
            "answer:  Coheed and Cambria , similarity score with the expected answer: 0.17\n",
            "answer:  Mark Hoppus , similarity score with the expected answer: 0.15\n",
            "answer:  Black Francis , similarity score with the expected answer: 0.14\n",
            "answer:  Birds of Tokyo , similarity score with the expected answer: 0.12\n",
            "answer:  U2 , similarity score with the expected answer: 0.09\n",
            "answer:  David Bowie , similarity score with the expected answer: 0.06\n",
            "answer:  Neil Young , similarity score with the expected answer: 0.06\n",
            "answer:  Tom DeLonge , similarity score with the expected answer: 0.04\n",
            "answer:  Kurt Cobain , similarity score with the expected answer: 0.04\n",
            "answer:  Kevin Rudolf , similarity score with the expected answer: 0.03\n",
            "The question is not answered correctly!\n",
            "who is the artist that performed on the album sample and hold: attack decay sustain release?\n",
            "P175\n",
            "sample and hold : attack\n",
            "Cosine similarity metric is used!\n",
            "Q7410135\n",
            "answer:  Simian Mobile Disco , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "where john brewster jr. was born\n",
            "P19\n",
            "john brewster jr\n",
            "Cosine similarity metric is used!\n",
            "Q6223118\n",
            "answer:  Hampton , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a multiplayer game?\n",
            "R404\n",
            "multiplayer game\n",
            "Cosine similarity metric is used!\n",
            "Q6895044\n",
            "answer:  Heroes of Might and Magic V: Tribes of the East , similarity score with the expected answer: 0.55\n",
            "answer:  Commandos 2: Men of Courage , similarity score with the expected answer: 0.49\n",
            "answer:  Heroes of Might and Magic V: Hammers of Fate , similarity score with the expected answer: 0.45\n",
            "answer:  Heroes of Might and Magic V , similarity score with the expected answer: 0.42\n",
            "answer:  Uncharted 2: Among Thieves , similarity score with the expected answer: 0.41\n",
            "answer:  Civilization III , similarity score with the expected answer: 0.40\n",
            "answer:  Civilization IV , similarity score with the expected answer: 0.37\n",
            "answer:  Uncharted 3: Drake's Deception , similarity score with the expected answer: 0.34\n",
            "answer:  Civilization V , similarity score with the expected answer: 0.32\n",
            "answer:  Super Mario Bros. , similarity score with the expected answer: 0.27\n",
            "answer:  Donkey Kong , similarity score with the expected answer: 0.27\n",
            "answer:  Freedom Force vs the 3rd Reich , similarity score with the expected answer: 0.22\n",
            "answer:  Grand Theft Auto V , similarity score with the expected answer: 0.17\n",
            "answer:  Need for Speed: Shift , similarity score with the expected answer: 0.11\n",
            "answer:  Football Manager , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which company produced hot enough for june\n",
            "P272\n",
            "hot enough for june\n",
            "Cosine similarity metric is used!\n",
            "Q12124859\n",
            "answer:  Rank Organisation , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "is jose figueroa alcorta from argentina or costa rica\n",
            "P27\n",
            "jose figueroa alcorta\n",
            "Q442729\n",
            "answer:  Argentina , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What kind of game is microsoft international soccer 2000\n",
            "P136\n",
            "microsoft international soccer 2000\n",
            "Q3312381\n",
            "answer:  association football video game , similarity score with the expected answer: 0.81\n",
            "The question is answered correctly!\n",
            "who is the composer of the song liar?\n",
            "P86\n",
            "liar\n",
            "Q6540228\n",
            "Sorry, no answer available\n",
            "Joshua Kimmich is member of which sports team?\n",
            "P641\n",
            "joshua kimmich\n",
            "Q13865408\n",
            "answer:  association football , similarity score with the expected answer: 0.50\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the name of a folk rock singer (or group)?\n",
            "R136\n",
            "folk rock\n",
            "Q186472\n",
            "answer:  Neil Young , similarity score with the expected answer: 1.00\n",
            "answer:  Paul Simon , similarity score with the expected answer: 0.53\n",
            "answer:  Bob Dylan , similarity score with the expected answer: 0.48\n",
            "answer:  Alan Stivell , similarity score with the expected answer: 0.44\n",
            "answer:  Leonard Cohen , similarity score with the expected answer: 0.44\n",
            "answer:  Marcus Mumford , similarity score with the expected answer: 0.39\n",
            "answer:  Amy Macdonald , similarity score with the expected answer: 0.37\n",
            "answer:  George Harrison , similarity score with the expected answer: 0.36\n",
            "answer:  The Beatles , similarity score with the expected answer: 0.31\n",
            "answer:  Led Zeppelin , similarity score with the expected answer: 0.28\n",
            "answer:  Cher , similarity score with the expected answer: 0.22\n",
            "answer:  Tri Yann , similarity score with the expected answer: 0.22\n",
            "answer:  Denez Prigent , similarity score with the expected answer: 0.16\n",
            "answer:  Tsvety , similarity score with the expected answer: 0.10\n",
            "answer:  Iļģi , similarity score with the expected answer: 0.06\n",
            "The question is answered correctly!\n",
            "Who was born in dakar?\n",
            "R19\n",
            "dakar\n",
            "Q3718\n",
            "answer:  Mamadou Diabang , similarity score with the expected answer: 0.50\n",
            "answer:  Lamine Diack , similarity score with the expected answer: 0.41\n",
            "answer:  Bineta Diedhiou , similarity score with the expected answer: 0.40\n",
            "answer:  Abdoul Mbaye , similarity score with the expected answer: 0.38\n",
            "answer:  Patrick Vieira , similarity score with the expected answer: 0.38\n",
            "answer:  Pape Abdou Camara , similarity score with the expected answer: 0.37\n",
            "answer:  Mouhamadou Dabo , similarity score with the expected answer: 0.36\n",
            "answer:  Idrissa Gueye , similarity score with the expected answer: 0.35\n",
            "answer:  Pape Alioune Diouf , similarity score with the expected answer: 0.34\n",
            "answer:  José Brito , similarity score with the expected answer: 0.34\n",
            "answer:  Mansour Gueye , similarity score with the expected answer: 0.33\n",
            "answer:  Patrice Evra , similarity score with the expected answer: 0.33\n",
            "answer:  Mame Biram Diouf , similarity score with the expected answer: 0.32\n",
            "answer:  Boniface N'Dong , similarity score with the expected answer: 0.27\n",
            "answer:  Henri Saivet , similarity score with the expected answer: 0.25\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "where did edward i. edwards died\n",
            "P20\n",
            "edward i edwards\n",
            "Cosine similarity metric is used!\n",
            "Q436902\n",
            "answer:  Jersey City , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the sex of david swift?\n",
            "P21\n",
            "david swift\n",
            "Q5240208\n",
            "answer:  male , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What language is mission to caracas written in\n",
            "P364\n",
            "mission to caracas\n",
            "Cosine similarity metric is used!\n",
            "Q6878840\n",
            "answer:  French , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what genre is the album why is there air?\n",
            "P136\n",
            "why is there air\n",
            "Cosine similarity metric is used!\n",
            "Q7997809\n",
            "answer:  stand-up comedy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is chad mustard's nationality\n",
            "P27\n",
            "chad mustard\n",
            "Q5066318\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is an instrument played by carl jackson\n",
            "P1303\n",
            "carl jackson\n",
            "Q5040368\n",
            "answer:  guitar , similarity score with the expected answer: 1.00\n",
            "answer:  mandolin , similarity score with the expected answer: 0.62\n",
            "answer:  banjo , similarity score with the expected answer: 0.57\n",
            "The question is answered correctly!\n",
            "Which is Aristotle Onassis profession?\n",
            "P106\n",
            "aristotle onassis\n",
            "Q180455\n",
            "answer:  ship-owner , similarity score with the expected answer: 1.00\n",
            "answer:  businessperson , similarity score with the expected answer: 0.45\n",
            "answer:  entrepreneur , similarity score with the expected answer: 0.33\n",
            "The question is answered correctly!\n",
            "what genre of music does bo diddley play?\n",
            "P136\n",
            "bo diddley\n",
            "Q10431795\n",
            "Sorry, no answer available\n",
            "Which genre of music was the album duck rock labeled?\n",
            "P136\n",
            "duck rock\n",
            "Q910692\n",
            "answer:  new wave , similarity score with the expected answer: 1.00\n",
            "answer:  rock music , similarity score with the expected answer: 0.27\n",
            "answer:  hip hop music , similarity score with the expected answer: 0.16\n",
            "The question is answered correctly!\n",
            "what is Michael Ballack's country of nationality\n",
            "P27\n",
            "michael ballack\n",
            "Q11948\n",
            "answer:  Germany , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what football position does dorin dickerson play at?\n",
            "P413\n",
            "dorin dickerson\n",
            "Q3037050\n",
            "answer:  wide receiver , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country is purple people eater filmed in?\n",
            "P495\n",
            "purple people eater\n",
            "Q3410974\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "idris phillips follows this major religion.\n",
            "P140\n",
            "idris phillips\n",
            "Q16192877\n",
            "answer:  Islam , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what instrument does ashwin sood play?\n",
            "P1303\n",
            "ashwin sood\n",
            "Q4806196\n",
            "answer:  drum kit , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Where was gunnar johansen born in Denmark?\n",
            "P19\n",
            "gunnar johansen\n",
            "Q445899\n",
            "answer:  Copenhagen , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the country of origin of the show tok! tok! tok! isang milyon pasok!\n",
            "P495\n",
            "tok\n",
            "Q394900\n",
            "Sorry, no answer available\n",
            "What is the political ideology behind the german free-minded party?\n",
            "P1142\n",
            "german free - minded party\n",
            "Cosine similarity metric is used!\n",
            "Q560777\n",
            "answer:  progressivism , similarity score with the expected answer: 1.00\n",
            "answer:  liberalism , similarity score with the expected answer: 0.42\n",
            "answer:  laicism , similarity score with the expected answer: 0.31\n",
            "The question is answered correctly!\n",
            "Name an territorial entity which is contained in England\n",
            "R17\n",
            "england\n",
            "Q21\n",
            "answer:  Cornish English , similarity score with the expected answer: 0.39\n",
            "answer:  Fawcett family , similarity score with the expected answer: 0.17\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what is a silent film from 1927\n",
            "R136\n",
            "silent film\n",
            "Q226730\n",
            "answer:  Modern Times , similarity score with the expected answer: 0.34\n",
            "answer:  King of the Circus , similarity score with the expected answer: 0.28\n",
            "answer:  The Broken Coin , similarity score with the expected answer: 0.28\n",
            "answer:  The Green Archer , similarity score with the expected answer: 0.26\n",
            "answer:  The Hawk's Trail , similarity score with the expected answer: 0.25\n",
            "answer:  The Pleasure Garden , similarity score with the expected answer: 0.24\n",
            "answer:  The Screaming Shadow , similarity score with the expected answer: 0.24\n",
            "answer:  Daredevil Jack , similarity score with the expected answer: 0.21\n",
            "answer:  Baseball and Bloomers , similarity score with the expected answer: 0.19\n",
            "answer:  Das wandernde Bild , similarity score with the expected answer: 0.19\n",
            "answer:  Eugene Onegin , similarity score with the expected answer: 0.19\n",
            "answer:  Symphonie diagonale , similarity score with the expected answer: 0.18\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.16\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.12\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.09\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "The power rangers dino thunder game was published by what American company?\n",
            "P123\n",
            "the power rangers dino thunder\n",
            "Cosine similarity metric is used!\n",
            "Q11888796\n",
            "answer:  THQ , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which was the country of citizehship of christopher robinson\n",
            "P27\n",
            "citizehship of christopher robinson\n",
            "Cosine similarity metric is used!\n",
            "Q370264\n",
            "answer:  Canada , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "Which position was David Beckham played\n",
            "P413\n",
            "david beckham\n",
            "Q10520\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is the second level division of the division crixas do tocantins\n",
            "P17\n",
            "crixas do to\n",
            "Cosine similarity metric is used!\n",
            "Q1801175\n",
            "answer:  Brazil , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which film was directed by ian iqbal rashid\n",
            "R57\n",
            "ian iqbal rashid\n",
            "Q15461094\n",
            "answer:  Touch of Pink , similarity score with the expected answer: 1.00\n",
            "answer:  How She Move , similarity score with the expected answer: 0.23\n",
            "The question is answered correctly!\n",
            "Which genre of book is bin laden: the man who declared war on america?\n",
            "P136\n",
            "bin laden : the man who declared war on\n",
            "Cosine similarity metric is used!\n",
            "Q4913778\n",
            "answer:  biography , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does dany saadia belong to\n",
            "P27\n",
            "dany saadia\n",
            "Q5221412\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is largemouth bass\n",
            "R136\n",
            "largemouth bass\n",
            "Q755105\n",
            "Sorry, no answer available\n",
            "does british music band crawler play blues-rock or classical\n",
            "P136\n",
            "crawler\n",
            "Q108882180\n",
            "Sorry, no answer available\n",
            "what river does the neville island bridge cross\n",
            "R177\n",
            "neville island bridge\n",
            "Q7004736\n",
            "Sorry, no answer available\n",
            "what was the country of origin of the tv show sidewalks entertainment\n",
            "P495\n",
            "sidewalks entertainment\n",
            "Q7508530\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which notable person has Rome as place of death\n",
            "P20\n",
            "rome\n",
            "Q220\n",
            "Sorry, no answer available\n",
            "what is the category of the celestial object 1241 dysona\n",
            "P31\n",
            "1241 dysona\n",
            "Q137259\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a city in yolo county in california\n",
            "R131\n",
            "yolo county\n",
            "Q109709\n",
            "answer:  Coast Starlight , similarity score with the expected answer: 0.23\n",
            "answer:  Capitol Corridor , similarity score with the expected answer: 0.20\n",
            "answer:  California State Route 84 , similarity score with the expected answer: 0.16\n",
            "answer:  California State Route 16 , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 5 in California , similarity score with the expected answer: 0.15\n",
            "answer:  West Sacramento , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 505 , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 113 , similarity score with the expected answer: 0.14\n",
            "answer:  Davis , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 275 , similarity score with the expected answer: 0.13\n",
            "answer:  California State Route 128 , similarity score with the expected answer: 0.11\n",
            "answer:  Interstate 80 in California , similarity score with the expected answer: 0.10\n",
            "answer:  Woodland , similarity score with the expected answer: 0.10\n",
            "answer:  California State Route 45 , similarity score with the expected answer: 0.07\n",
            "answer:  U.S. Route 50 in California , similarity score with the expected answer: -0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which place was named after john radcliffe (english physician)\n",
            "R138\n",
            "john radcliffe\n",
            "Q922508\n",
            "answer:  John Radcliffe Hospital , similarity score with the expected answer: 1.00\n",
            "answer:  Radcliffe Infirmary , similarity score with the expected answer: 0.74\n",
            "answer:  Radcliffe Camera , similarity score with the expected answer: 0.58\n",
            "answer:  The Radcliffe Trust , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Square , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Science Library , similarity score with the expected answer: 0.52\n",
            "answer:  Radcliffe Quadrangle , similarity score with the expected answer: 0.49\n",
            "answer:  Radcliffe Observatory , similarity score with the expected answer: 0.48\n",
            "The question is answered correctly!\n",
            "What is Albert Einstein occupation?\n",
            "P106\n",
            "albert einstein\n",
            "Q937\n",
            "answer:  physicist , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which is the film's crying freeman country of origin?\n",
            "P495\n",
            "crying freeman\n",
            "Q1117884\n",
            "answer:  Japan , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "what kind of music is played on film life and death of an american fourtracker\n",
            "P136\n",
            "film life and death of an american\n",
            "Cosine similarity metric is used!\n",
            "Q18648361\n",
            "answer:  drama film , similarity score with the expected answer: 0.36\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what's the name of an documentary film\n",
            "R136\n",
            "documentary film\n",
            "Q93204\n",
            "answer:  Visions of Light , similarity score with the expected answer: 1.00\n",
            "answer:  Special Effects: Anything Can Happen , similarity score with the expected answer: 0.36\n",
            "answer:  Fellini: A Director's Notebook , similarity score with the expected answer: 0.24\n",
            "answer:  The Clowns , similarity score with the expected answer: 0.23\n",
            "answer:  Isle of Flowers , similarity score with the expected answer: 0.20\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.19\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.19\n",
            "answer:  Kony 2012 , similarity score with the expected answer: 0.18\n",
            "answer:  Black Box BRD , similarity score with the expected answer: 0.17\n",
            "answer:  ¿¡Revolución!? , similarity score with the expected answer: 0.15\n",
            "answer:  Farewell to Enrico Berlinguer , similarity score with the expected answer: 0.12\n",
            "answer:  The Revolution Will Not Be Televised , similarity score with the expected answer: 0.12\n",
            "answer:  We Live in Public , similarity score with the expected answer: 0.11\n",
            "answer:  Frat Party at the Pankake Festival , similarity score with the expected answer: 0.11\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.07\n",
            "The question is answered correctly!\n",
            "exit\n",
            "39\n",
            "12\n",
            "60\n",
            "The percentage of the test questions that are answered correct is: 65.00%\n",
            "The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\n",
            "regardless if the expected answer is one of these correct answer(s) or not: 20.00%\n"
          ]
        }
      ],
      "source": [
        "#Question Answering engine\n",
        "activation_relation_best_parameters_path = 'drive/MyDrive/Relation_indexes_models_best_parameters/All_Questions/ELU/relation_prediction_cosine_similarity_ELU.pt'\n",
        "activation_entity_best_parameters_path =  \"drive/MyDrive/Entity_span_indexes_models_best_parameters/All_Questions/ELU/entity_span_prediction_cosine_similarity_ELU.pt\"\n",
        "print('This is the question answering engine. Type exit to quit')\n",
        "dropout_prob = 0.3\n",
        "count_test_questions_total = 0\n",
        "count_test_questions_correct_answered = 0\n",
        "count_test_questions_answered = 0\n",
        "while(1):#\n",
        "  question = input()\n",
        "  if question == \"exit\":\n",
        "    break;\n",
        "  else:\n",
        "    count_test_questions_total += 1\n",
        "#Find the real answer, relation id and entity id of the input question from the corresponding .txt file.\n",
        "  for i in range(len(testing_questions)):\n",
        "    if testing_questions[i] == question:\n",
        "      real_question_answer_label = testing_questions_answer_labels[i]\n",
        "      real_question_entity_id = testing_questions_entity_ids[i]\n",
        "      real_question_relation_id = testing_questions_relation_ids[i]\n",
        "      break\n",
        "  question_correct_answered, question_answered = answer(question, Endict, entities, rel_vocab, len(rel_vocab), tokenizer, quests, similarity_model, max(q_lengths), \"ELU\", \"ELU\", activation_relation_best_parameters_path, activation_entity_best_parameters_path, dropout_prob, SEED, real_question_answer_label, real_question_entity_id, real_question_relation_id)\n",
        "  if question_correct_answered == 1:\n",
        "    count_test_questions_correct_answered += 1\n",
        "  if question_answered == 1:\n",
        "    count_test_questions_answered += 1\n",
        "print(count_test_questions_correct_answered)\n",
        "print(count_test_questions_answered)\n",
        "print(count_test_questions_total)\n",
        "print(\"The percentage of the test questions that are answered correct is: {:.2f}%\".format((count_test_questions_correct_answered/count_test_questions_total)*100))\n",
        "print(\"The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\\nregardless if the expected answer is one of these correct answer(s) or not: {:.2f}%\".format((count_test_questions_answered/count_test_questions_total)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6fd1745-f4c6-4196-8155-198946e9fe69",
        "id": "G2TNlLcTToGq"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the question answering engine. Type exit to quit\n",
            "Which home is an example of italianate architecture?\n",
            "R149\n",
            "italianate architecture\n",
            "Cosine similarity metric is used!\n",
            "Q615196\n",
            "answer:  Fairfield House , similarity score with the expected answer: 0.46\n",
            "answer:  Osborne House , similarity score with the expected answer: 0.41\n",
            "answer:  Hugh Glenn House , similarity score with the expected answer: 0.40\n",
            "answer:  Houses at 37–47 North Fifth Street , similarity score with the expected answer: 0.38\n",
            "answer:  Chatsworth House , similarity score with the expected answer: 0.37\n",
            "answer:  Royal Albert Hall , similarity score with the expected answer: 0.35\n",
            "answer:  Campbell-Rumsey House , similarity score with the expected answer: 0.34\n",
            "answer:  Casa Rosada , similarity score with the expected answer: 0.30\n",
            "answer:  Robinson-Schwenn Building , similarity score with the expected answer: 0.26\n",
            "answer:  Lower East Side Tenement Museum , similarity score with the expected answer: 0.21\n",
            "answer:  Criterion Hotel , similarity score with the expected answer: 0.20\n",
            "answer:  Palacio de los Leones , similarity score with the expected answer: 0.18\n",
            "answer:  Houghton County Courthouse , similarity score with the expected answer: 0.18\n",
            "answer:  Balch Hotel , similarity score with the expected answer: 0.16\n",
            "answer:  Tweed Courthouse , similarity score with the expected answer: 0.15\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what type of object is 25049 christofnorn\n",
            "P31\n",
            "25049 christofnorn\n",
            "Q1753907\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which person was born in liverpool?\n",
            "R19\n",
            "liverpool\n",
            "Q24826\n",
            "answer:  Ringo Starr , similarity score with the expected answer: 1.00\n",
            "answer:  Keith Newton , similarity score with the expected answer: 0.38\n",
            "answer:  Miles Jackson-Lipkin , similarity score with the expected answer: 0.38\n",
            "answer:  Toni Duggan , similarity score with the expected answer: 0.34\n",
            "answer:  Simon Rattle , similarity score with the expected answer: 0.32\n",
            "answer:  Kevin Nolan , similarity score with the expected answer: 0.31\n",
            "answer:  Adam F , similarity score with the expected answer: 0.30\n",
            "answer:  Richard Laurence Millington Synge , similarity score with the expected answer: 0.28\n",
            "answer:  David Johnson , similarity score with the expected answer: 0.28\n",
            "answer:  David Weatherall , similarity score with the expected answer: 0.28\n",
            "answer:  James Heneghan , similarity score with the expected answer: 0.26\n",
            "answer:  Adam Morgan , similarity score with the expected answer: 0.22\n",
            "answer:  William Ewart Gladstone , similarity score with the expected answer: 0.22\n",
            "answer:  Gertrud Luckner , similarity score with the expected answer: 0.20\n",
            "answer:  Zarqa Nawaz , similarity score with the expected answer: 0.14\n",
            "The question is answered correctly!\n",
            "What film genre is twilight considered to be?\n",
            "P136\n",
            "twilight\n",
            "Q44523\n",
            "answer:  romantic fiction , similarity score with the expected answer: 0.71\n",
            "answer:  young adult fiction , similarity score with the expected answer: 0.49\n",
            "answer:  vampire fiction , similarity score with the expected answer: 0.47\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which type of film is the bitter tea of general yen?\n",
            "P136\n",
            "the bitter tea of general yen\n",
            "Cosine similarity metric is used!\n",
            "Q568239\n",
            "answer:  drama film , similarity score with the expected answer: 1.00\n",
            "answer:  film based on literature , similarity score with the expected answer: 0.66\n",
            "answer:  romance film , similarity score with the expected answer: 0.65\n",
            "The question is answered correctly!\n",
            "What is the gender of Athina Maximou\n",
            "P21\n",
            "athina maximou\n",
            "Cosine similarity metric is used!\n",
            "Q757820\n",
            "answer:  male , similarity score with the expected answer: 0.73\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Name an Rolling Stones album\n",
            "R136\n",
            "rolling stones\n",
            "Q11036\n",
            "Sorry, no answer available\n",
            "Who directed woody meets davy crewcut\n",
            "P57\n",
            "woody meets davy crewcut\n",
            "Q8033685\n",
            "answer:  Alex Lovy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "who was the first NSW female Minister of Education died from cancer\n",
            "R509\n",
            "from cancer\n",
            "Cosine similarity metric is used!\n",
            "Q12078\n",
            "answer:  Kathleen Lonsdale , similarity score with the expected answer: 0.46\n",
            "answer:  Jude Milhon , similarity score with the expected answer: 0.39\n",
            "answer:  Ivory Joe Hunter , similarity score with the expected answer: 0.36\n",
            "answer:  Ivo Lapenna , similarity score with the expected answer: 0.33\n",
            "answer:  Henriette Avram , similarity score with the expected answer: 0.31\n",
            "answer:  Danielle Bunten Berry , similarity score with the expected answer: 0.29\n",
            "answer:  Georges Brassens , similarity score with the expected answer: 0.28\n",
            "answer:  Harry Mulisch , similarity score with the expected answer: 0.28\n",
            "answer:  Marcel Doret , similarity score with the expected answer: 0.28\n",
            "answer:  Juan Antonio Rios , similarity score with the expected answer: 0.26\n",
            "answer:  Michel Rocard , similarity score with the expected answer: 0.24\n",
            "answer:  Robert Mugabe , similarity score with the expected answer: 0.23\n",
            "answer:  Yann-Fañch Kemener , similarity score with the expected answer: 0.12\n",
            "answer:  Pierre Desproges , similarity score with the expected answer: 0.09\n",
            "answer:  Elder Paisios of Mount Athos , similarity score with the expected answer: 0.00\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What position does denis shcherbak play\n",
            "P413\n",
            "denis shcherbak\n",
            "Q4528782\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does the show un refugio para el amor originate from\n",
            "P495\n",
            "un refugio para el amor\n",
            "Cosine similarity metric is used!\n",
            "Q1068093\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what alternative rock band from Chicago is the author of of the blue colour of the sky\n",
            "R136\n",
            "alternative rock\n",
            "Q11366\n",
            "answer:  Ride , similarity score with the expected answer: 0.26\n",
            "answer:  Howl , similarity score with the expected answer: 0.22\n",
            "answer:  Linkin Park , similarity score with the expected answer: 0.21\n",
            "answer:  Red Hot Chili Peppers , similarity score with the expected answer: 0.18\n",
            "answer:  Tame Impala , similarity score with the expected answer: 0.18\n",
            "answer:  Coheed and Cambria , similarity score with the expected answer: 0.17\n",
            "answer:  Mark Hoppus , similarity score with the expected answer: 0.15\n",
            "answer:  Black Francis , similarity score with the expected answer: 0.14\n",
            "answer:  Birds of Tokyo , similarity score with the expected answer: 0.12\n",
            "answer:  U2 , similarity score with the expected answer: 0.09\n",
            "answer:  David Bowie , similarity score with the expected answer: 0.06\n",
            "answer:  Neil Young , similarity score with the expected answer: 0.06\n",
            "answer:  Tom DeLonge , similarity score with the expected answer: 0.04\n",
            "answer:  Kurt Cobain , similarity score with the expected answer: 0.04\n",
            "answer:  Kevin Rudolf , similarity score with the expected answer: 0.03\n",
            "The question is not answered correctly!\n",
            "who is the artist that performed on the album sample and hold: attack decay sustain release?\n",
            "P175\n",
            "sample and hold : attack\n",
            "Cosine similarity metric is used!\n",
            "Q7410135\n",
            "answer:  Simian Mobile Disco , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "where john brewster jr. was born\n",
            "P19\n",
            "john brewster jr\n",
            "Cosine similarity metric is used!\n",
            "Q6223118\n",
            "answer:  Hampton , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a multiplayer game?\n",
            "R404\n",
            "multiplayer game\n",
            "Cosine similarity metric is used!\n",
            "Q6895044\n",
            "answer:  Heroes of Might and Magic V: Tribes of the East , similarity score with the expected answer: 0.55\n",
            "answer:  Commandos 2: Men of Courage , similarity score with the expected answer: 0.49\n",
            "answer:  Heroes of Might and Magic V: Hammers of Fate , similarity score with the expected answer: 0.45\n",
            "answer:  Heroes of Might and Magic V , similarity score with the expected answer: 0.42\n",
            "answer:  Uncharted 2: Among Thieves , similarity score with the expected answer: 0.41\n",
            "answer:  Civilization III , similarity score with the expected answer: 0.40\n",
            "answer:  Civilization IV , similarity score with the expected answer: 0.37\n",
            "answer:  Uncharted 3: Drake's Deception , similarity score with the expected answer: 0.34\n",
            "answer:  Civilization V , similarity score with the expected answer: 0.32\n",
            "answer:  Super Mario Bros. , similarity score with the expected answer: 0.27\n",
            "answer:  Donkey Kong , similarity score with the expected answer: 0.27\n",
            "answer:  Freedom Force vs the 3rd Reich , similarity score with the expected answer: 0.22\n",
            "answer:  Grand Theft Auto V , similarity score with the expected answer: 0.17\n",
            "answer:  Need for Speed: Shift , similarity score with the expected answer: 0.11\n",
            "answer:  Football Manager , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which company produced hot enough for june\n",
            "P272\n",
            "hot enough for june\n",
            "Cosine similarity metric is used!\n",
            "Q12124859\n",
            "answer:  Rank Organisation , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "is jose figueroa alcorta from argentina or costa rica\n",
            "P27\n",
            "jose figueroa alcorta\n",
            "Q442729\n",
            "answer:  Argentina , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What kind of game is microsoft international soccer 2000\n",
            "P136\n",
            "microsoft international soccer 2000\n",
            "Q3312381\n",
            "answer:  association football video game , similarity score with the expected answer: 0.81\n",
            "The question is answered correctly!\n",
            "who is the composer of the song liar?\n",
            "P86\n",
            "liar\n",
            "Q6540228\n",
            "Sorry, no answer available\n",
            "Joshua Kimmich is member of which sports team?\n",
            "P641\n",
            "joshua kimmich\n",
            "Q13865408\n",
            "answer:  association football , similarity score with the expected answer: 0.50\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the name of a folk rock singer (or group)?\n",
            "R136\n",
            "folk rock\n",
            "Q186472\n",
            "answer:  Neil Young , similarity score with the expected answer: 1.00\n",
            "answer:  Paul Simon , similarity score with the expected answer: 0.53\n",
            "answer:  Bob Dylan , similarity score with the expected answer: 0.48\n",
            "answer:  Alan Stivell , similarity score with the expected answer: 0.44\n",
            "answer:  Leonard Cohen , similarity score with the expected answer: 0.44\n",
            "answer:  Marcus Mumford , similarity score with the expected answer: 0.39\n",
            "answer:  Amy Macdonald , similarity score with the expected answer: 0.37\n",
            "answer:  George Harrison , similarity score with the expected answer: 0.36\n",
            "answer:  The Beatles , similarity score with the expected answer: 0.31\n",
            "answer:  Led Zeppelin , similarity score with the expected answer: 0.28\n",
            "answer:  Cher , similarity score with the expected answer: 0.22\n",
            "answer:  Tri Yann , similarity score with the expected answer: 0.22\n",
            "answer:  Denez Prigent , similarity score with the expected answer: 0.16\n",
            "answer:  Tsvety , similarity score with the expected answer: 0.10\n",
            "answer:  Iļģi , similarity score with the expected answer: 0.06\n",
            "The question is answered correctly!\n",
            "Who was born in dakar?\n",
            "R19\n",
            "dakar\n",
            "Q3718\n",
            "answer:  Mamadou Diabang , similarity score with the expected answer: 0.50\n",
            "answer:  Lamine Diack , similarity score with the expected answer: 0.41\n",
            "answer:  Bineta Diedhiou , similarity score with the expected answer: 0.40\n",
            "answer:  Abdoul Mbaye , similarity score with the expected answer: 0.38\n",
            "answer:  Patrick Vieira , similarity score with the expected answer: 0.38\n",
            "answer:  Pape Abdou Camara , similarity score with the expected answer: 0.37\n",
            "answer:  Mouhamadou Dabo , similarity score with the expected answer: 0.36\n",
            "answer:  Idrissa Gueye , similarity score with the expected answer: 0.35\n",
            "answer:  Pape Alioune Diouf , similarity score with the expected answer: 0.34\n",
            "answer:  José Brito , similarity score with the expected answer: 0.34\n",
            "answer:  Mansour Gueye , similarity score with the expected answer: 0.33\n",
            "answer:  Patrice Evra , similarity score with the expected answer: 0.33\n",
            "answer:  Mame Biram Diouf , similarity score with the expected answer: 0.32\n",
            "answer:  Boniface N'Dong , similarity score with the expected answer: 0.27\n",
            "answer:  Henri Saivet , similarity score with the expected answer: 0.25\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "where did edward i. edwards died\n",
            "P20\n",
            "edward i edwards\n",
            "Cosine similarity metric is used!\n",
            "Q436902\n",
            "answer:  Jersey City , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the sex of david swift?\n",
            "P21\n",
            "david swift\n",
            "Q5240208\n",
            "answer:  male , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What language is mission to caracas written in\n",
            "P364\n",
            "mission to caracas\n",
            "Cosine similarity metric is used!\n",
            "Q6878840\n",
            "answer:  French , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what genre is the album why is there air?\n",
            "P136\n",
            "why is there air\n",
            "Cosine similarity metric is used!\n",
            "Q7997809\n",
            "answer:  stand-up comedy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is chad mustard's nationality\n",
            "P27\n",
            "chad mustard\n",
            "Q5066318\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is an instrument played by carl jackson\n",
            "P1303\n",
            "carl jackson\n",
            "Q5040368\n",
            "answer:  guitar , similarity score with the expected answer: 1.00\n",
            "answer:  mandolin , similarity score with the expected answer: 0.62\n",
            "answer:  banjo , similarity score with the expected answer: 0.57\n",
            "The question is answered correctly!\n",
            "Which is Aristotle Onassis profession?\n",
            "P106\n",
            "aristotle onassis\n",
            "Q180455\n",
            "answer:  ship-owner , similarity score with the expected answer: 1.00\n",
            "answer:  businessperson , similarity score with the expected answer: 0.45\n",
            "answer:  entrepreneur , similarity score with the expected answer: 0.33\n",
            "The question is answered correctly!\n",
            "what genre of music does bo diddley play?\n",
            "P136\n",
            "bo diddley\n",
            "Q10431795\n",
            "Sorry, no answer available\n",
            "Which genre of music was the album duck rock labeled?\n",
            "P136\n",
            "duck rock\n",
            "Q910692\n",
            "answer:  new wave , similarity score with the expected answer: 1.00\n",
            "answer:  rock music , similarity score with the expected answer: 0.27\n",
            "answer:  hip hop music , similarity score with the expected answer: 0.16\n",
            "The question is answered correctly!\n",
            "what is Michael Ballack's country of nationality\n",
            "P27\n",
            "michael ballack\n",
            "Q11948\n",
            "answer:  Germany , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what football position does dorin dickerson play at?\n",
            "P413\n",
            "dorin dickerson\n",
            "Q3037050\n",
            "answer:  wide receiver , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country is purple people eater filmed in?\n",
            "P495\n",
            "purple people eater\n",
            "Q3410974\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "idris phillips follows this major religion.\n",
            "P140\n",
            "idris phillips\n",
            "Q16192877\n",
            "answer:  Islam , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what instrument does ashwin sood play?\n",
            "P1303\n",
            "ashwin sood\n",
            "Q4806196\n",
            "answer:  drum kit , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Where was gunnar johansen born in Denmark?\n",
            "P19\n",
            "gunnar johansen\n",
            "Q445899\n",
            "answer:  Copenhagen , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the country of origin of the show tok! tok! tok! isang milyon pasok!\n",
            "P495\n",
            "tok tok to\n",
            "Cosine similarity metric is used!\n",
            "Q2300687\n",
            "answer:  Japan , similarity score with the expected answer: 0.60\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the political ideology behind the german free-minded party?\n",
            "P1142\n",
            "german free - minded party\n",
            "Cosine similarity metric is used!\n",
            "Q560777\n",
            "answer:  progressivism , similarity score with the expected answer: 1.00\n",
            "answer:  liberalism , similarity score with the expected answer: 0.42\n",
            "answer:  laicism , similarity score with the expected answer: 0.31\n",
            "The question is answered correctly!\n",
            "Name an territorial entity which is contained in England\n",
            "R17\n",
            "england\n",
            "Q21\n",
            "answer:  Cornish English , similarity score with the expected answer: 0.39\n",
            "answer:  Fawcett family , similarity score with the expected answer: 0.17\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what is a silent film from 1927\n",
            "R136\n",
            "silent film\n",
            "Q226730\n",
            "answer:  Modern Times , similarity score with the expected answer: 0.34\n",
            "answer:  King of the Circus , similarity score with the expected answer: 0.28\n",
            "answer:  The Broken Coin , similarity score with the expected answer: 0.28\n",
            "answer:  The Green Archer , similarity score with the expected answer: 0.26\n",
            "answer:  The Hawk's Trail , similarity score with the expected answer: 0.25\n",
            "answer:  The Pleasure Garden , similarity score with the expected answer: 0.24\n",
            "answer:  The Screaming Shadow , similarity score with the expected answer: 0.24\n",
            "answer:  Daredevil Jack , similarity score with the expected answer: 0.21\n",
            "answer:  Baseball and Bloomers , similarity score with the expected answer: 0.19\n",
            "answer:  Das wandernde Bild , similarity score with the expected answer: 0.19\n",
            "answer:  Eugene Onegin , similarity score with the expected answer: 0.19\n",
            "answer:  Symphonie diagonale , similarity score with the expected answer: 0.18\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.16\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.12\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.09\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "The power rangers dino thunder game was published by what American company?\n",
            "P123\n",
            "the power rangers dino thunder\n",
            "Cosine similarity metric is used!\n",
            "Q11888796\n",
            "answer:  THQ , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which was the country of citizehship of christopher robinson\n",
            "P27\n",
            "citizehship of christopher robinson\n",
            "Cosine similarity metric is used!\n",
            "Q370264\n",
            "answer:  Canada , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "Which position was David Beckham played\n",
            "P413\n",
            "david beckham\n",
            "Q10520\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is the second level division of the division crixas do tocantins\n",
            "P17\n",
            "crixas do to\n",
            "Cosine similarity metric is used!\n",
            "Q1801175\n",
            "answer:  Brazil , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which film was directed by ian iqbal rashid\n",
            "R57\n",
            "ian iqbal rashid\n",
            "Q15461094\n",
            "answer:  Touch of Pink , similarity score with the expected answer: 1.00\n",
            "answer:  How She Move , similarity score with the expected answer: 0.23\n",
            "The question is answered correctly!\n",
            "Which genre of book is bin laden: the man who declared war on america?\n",
            "P136\n",
            "bin laden : the man who declared war on\n",
            "Cosine similarity metric is used!\n",
            "Q4913778\n",
            "answer:  biography , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does dany saadia belong to\n",
            "P27\n",
            "dany saadia\n",
            "Q5221412\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is largemouth bass\n",
            "R136\n",
            "largemouth bass\n",
            "Q755105\n",
            "Sorry, no answer available\n",
            "does british music band crawler play blues-rock or classical\n",
            "P136\n",
            "crawler\n",
            "Q108882180\n",
            "Sorry, no answer available\n",
            "what river does the neville island bridge cross\n",
            "R177\n",
            "neville island bridge\n",
            "Q7004736\n",
            "Sorry, no answer available\n",
            "what was the country of origin of the tv show sidewalks entertainment\n",
            "P495\n",
            "sidewalks entertainment\n",
            "Q7508530\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which notable person has Rome as place of death\n",
            "P20\n",
            "rome\n",
            "Q220\n",
            "Sorry, no answer available\n",
            "what is the category of the celestial object 1241 dysona\n",
            "P31\n",
            "1241 dysona\n",
            "Q137259\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a city in yolo county in california\n",
            "R131\n",
            "yolo county\n",
            "Q109709\n",
            "answer:  Coast Starlight , similarity score with the expected answer: 0.23\n",
            "answer:  Capitol Corridor , similarity score with the expected answer: 0.20\n",
            "answer:  California State Route 84 , similarity score with the expected answer: 0.16\n",
            "answer:  California State Route 16 , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 5 in California , similarity score with the expected answer: 0.15\n",
            "answer:  West Sacramento , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 505 , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 113 , similarity score with the expected answer: 0.14\n",
            "answer:  Davis , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 275 , similarity score with the expected answer: 0.13\n",
            "answer:  California State Route 128 , similarity score with the expected answer: 0.11\n",
            "answer:  Interstate 80 in California , similarity score with the expected answer: 0.10\n",
            "answer:  Woodland , similarity score with the expected answer: 0.10\n",
            "answer:  California State Route 45 , similarity score with the expected answer: 0.07\n",
            "answer:  U.S. Route 50 in California , similarity score with the expected answer: -0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which place was named after john radcliffe (english physician)\n",
            "R138\n",
            "john radcliffe\n",
            "Q922508\n",
            "answer:  John Radcliffe Hospital , similarity score with the expected answer: 1.00\n",
            "answer:  Radcliffe Infirmary , similarity score with the expected answer: 0.74\n",
            "answer:  Radcliffe Camera , similarity score with the expected answer: 0.58\n",
            "answer:  The Radcliffe Trust , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Square , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Science Library , similarity score with the expected answer: 0.52\n",
            "answer:  Radcliffe Quadrangle , similarity score with the expected answer: 0.49\n",
            "answer:  Radcliffe Observatory , similarity score with the expected answer: 0.48\n",
            "The question is answered correctly!\n",
            "What is Albert Einstein occupation?\n",
            "P106\n",
            "albert einstein\n",
            "Q937\n",
            "answer:  physicist , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which is the film's crying freeman country of origin?\n",
            "P495\n",
            "crying freeman\n",
            "Q1117884\n",
            "answer:  Japan , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "what kind of music is played on film life and death of an american fourtracker\n",
            "P136\n",
            "life and death of an american\n",
            "Cosine similarity metric is used!\n",
            "Q6545041\n",
            "answer:  indie rock , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what's the name of an documentary film\n",
            "R136\n",
            "documentary film\n",
            "Q93204\n",
            "answer:  Visions of Light , similarity score with the expected answer: 1.00\n",
            "answer:  Special Effects: Anything Can Happen , similarity score with the expected answer: 0.36\n",
            "answer:  Fellini: A Director's Notebook , similarity score with the expected answer: 0.24\n",
            "answer:  The Clowns , similarity score with the expected answer: 0.23\n",
            "answer:  Isle of Flowers , similarity score with the expected answer: 0.20\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.19\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.19\n",
            "answer:  Kony 2012 , similarity score with the expected answer: 0.18\n",
            "answer:  Black Box BRD , similarity score with the expected answer: 0.17\n",
            "answer:  ¿¡Revolución!? , similarity score with the expected answer: 0.15\n",
            "answer:  Farewell to Enrico Berlinguer , similarity score with the expected answer: 0.12\n",
            "answer:  The Revolution Will Not Be Televised , similarity score with the expected answer: 0.12\n",
            "answer:  We Live in Public , similarity score with the expected answer: 0.11\n",
            "answer:  Frat Party at the Pankake Festival , similarity score with the expected answer: 0.11\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.07\n",
            "The question is answered correctly!\n",
            "exit\n",
            "41\n",
            "11\n",
            "60\n",
            "The percentage of the test questions that are answered correct is: 68.33%\n",
            "The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\n",
            "regardless if the expected answer is one of these correct answer(s) or not: 18.33%\n"
          ]
        }
      ],
      "source": [
        "#Question Answering engine\n",
        "activation_relation_best_parameters_path = 'drive/MyDrive/Relation_indexes_models_best_parameters/All_Questions/ELU/relation_prediction_jaccard_similarity_ELU.pt'\n",
        "activation_entity_best_parameters_path =  \"drive/MyDrive/Entity_span_indexes_models_best_parameters/All_Questions/Softplus/entity_span_prediction_jaccard_similarity_Softplus.pt\"\n",
        "print('This is the question answering engine. Type exit to quit')\n",
        "dropout_prob = 0.3\n",
        "count_test_questions_total = 0\n",
        "count_test_questions_correct_answered = 0\n",
        "count_test_questions_answered = 0\n",
        "while(1):\n",
        "  question = input()\n",
        "  if question == \"exit\":\n",
        "    break;\n",
        "  else:\n",
        "    count_test_questions_total += 1\n",
        "  #Find the real answer, relation id and entity id of the input question from the corresponding .txt file.\n",
        "  for i in range(len(testing_questions)):\n",
        "    if testing_questions[i] == question:\n",
        "      real_question_answer_label = testing_questions_answer_labels[i]\n",
        "      real_question_entity_id = testing_questions_entity_ids[i]\n",
        "      real_question_relation_id = testing_questions_relation_ids[i]\n",
        "      break\n",
        "  question_correct_answered, question_answered = answer(question, Endict, entities, rel_vocab, len(rel_vocab), tokenizer, quests, similarity_model, max(q_lengths), \"ELU\", \"Softplus\", activation_relation_best_parameters_path, activation_entity_best_parameters_path, dropout_prob, SEED, real_question_answer_label, real_question_entity_id, real_question_relation_id)\n",
        "  if question_correct_answered == 1:\n",
        "    count_test_questions_correct_answered += 1\n",
        "  if question_answered == 1:\n",
        "    count_test_questions_answered += 1\n",
        "print(count_test_questions_correct_answered)\n",
        "print(count_test_questions_answered)\n",
        "print(count_test_questions_total)\n",
        "print(\"The percentage of the test questions that are answered correct is: {:.2f}%\".format((count_test_questions_correct_answered/count_test_questions_total)*100))\n",
        "print(\"The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\\nregardless if the expected answer is one of these correct answer(s) or not: {:.2f}%\".format((count_test_questions_answered/count_test_questions_total)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiJOwXwTDKfX"
      },
      "source": [
        "**Question Answering engine for the answerable questions, with the best parameters for each methodology.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d328887f-4855-4c90-b9af-b593886637ff",
        "id": "VAawpMQYdxRr"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the question answering engine. Type exit to quit\n",
            "Which home is an example of italianate architecture?\n",
            "P149\n",
            "italianate architecture\n",
            "Cosine similarity metric is used!\n",
            "Q615196\n",
            "Sorry, no answer available\n",
            "what type of object is 25049 christofnorn\n",
            "P31\n",
            "25049 christofnorn\n",
            "Q1753907\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which person was born in liverpool?\n",
            "R19\n",
            "liverpool\n",
            "Q24826\n",
            "answer:  Ringo Starr , similarity score with the expected answer: 1.00\n",
            "answer:  Keith Newton , similarity score with the expected answer: 0.38\n",
            "answer:  Miles Jackson-Lipkin , similarity score with the expected answer: 0.38\n",
            "answer:  Toni Duggan , similarity score with the expected answer: 0.34\n",
            "answer:  Simon Rattle , similarity score with the expected answer: 0.32\n",
            "answer:  Kevin Nolan , similarity score with the expected answer: 0.31\n",
            "answer:  Adam F , similarity score with the expected answer: 0.30\n",
            "answer:  Richard Laurence Millington Synge , similarity score with the expected answer: 0.28\n",
            "answer:  David Johnson , similarity score with the expected answer: 0.28\n",
            "answer:  David Weatherall , similarity score with the expected answer: 0.28\n",
            "answer:  James Heneghan , similarity score with the expected answer: 0.26\n",
            "answer:  Adam Morgan , similarity score with the expected answer: 0.22\n",
            "answer:  William Ewart Gladstone , similarity score with the expected answer: 0.22\n",
            "answer:  Gertrud Luckner , similarity score with the expected answer: 0.20\n",
            "answer:  Zarqa Nawaz , similarity score with the expected answer: 0.14\n",
            "The question is answered correctly!\n",
            "What film genre is twilight considered to be?\n",
            "P136\n",
            "twilight\n",
            "Q44523\n",
            "answer:  romantic fiction , similarity score with the expected answer: 0.71\n",
            "answer:  young adult fiction , similarity score with the expected answer: 0.49\n",
            "answer:  vampire fiction , similarity score with the expected answer: 0.47\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which type of film is the bitter tea of general yen?\n",
            "P136\n",
            "the bitter tea of general yen\n",
            "Cosine similarity metric is used!\n",
            "Q568239\n",
            "answer:  drama film , similarity score with the expected answer: 1.00\n",
            "answer:  film based on literature , similarity score with the expected answer: 0.66\n",
            "answer:  romance film , similarity score with the expected answer: 0.65\n",
            "The question is answered correctly!\n",
            "What is the gender of Athina Maximou\n",
            "P21\n",
            "athina maximou\n",
            "Cosine similarity metric is used!\n",
            "Q757820\n",
            "answer:  male , similarity score with the expected answer: 0.73\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Name an Rolling Stones album\n",
            "R175\n",
            "rolling stones\n",
            "Q11036\n",
            "answer:  Metamorphosis , similarity score with the expected answer: 1.00\n",
            "answer:  Heart of Stone , similarity score with the expected answer: 0.29\n",
            "answer:  Flowers , similarity score with the expected answer: 0.25\n",
            "answer:  Through the Past, Darkly (Big Hits Vol. 2) , similarity score with the expected answer: 0.22\n",
            "answer:  The Last Time , similarity score with the expected answer: 0.15\n",
            "answer:  GRRR! , similarity score with the expected answer: 0.14\n",
            "answer:  More Hot Rocks , similarity score with the expected answer: 0.14\n",
            "answer:  (I Can't Get No) Satisfaction , similarity score with the expected answer: 0.13\n",
            "answer:  Jump Back: The Best of The Rolling Stones , similarity score with the expected answer: 0.13\n",
            "answer:  Live Licks , similarity score with the expected answer: 0.13\n",
            "answer:  Angie , similarity score with the expected answer: 0.12\n",
            "answer:  Rarities 1971–2003 , similarity score with the expected answer: 0.11\n",
            "answer:  Sucking in the Seventies , similarity score with the expected answer: 0.09\n",
            "answer:  No Security , similarity score with the expected answer: 0.06\n",
            "answer:  Fingerprint File , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Who directed woody meets davy crewcut\n",
            "P57\n",
            "woody meets davy crewcut\n",
            "Q8033685\n",
            "answer:  Alex Lovy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "who was the first NSW female Minister of Education died from cancer\n",
            "R509\n",
            "education\n",
            "Q8434\n",
            "Sorry, no answer available\n",
            "What position does denis shcherbak play\n",
            "P413\n",
            "denis shcherbak\n",
            "Q4528782\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does the show un refugio para el amor originate from\n",
            "P495\n",
            "un refugio para el amor\n",
            "Cosine similarity metric is used!\n",
            "Q1068093\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what alternative rock band from Chicago is the author of of the blue colour of the sky\n",
            "P175\n",
            "alternative rock band from chicago is\n",
            "Cosine similarity metric is used!\n",
            "Q11366\n",
            "Sorry, no answer available\n",
            "who is the artist that performed on the album sample and hold: attack decay sustain release?\n",
            "P175\n",
            "sample and hold\n",
            "Cosine similarity metric is used!\n",
            "Q7410135\n",
            "answer:  Simian Mobile Disco , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "where john brewster jr. was born\n",
            "P19\n",
            "john brewster jr\n",
            "Cosine similarity metric is used!\n",
            "Q6223118\n",
            "answer:  Hampton , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a multiplayer game?\n",
            "P404\n",
            "multiplayer game\n",
            "Cosine similarity metric is used!\n",
            "Q6895044\n",
            "Sorry, no answer available\n",
            "which company produced hot enough for june\n",
            "P272\n",
            "hot enough for june\n",
            "Cosine similarity metric is used!\n",
            "Q12124859\n",
            "answer:  Rank Organisation , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "is jose figueroa alcorta from argentina or costa rica\n",
            "P27\n",
            "jose figueroa alcorta\n",
            "Q442729\n",
            "answer:  Argentina , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What kind of game is microsoft international soccer 2000\n",
            "P136\n",
            "microsoft international soccer 2000\n",
            "Q3312381\n",
            "answer:  association football video game , similarity score with the expected answer: 0.81\n",
            "The question is answered correctly!\n",
            "who is the composer of the song liar?\n",
            "P86\n",
            "liar\n",
            "Q6540228\n",
            "Sorry, no answer available\n",
            "Joshua Kimmich is member of which sports team?\n",
            "P53\n",
            "joshua kimmich\n",
            "Q13865408\n",
            "Sorry, no answer available\n",
            "What is the name of a folk rock singer (or group)?\n",
            "R136\n",
            "folk rock\n",
            "Q186472\n",
            "answer:  Neil Young , similarity score with the expected answer: 1.00\n",
            "answer:  Paul Simon , similarity score with the expected answer: 0.53\n",
            "answer:  Bob Dylan , similarity score with the expected answer: 0.48\n",
            "answer:  Alan Stivell , similarity score with the expected answer: 0.44\n",
            "answer:  Leonard Cohen , similarity score with the expected answer: 0.44\n",
            "answer:  Marcus Mumford , similarity score with the expected answer: 0.39\n",
            "answer:  Amy Macdonald , similarity score with the expected answer: 0.37\n",
            "answer:  George Harrison , similarity score with the expected answer: 0.36\n",
            "answer:  The Beatles , similarity score with the expected answer: 0.31\n",
            "answer:  Led Zeppelin , similarity score with the expected answer: 0.28\n",
            "answer:  Cher , similarity score with the expected answer: 0.22\n",
            "answer:  Tri Yann , similarity score with the expected answer: 0.22\n",
            "answer:  Denez Prigent , similarity score with the expected answer: 0.16\n",
            "answer:  Tsvety , similarity score with the expected answer: 0.10\n",
            "answer:  Iļģi , similarity score with the expected answer: 0.06\n",
            "The question is answered correctly!\n",
            "Who was born in dakar?\n",
            "R19\n",
            "dakar\n",
            "Q3718\n",
            "answer:  Mamadou Diabang , similarity score with the expected answer: 0.50\n",
            "answer:  Lamine Diack , similarity score with the expected answer: 0.41\n",
            "answer:  Bineta Diedhiou , similarity score with the expected answer: 0.40\n",
            "answer:  Abdoul Mbaye , similarity score with the expected answer: 0.38\n",
            "answer:  Patrick Vieira , similarity score with the expected answer: 0.38\n",
            "answer:  Pape Abdou Camara , similarity score with the expected answer: 0.37\n",
            "answer:  Mouhamadou Dabo , similarity score with the expected answer: 0.36\n",
            "answer:  Idrissa Gueye , similarity score with the expected answer: 0.35\n",
            "answer:  Pape Alioune Diouf , similarity score with the expected answer: 0.34\n",
            "answer:  José Brito , similarity score with the expected answer: 0.34\n",
            "answer:  Mansour Gueye , similarity score with the expected answer: 0.33\n",
            "answer:  Patrice Evra , similarity score with the expected answer: 0.33\n",
            "answer:  Mame Biram Diouf , similarity score with the expected answer: 0.32\n",
            "answer:  Boniface N'Dong , similarity score with the expected answer: 0.27\n",
            "answer:  Henri Saivet , similarity score with the expected answer: 0.25\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "where did edward i. edwards died\n",
            "P20\n",
            "edward i edwards\n",
            "Cosine similarity metric is used!\n",
            "Q436902\n",
            "answer:  Jersey City , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the sex of david swift?\n",
            "P21\n",
            "david swift\n",
            "Q5240208\n",
            "answer:  male , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What language is mission to caracas written in\n",
            "P364\n",
            "mission to caracas\n",
            "Cosine similarity metric is used!\n",
            "Q6878840\n",
            "answer:  French , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what genre is the album why is there air?\n",
            "P136\n",
            "why is there air\n",
            "Cosine similarity metric is used!\n",
            "Q7997809\n",
            "answer:  stand-up comedy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is chad mustard's nationality\n",
            "P27\n",
            "chad mustard\n",
            "Q5066318\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is an instrument played by carl jackson\n",
            "P1303\n",
            "carl jackson\n",
            "Q5040368\n",
            "answer:  guitar , similarity score with the expected answer: 1.00\n",
            "answer:  mandolin , similarity score with the expected answer: 0.62\n",
            "answer:  banjo , similarity score with the expected answer: 0.57\n",
            "The question is answered correctly!\n",
            "Which is Aristotle Onassis profession?\n",
            "P106\n",
            "aristotle onassis\n",
            "Q180455\n",
            "answer:  ship-owner , similarity score with the expected answer: 1.00\n",
            "answer:  businessperson , similarity score with the expected answer: 0.45\n",
            "answer:  entrepreneur , similarity score with the expected answer: 0.33\n",
            "The question is answered correctly!\n",
            "what genre of music does bo diddley play?\n",
            "P136\n",
            "bo diddley\n",
            "Q10431795\n",
            "Sorry, no answer available\n",
            "Which genre of music was the album duck rock labeled?\n",
            "P136\n",
            "duck rock\n",
            "Q910692\n",
            "answer:  new wave , similarity score with the expected answer: 1.00\n",
            "answer:  rock music , similarity score with the expected answer: 0.27\n",
            "answer:  hip hop music , similarity score with the expected answer: 0.16\n",
            "The question is answered correctly!\n",
            "what is Michael Ballack's country of nationality\n",
            "P27\n",
            "michael ballack\n",
            "Q11948\n",
            "answer:  Germany , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what football position does dorin dickerson play at?\n",
            "P413\n",
            "dorin dickerson\n",
            "Q3037050\n",
            "answer:  wide receiver , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country is purple people eater filmed in?\n",
            "P495\n",
            "purple people eater\n",
            "Q3410974\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "idris phillips follows this major religion.\n",
            "P140\n",
            "idris phillips\n",
            "Q16192877\n",
            "answer:  Islam , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what instrument does ashwin sood play?\n",
            "P1303\n",
            "ashwin sood\n",
            "Q4806196\n",
            "answer:  drum kit , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Where was gunnar johansen born in Denmark?\n",
            "P19\n",
            "gunnar johansen\n",
            "Q445899\n",
            "answer:  Copenhagen , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the country of origin of the show tok! tok! tok! isang milyon pasok!\n",
            "P495\n",
            "to\n",
            "Q7810815\n",
            "Sorry, no answer available\n",
            "What is the political ideology behind the german free-minded party?\n",
            "P140\n",
            "german free - minded\n",
            "Cosine similarity metric is used!\n",
            "Q560777\n",
            "Sorry, no answer available\n",
            "Name an territorial entity which is contained in England\n",
            "P17\n",
            "england\n",
            "Q21\n",
            "answer:  United Kingdom , similarity score with the expected answer: 0.67\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what is a silent film from 1927\n",
            "R136\n",
            "silent film\n",
            "Q226730\n",
            "answer:  Modern Times , similarity score with the expected answer: 0.34\n",
            "answer:  King of the Circus , similarity score with the expected answer: 0.28\n",
            "answer:  The Broken Coin , similarity score with the expected answer: 0.28\n",
            "answer:  The Green Archer , similarity score with the expected answer: 0.26\n",
            "answer:  The Hawk's Trail , similarity score with the expected answer: 0.25\n",
            "answer:  The Pleasure Garden , similarity score with the expected answer: 0.24\n",
            "answer:  The Screaming Shadow , similarity score with the expected answer: 0.24\n",
            "answer:  Daredevil Jack , similarity score with the expected answer: 0.21\n",
            "answer:  Baseball and Bloomers , similarity score with the expected answer: 0.19\n",
            "answer:  Das wandernde Bild , similarity score with the expected answer: 0.19\n",
            "answer:  Eugene Onegin , similarity score with the expected answer: 0.19\n",
            "answer:  Symphonie diagonale , similarity score with the expected answer: 0.18\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.16\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.12\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.09\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "The power rangers dino thunder game was published by what American company?\n",
            "P123\n",
            "the power rangers dino thunder\n",
            "Cosine similarity metric is used!\n",
            "Q11888796\n",
            "answer:  THQ , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which was the country of citizehship of christopher robinson\n",
            "P495\n",
            "citizehship of christopher robinson\n",
            "Cosine similarity metric is used!\n",
            "Q370264\n",
            "Sorry, no answer available\n",
            "Which position was David Beckham played\n",
            "P413\n",
            "david beckham\n",
            "Q10520\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is the second level division of the division crixas do tocantins\n",
            "P17\n",
            "crixas\n",
            "Q177030\n",
            "answer:  Brazil , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "Which film was directed by ian iqbal rashid\n",
            "R57\n",
            "ian iqbal rashid\n",
            "Q15461094\n",
            "answer:  Touch of Pink , similarity score with the expected answer: 1.00\n",
            "answer:  How She Move , similarity score with the expected answer: 0.23\n",
            "The question is answered correctly!\n",
            "Which genre of book is bin laden: the man who declared war on america?\n",
            "P136\n",
            "bin laden : the man who declared war\n",
            "Cosine similarity metric is used!\n",
            "Q4913778\n",
            "answer:  biography , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does dany saadia belong to\n",
            "P27\n",
            "dany saadia\n",
            "Q5221412\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is largemouth bass\n",
            "R21\n",
            "largemouth bass\n",
            "Q755105\n",
            "Sorry, no answer available\n",
            "does british music band crawler play blues-rock or classical\n",
            "P136\n",
            "crawler\n",
            "Q108882180\n",
            "Sorry, no answer available\n",
            "what river does the neville island bridge cross\n",
            "P710\n",
            "neville island bridge\n",
            "Q7004736\n",
            "Sorry, no answer available\n",
            "what was the country of origin of the tv show sidewalks entertainment\n",
            "P495\n",
            "sidewalks entertainment\n",
            "Q7508530\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which notable person has Rome as place of death\n",
            "P20\n",
            "rome\n",
            "Q220\n",
            "Sorry, no answer available\n",
            "what is the category of the celestial object 1241 dysona\n",
            "P31\n",
            "1241 dysona\n",
            "Q137259\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a city in yolo county in california\n",
            "R131\n",
            "yolo county\n",
            "Q109709\n",
            "answer:  Coast Starlight , similarity score with the expected answer: 0.23\n",
            "answer:  Capitol Corridor , similarity score with the expected answer: 0.20\n",
            "answer:  California State Route 84 , similarity score with the expected answer: 0.16\n",
            "answer:  California State Route 16 , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 5 in California , similarity score with the expected answer: 0.15\n",
            "answer:  West Sacramento , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 505 , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 113 , similarity score with the expected answer: 0.14\n",
            "answer:  Davis , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 275 , similarity score with the expected answer: 0.13\n",
            "answer:  California State Route 128 , similarity score with the expected answer: 0.11\n",
            "answer:  Interstate 80 in California , similarity score with the expected answer: 0.10\n",
            "answer:  Woodland , similarity score with the expected answer: 0.10\n",
            "answer:  California State Route 45 , similarity score with the expected answer: 0.07\n",
            "answer:  U.S. Route 50 in California , similarity score with the expected answer: -0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which place was named after john radcliffe (english physician)\n",
            "P138\n",
            "john radcliffe\n",
            "Q922508\n",
            "Sorry, no answer available\n",
            "What is Albert Einstein occupation?\n",
            "P106\n",
            "albert einstein\n",
            "Q937\n",
            "answer:  physicist , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which is the film's crying freeman country of origin?\n",
            "P495\n",
            "crying freeman\n",
            "Q1117884\n",
            "answer:  Japan , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "what kind of music is played on film life and death of an american fourtracker\n",
            "P86\n",
            "life and death of\n",
            "Cosine similarity metric is used!\n",
            "Q6545292\n",
            "Sorry, no answer available\n",
            "what's the name of an documentary film\n",
            "R136\n",
            "documentary film\n",
            "Q93204\n",
            "answer:  Visions of Light , similarity score with the expected answer: 1.00\n",
            "answer:  Special Effects: Anything Can Happen , similarity score with the expected answer: 0.36\n",
            "answer:  Fellini: A Director's Notebook , similarity score with the expected answer: 0.24\n",
            "answer:  The Clowns , similarity score with the expected answer: 0.23\n",
            "answer:  Isle of Flowers , similarity score with the expected answer: 0.20\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.19\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.19\n",
            "answer:  Kony 2012 , similarity score with the expected answer: 0.18\n",
            "answer:  Black Box BRD , similarity score with the expected answer: 0.17\n",
            "answer:  ¿¡Revolución!? , similarity score with the expected answer: 0.15\n",
            "answer:  Farewell to Enrico Berlinguer , similarity score with the expected answer: 0.12\n",
            "answer:  The Revolution Will Not Be Televised , similarity score with the expected answer: 0.12\n",
            "answer:  We Live in Public , similarity score with the expected answer: 0.11\n",
            "answer:  Frat Party at the Pankake Festival , similarity score with the expected answer: 0.11\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.07\n",
            "The question is answered correctly!\n",
            "exit\n",
            "37\n",
            "7\n",
            "60\n",
            "The percentage of the test questions that are answered correct is: 61.67%\n",
            "The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\n",
            "regardless if the expected answer is one of these correct answer(s) or not: 11.67%\n"
          ]
        }
      ],
      "source": [
        "#Question Answering engine\n",
        "activation_relation_best_parameters_path = 'drive/MyDrive/Relation_indexes_models_best_parameters/Answerable_Questions/ELU/relation_prediction_span_encoded_ignoring_answerable_questions_ELU.pt'\n",
        "activation_entity_best_parameters_path =  \"drive/MyDrive/Entity_span_indexes_models_best_parameters/Answerable_Questions/Softplus/entity_span_encoded_prediction_ignoring_answerable_questions_Softplus.pt\"\n",
        "print('This is the question answering engine. Type exit to quit')\n",
        "dropout_prob = 0.3\n",
        "count_test_questions_total = 0\n",
        "count_test_questions_correct_answered = 0\n",
        "count_test_questions_answered = 0\n",
        "while(1):\n",
        "  question = input()\n",
        "  if question == \"exit\":\n",
        "    break;\n",
        "  else:\n",
        "    count_test_questions_total += 1\n",
        "  #Find the real answer, relation id and entity id of the input question from the corresponding .txt file.\n",
        "  for i in range(len(testing_questions)):\n",
        "    if testing_questions[i] == question:\n",
        "      real_question_answer_label = testing_questions_answer_labels[i]\n",
        "      real_question_entity_id = testing_questions_entity_ids[i]\n",
        "      real_question_relation_id = testing_questions_relation_ids[i]\n",
        "      break\n",
        "  question_correct_answered, question_answered = answer(question, Endict, entities, rel_answerable_vocab, len(rel_answerable_vocab), tokenizer, quests, similarity_model, max(q_lengths), \"ELU\", \"Softplus\", activation_relation_best_parameters_path, activation_entity_best_parameters_path, dropout_prob, SEED, real_question_answer_label, real_question_entity_id, real_question_relation_id)\n",
        "  if question_correct_answered == 1:\n",
        "    count_test_questions_correct_answered += 1\n",
        "  if question_answered == 1:\n",
        "    count_test_questions_answered += 1\n",
        "print(count_test_questions_correct_answered)\n",
        "print(count_test_questions_answered)\n",
        "print(count_test_questions_total)\n",
        "print(\"The percentage of the test questions that are answered correct is: {:.2f}%\".format((count_test_questions_correct_answered/count_test_questions_total)*100))\n",
        "print(\"The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\\nregardless if the expected answer is one of these correct answer(s) or not: {:.2f}%\".format((count_test_questions_answered/count_test_questions_total)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0099ef-0887-4799-b978-7a70a1864e4c",
        "id": "-h-GjWFWqENU"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the question answering engine. Type exit to quit\n",
            "Which home is an example of italianate architecture?\n",
            "R149\n",
            "italianate architecture\n",
            "Cosine similarity metric is used!\n",
            "Q615196\n",
            "answer:  Fairfield House , similarity score with the expected answer: 0.46\n",
            "answer:  Osborne House , similarity score with the expected answer: 0.41\n",
            "answer:  Hugh Glenn House , similarity score with the expected answer: 0.40\n",
            "answer:  Houses at 37–47 North Fifth Street , similarity score with the expected answer: 0.38\n",
            "answer:  Chatsworth House , similarity score with the expected answer: 0.37\n",
            "answer:  Royal Albert Hall , similarity score with the expected answer: 0.35\n",
            "answer:  Campbell-Rumsey House , similarity score with the expected answer: 0.34\n",
            "answer:  Casa Rosada , similarity score with the expected answer: 0.30\n",
            "answer:  Robinson-Schwenn Building , similarity score with the expected answer: 0.26\n",
            "answer:  Lower East Side Tenement Museum , similarity score with the expected answer: 0.21\n",
            "answer:  Criterion Hotel , similarity score with the expected answer: 0.20\n",
            "answer:  Palacio de los Leones , similarity score with the expected answer: 0.18\n",
            "answer:  Houghton County Courthouse , similarity score with the expected answer: 0.18\n",
            "answer:  Balch Hotel , similarity score with the expected answer: 0.16\n",
            "answer:  Tweed Courthouse , similarity score with the expected answer: 0.15\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what type of object is 25049 christofnorn\n",
            "P31\n",
            "25049 christofnorn\n",
            "Q1753907\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which person was born in liverpool?\n",
            "R19\n",
            "liverpool\n",
            "Q24826\n",
            "answer:  Ringo Starr , similarity score with the expected answer: 1.00\n",
            "answer:  Keith Newton , similarity score with the expected answer: 0.38\n",
            "answer:  Miles Jackson-Lipkin , similarity score with the expected answer: 0.38\n",
            "answer:  Toni Duggan , similarity score with the expected answer: 0.34\n",
            "answer:  Simon Rattle , similarity score with the expected answer: 0.32\n",
            "answer:  Kevin Nolan , similarity score with the expected answer: 0.31\n",
            "answer:  Adam F , similarity score with the expected answer: 0.30\n",
            "answer:  Richard Laurence Millington Synge , similarity score with the expected answer: 0.28\n",
            "answer:  David Johnson , similarity score with the expected answer: 0.28\n",
            "answer:  David Weatherall , similarity score with the expected answer: 0.28\n",
            "answer:  James Heneghan , similarity score with the expected answer: 0.26\n",
            "answer:  Adam Morgan , similarity score with the expected answer: 0.22\n",
            "answer:  William Ewart Gladstone , similarity score with the expected answer: 0.22\n",
            "answer:  Gertrud Luckner , similarity score with the expected answer: 0.20\n",
            "answer:  Zarqa Nawaz , similarity score with the expected answer: 0.14\n",
            "The question is answered correctly!\n",
            "What film genre is twilight considered to be?\n",
            "P136\n",
            "twilight\n",
            "Q44523\n",
            "answer:  romantic fiction , similarity score with the expected answer: 0.71\n",
            "answer:  young adult fiction , similarity score with the expected answer: 0.49\n",
            "answer:  vampire fiction , similarity score with the expected answer: 0.47\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which type of film is the bitter tea of general yen?\n",
            "P136\n",
            "the bitter tea of general yen\n",
            "Cosine similarity metric is used!\n",
            "Q568239\n",
            "answer:  drama film , similarity score with the expected answer: 1.00\n",
            "answer:  film based on literature , similarity score with the expected answer: 0.66\n",
            "answer:  romance film , similarity score with the expected answer: 0.65\n",
            "The question is answered correctly!\n",
            "What is the gender of Athina Maximou\n",
            "P21\n",
            "athina maximou\n",
            "Cosine similarity metric is used!\n",
            "Q757820\n",
            "answer:  male , similarity score with the expected answer: 0.73\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Name an Rolling Stones album\n",
            "R175\n",
            "rolling stones\n",
            "Q11036\n",
            "answer:  Metamorphosis , similarity score with the expected answer: 1.00\n",
            "answer:  Heart of Stone , similarity score with the expected answer: 0.29\n",
            "answer:  Flowers , similarity score with the expected answer: 0.25\n",
            "answer:  Through the Past, Darkly (Big Hits Vol. 2) , similarity score with the expected answer: 0.22\n",
            "answer:  The Last Time , similarity score with the expected answer: 0.15\n",
            "answer:  GRRR! , similarity score with the expected answer: 0.14\n",
            "answer:  More Hot Rocks , similarity score with the expected answer: 0.14\n",
            "answer:  (I Can't Get No) Satisfaction , similarity score with the expected answer: 0.13\n",
            "answer:  Jump Back: The Best of The Rolling Stones , similarity score with the expected answer: 0.13\n",
            "answer:  Live Licks , similarity score with the expected answer: 0.13\n",
            "answer:  Angie , similarity score with the expected answer: 0.12\n",
            "answer:  Rarities 1971–2003 , similarity score with the expected answer: 0.11\n",
            "answer:  Sucking in the Seventies , similarity score with the expected answer: 0.09\n",
            "answer:  No Security , similarity score with the expected answer: 0.06\n",
            "answer:  Fingerprint File , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Who directed woody meets davy crewcut\n",
            "P57\n",
            "woody meets davy crewcut\n",
            "Q8033685\n",
            "answer:  Alex Lovy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "who was the first NSW female Minister of Education died from cancer\n",
            "R509\n",
            "died from cancer\n",
            "Cosine similarity metric is used!\n",
            "Q12078\n",
            "answer:  Kathleen Lonsdale , similarity score with the expected answer: 0.46\n",
            "answer:  Jude Milhon , similarity score with the expected answer: 0.39\n",
            "answer:  Ivory Joe Hunter , similarity score with the expected answer: 0.36\n",
            "answer:  Ivo Lapenna , similarity score with the expected answer: 0.33\n",
            "answer:  Henriette Avram , similarity score with the expected answer: 0.31\n",
            "answer:  Danielle Bunten Berry , similarity score with the expected answer: 0.29\n",
            "answer:  Georges Brassens , similarity score with the expected answer: 0.28\n",
            "answer:  Harry Mulisch , similarity score with the expected answer: 0.28\n",
            "answer:  Marcel Doret , similarity score with the expected answer: 0.28\n",
            "answer:  Juan Antonio Rios , similarity score with the expected answer: 0.26\n",
            "answer:  Michel Rocard , similarity score with the expected answer: 0.24\n",
            "answer:  Robert Mugabe , similarity score with the expected answer: 0.23\n",
            "answer:  Yann-Fañch Kemener , similarity score with the expected answer: 0.12\n",
            "answer:  Pierre Desproges , similarity score with the expected answer: 0.09\n",
            "answer:  Elder Paisios of Mount Athos , similarity score with the expected answer: 0.00\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What position does denis shcherbak play\n",
            "P413\n",
            "denis shcherbak\n",
            "Q4528782\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does the show un refugio para el amor originate from\n",
            "P495\n",
            "un refugio para el amor\n",
            "Cosine similarity metric is used!\n",
            "Q1068093\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what alternative rock band from Chicago is the author of of the blue colour of the sky\n",
            "P175\n",
            "chicago is the author of of the\n",
            "Cosine similarity metric is used!\n",
            "Q5095740\n",
            "Sorry, no answer available\n",
            "who is the artist that performed on the album sample and hold: attack decay sustain release?\n",
            "P175\n",
            "sample and hold :\n",
            "Cosine similarity metric is used!\n",
            "Q7410135\n",
            "answer:  Simian Mobile Disco , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "where john brewster jr. was born\n",
            "P19\n",
            "where john brewster jr\n",
            "Cosine similarity metric is used!\n",
            "Q6223118\n",
            "answer:  Hampton , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a multiplayer game?\n",
            "R404\n",
            "a multiplayer game\n",
            "Cosine similarity metric is used!\n",
            "Q6895044\n",
            "answer:  Heroes of Might and Magic V: Tribes of the East , similarity score with the expected answer: 0.55\n",
            "answer:  Commandos 2: Men of Courage , similarity score with the expected answer: 0.49\n",
            "answer:  Heroes of Might and Magic V: Hammers of Fate , similarity score with the expected answer: 0.45\n",
            "answer:  Heroes of Might and Magic V , similarity score with the expected answer: 0.42\n",
            "answer:  Uncharted 2: Among Thieves , similarity score with the expected answer: 0.41\n",
            "answer:  Civilization III , similarity score with the expected answer: 0.40\n",
            "answer:  Civilization IV , similarity score with the expected answer: 0.37\n",
            "answer:  Uncharted 3: Drake's Deception , similarity score with the expected answer: 0.34\n",
            "answer:  Civilization V , similarity score with the expected answer: 0.32\n",
            "answer:  Super Mario Bros. , similarity score with the expected answer: 0.27\n",
            "answer:  Donkey Kong , similarity score with the expected answer: 0.27\n",
            "answer:  Freedom Force vs the 3rd Reich , similarity score with the expected answer: 0.22\n",
            "answer:  Grand Theft Auto V , similarity score with the expected answer: 0.17\n",
            "answer:  Need for Speed: Shift , similarity score with the expected answer: 0.11\n",
            "answer:  Football Manager , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which company produced hot enough for june\n",
            "P272\n",
            "hot enough for june\n",
            "Cosine similarity metric is used!\n",
            "Q12124859\n",
            "answer:  Rank Organisation , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "is jose figueroa alcorta from argentina or costa rica\n",
            "P27\n",
            "jose figueroa alcorta\n",
            "Q442729\n",
            "answer:  Argentina , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What kind of game is microsoft international soccer 2000\n",
            "P136\n",
            "microsoft international soccer 2000\n",
            "Q3312381\n",
            "answer:  association football video game , similarity score with the expected answer: 0.81\n",
            "The question is answered correctly!\n",
            "who is the composer of the song liar?\n",
            "P86\n",
            "liar\n",
            "Q124707535\n",
            "Sorry, no answer available\n",
            "Joshua Kimmich is member of which sports team?\n",
            "P641\n",
            "joshua kimmich\n",
            "Q13865408\n",
            "answer:  association football , similarity score with the expected answer: 0.50\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the name of a folk rock singer (or group)?\n",
            "R136\n",
            "folk rock\n",
            "Q186472\n",
            "answer:  Emily Saliers , similarity score with the expected answer: 0.39\n",
            "answer:  John Kadlecik , similarity score with the expected answer: 0.38\n",
            "answer:  Maureen Tucker , similarity score with the expected answer: 0.36\n",
            "answer:  Spencer Breslin , similarity score with the expected answer: 0.31\n",
            "answer:  Grateful Dead , similarity score with the expected answer: 0.30\n",
            "answer:  Lisa Loeb , similarity score with the expected answer: 0.28\n",
            "answer:  Hoven Droven , similarity score with the expected answer: 0.27\n",
            "answer:  Jem , similarity score with the expected answer: 0.24\n",
            "answer:  American Beauty , similarity score with the expected answer: 0.21\n",
            "answer:  Bron-Y-Aur Stomp , similarity score with the expected answer: 0.20\n",
            "answer:  4 Way Street , similarity score with the expected answer: 0.14\n",
            "answer:  Déjà Vu , similarity score with the expected answer: 0.14\n",
            "answer:  The Battle of Evermore , similarity score with the expected answer: 0.14\n",
            "answer:  Manassas , similarity score with the expected answer: 0.09\n",
            "answer:  Markéta Irglová , similarity score with the expected answer: 0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Who was born in dakar?\n",
            "R19\n",
            "dakar\n",
            "Q3718\n",
            "answer:  Mamadou Diabang , similarity score with the expected answer: 0.50\n",
            "answer:  Lamine Diack , similarity score with the expected answer: 0.41\n",
            "answer:  Bineta Diedhiou , similarity score with the expected answer: 0.40\n",
            "answer:  Abdoul Mbaye , similarity score with the expected answer: 0.38\n",
            "answer:  Patrick Vieira , similarity score with the expected answer: 0.38\n",
            "answer:  Pape Abdou Camara , similarity score with the expected answer: 0.37\n",
            "answer:  Mouhamadou Dabo , similarity score with the expected answer: 0.36\n",
            "answer:  Idrissa Gueye , similarity score with the expected answer: 0.35\n",
            "answer:  Pape Alioune Diouf , similarity score with the expected answer: 0.34\n",
            "answer:  José Brito , similarity score with the expected answer: 0.34\n",
            "answer:  Mansour Gueye , similarity score with the expected answer: 0.33\n",
            "answer:  Patrice Evra , similarity score with the expected answer: 0.33\n",
            "answer:  Mame Biram Diouf , similarity score with the expected answer: 0.32\n",
            "answer:  Boniface N'Dong , similarity score with the expected answer: 0.27\n",
            "answer:  Henri Saivet , similarity score with the expected answer: 0.25\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "where did edward i. edwards died\n",
            "P20\n",
            "edward i edwards\n",
            "Cosine similarity metric is used!\n",
            "Q436902\n",
            "answer:  Jersey City , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the sex of david swift?\n",
            "P21\n",
            "david swift\n",
            "Q5240208\n",
            "answer:  male , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What language is mission to caracas written in\n",
            "P364\n",
            "mission to caracas\n",
            "Cosine similarity metric is used!\n",
            "Q6878840\n",
            "answer:  French , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what genre is the album why is there air?\n",
            "P136\n",
            "why is there air\n",
            "Cosine similarity metric is used!\n",
            "Q7997809\n",
            "answer:  stand-up comedy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is chad mustard's nationality\n",
            "P27\n",
            "chad mustard\n",
            "Q5066318\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is an instrument played by carl jackson\n",
            "P1303\n",
            "carl jackson\n",
            "Q5040368\n",
            "answer:  guitar , similarity score with the expected answer: 1.00\n",
            "answer:  mandolin , similarity score with the expected answer: 0.62\n",
            "answer:  banjo , similarity score with the expected answer: 0.57\n",
            "The question is answered correctly!\n",
            "Which is Aristotle Onassis profession?\n",
            "P106\n",
            "aristotle onassis\n",
            "Q180455\n",
            "answer:  ship-owner , similarity score with the expected answer: 1.00\n",
            "answer:  businessperson , similarity score with the expected answer: 0.45\n",
            "answer:  entrepreneur , similarity score with the expected answer: 0.33\n",
            "The question is answered correctly!\n",
            "what genre of music does bo diddley play?\n",
            "P136\n",
            "bo diddley\n",
            "Q10431795\n",
            "Sorry, no answer available\n",
            "Which genre of music was the album duck rock labeled?\n",
            "P136\n",
            "duck rock\n",
            "Q910692\n",
            "answer:  new wave , similarity score with the expected answer: 1.00\n",
            "answer:  rock music , similarity score with the expected answer: 0.27\n",
            "answer:  hip hop music , similarity score with the expected answer: 0.16\n",
            "The question is answered correctly!\n",
            "what is Michael Ballack's country of nationality\n",
            "P27\n",
            "michael ballack\n",
            "Q11948\n",
            "answer:  Germany , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what football position does dorin dickerson play at?\n",
            "P413\n",
            "dorin dickerson\n",
            "Q3037050\n",
            "answer:  wide receiver , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country is purple people eater filmed in?\n",
            "P495\n",
            "purple people eater\n",
            "Q3410974\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "idris phillips follows this major religion.\n",
            "P140\n",
            "idris phillips\n",
            "Q16192877\n",
            "answer:  Islam , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what instrument does ashwin sood play?\n",
            "P1303\n",
            "ashwin sood\n",
            "Q4806196\n",
            "answer:  drum kit , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Where was gunnar johansen born in Denmark?\n",
            "P19\n",
            "gunnar johansen\n",
            "Q445899\n",
            "answer:  Copenhagen , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the country of origin of the show tok! tok! tok! isang milyon pasok!\n",
            "P495\n",
            "show tok tok\n",
            "Cosine similarity metric is used!\n",
            "Q7813436\n",
            "answer:  Philippines , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the political ideology behind the german free-minded party?\n",
            "P1142\n",
            "free - minded party\n",
            "Cosine similarity metric is used!\n",
            "Q560777\n",
            "answer:  progressivism , similarity score with the expected answer: 1.00\n",
            "answer:  liberalism , similarity score with the expected answer: 0.42\n",
            "answer:  laicism , similarity score with the expected answer: 0.31\n",
            "The question is answered correctly!\n",
            "Name an territorial entity which is contained in England\n",
            "R17\n",
            "england\n",
            "Q21\n",
            "answer:  Cornish English , similarity score with the expected answer: 0.39\n",
            "answer:  Fawcett family , similarity score with the expected answer: 0.17\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what is a silent film from 1927\n",
            "R136\n",
            "silent film\n",
            "Q226730\n",
            "answer:  Modern Times , similarity score with the expected answer: 0.34\n",
            "answer:  King of the Circus , similarity score with the expected answer: 0.28\n",
            "answer:  The Broken Coin , similarity score with the expected answer: 0.28\n",
            "answer:  The Green Archer , similarity score with the expected answer: 0.26\n",
            "answer:  The Hawk's Trail , similarity score with the expected answer: 0.25\n",
            "answer:  The Pleasure Garden , similarity score with the expected answer: 0.24\n",
            "answer:  The Screaming Shadow , similarity score with the expected answer: 0.24\n",
            "answer:  Daredevil Jack , similarity score with the expected answer: 0.21\n",
            "answer:  Baseball and Bloomers , similarity score with the expected answer: 0.19\n",
            "answer:  Das wandernde Bild , similarity score with the expected answer: 0.19\n",
            "answer:  Eugene Onegin , similarity score with the expected answer: 0.19\n",
            "answer:  Symphonie diagonale , similarity score with the expected answer: 0.18\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.16\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.12\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.09\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "The power rangers dino thunder game was published by what American company?\n",
            "P123\n",
            "the power rangers dino thunder\n",
            "Cosine similarity metric is used!\n",
            "Q11888796\n",
            "answer:  THQ , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which was the country of citizehship of christopher robinson\n",
            "P27\n",
            "citizehship of christopher\n",
            "Cosine similarity metric is used!\n",
            "Q7322\n",
            "answer:  Republic of Genoa , similarity score with the expected answer: 0.40\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Which position was David Beckham played\n",
            "P413\n",
            "david beckham\n",
            "Q10520\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is the second level division of the division crixas do tocantins\n",
            "P17\n",
            "crixas do\n",
            "Cosine similarity metric is used!\n",
            "Q1801175\n",
            "answer:  Brazil , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which film was directed by ian iqbal rashid\n",
            "R57\n",
            "ian iqbal rashid\n",
            "Q15461094\n",
            "answer:  Touch of Pink , similarity score with the expected answer: 1.00\n",
            "answer:  How She Move , similarity score with the expected answer: 0.23\n",
            "The question is answered correctly!\n",
            "Which genre of book is bin laden: the man who declared war on america?\n",
            "P136\n",
            "bin laden : the man who declared war\n",
            "Cosine similarity metric is used!\n",
            "Q4913778\n",
            "answer:  biography , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does dany saadia belong to\n",
            "P27\n",
            "dany saadia\n",
            "Q5221412\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is largemouth bass\n",
            "P136\n",
            "largemouth bass\n",
            "Q755105\n",
            "Sorry, no answer available\n",
            "does british music band crawler play blues-rock or classical\n",
            "P136\n",
            "crawler\n",
            "Q108882180\n",
            "Sorry, no answer available\n",
            "what river does the neville island bridge cross\n",
            "P17\n",
            "neville island bridge\n",
            "Q7004736\n",
            "answer:  United States of America , similarity score with the expected answer: 0.28\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what was the country of origin of the tv show sidewalks entertainment\n",
            "P495\n",
            "show sidewalks entertainment\n",
            "Cosine similarity metric is used!\n",
            "Q7508530\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which notable person has Rome as place of death\n",
            "P20\n",
            "rome\n",
            "Q220\n",
            "Sorry, no answer available\n",
            "what is the category of the celestial object 1241 dysona\n",
            "P31\n",
            "1241 dysona\n",
            "Q137259\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a city in yolo county in california\n",
            "R131\n",
            "yolo county\n",
            "Q109709\n",
            "answer:  Coast Starlight , similarity score with the expected answer: 0.23\n",
            "answer:  Capitol Corridor , similarity score with the expected answer: 0.20\n",
            "answer:  California State Route 84 , similarity score with the expected answer: 0.16\n",
            "answer:  California State Route 16 , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 5 in California , similarity score with the expected answer: 0.15\n",
            "answer:  West Sacramento , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 505 , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 113 , similarity score with the expected answer: 0.14\n",
            "answer:  Davis , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 275 , similarity score with the expected answer: 0.13\n",
            "answer:  California State Route 128 , similarity score with the expected answer: 0.11\n",
            "answer:  Interstate 80 in California , similarity score with the expected answer: 0.10\n",
            "answer:  Woodland , similarity score with the expected answer: 0.10\n",
            "answer:  California State Route 45 , similarity score with the expected answer: 0.07\n",
            "answer:  U.S. Route 50 in California , similarity score with the expected answer: -0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which place was named after john radcliffe (english physician)\n",
            "R138\n",
            "john radcliffe\n",
            "Q922508\n",
            "answer:  John Radcliffe Hospital , similarity score with the expected answer: 1.00\n",
            "answer:  Radcliffe Infirmary , similarity score with the expected answer: 0.74\n",
            "answer:  Radcliffe Camera , similarity score with the expected answer: 0.58\n",
            "answer:  The Radcliffe Trust , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Square , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Science Library , similarity score with the expected answer: 0.52\n",
            "answer:  Radcliffe Quadrangle , similarity score with the expected answer: 0.49\n",
            "answer:  Radcliffe Observatory , similarity score with the expected answer: 0.48\n",
            "The question is answered correctly!\n",
            "What is Albert Einstein occupation?\n",
            "P106\n",
            "albert einstein\n",
            "Q937\n",
            "answer:  physicist , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which is the film's crying freeman country of origin?\n",
            "P495\n",
            "crying freeman\n",
            "Q1117884\n",
            "answer:  Japan , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "what kind of music is played on film life and death of an american fourtracker\n",
            "P86\n",
            "life and death of an\n",
            "Cosine similarity metric is used!\n",
            "Q1546792\n",
            "answer:  Allan Gray , similarity score with the expected answer: 0.23\n",
            "The question is not answered correctly!\n",
            "what's the name of an documentary film\n",
            "R136\n",
            "documentary film\n",
            "Q93204\n",
            "answer:  Visions of Light , similarity score with the expected answer: 1.00\n",
            "answer:  Special Effects: Anything Can Happen , similarity score with the expected answer: 0.36\n",
            "answer:  Fellini: A Director's Notebook , similarity score with the expected answer: 0.24\n",
            "answer:  The Clowns , similarity score with the expected answer: 0.23\n",
            "answer:  Isle of Flowers , similarity score with the expected answer: 0.20\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.19\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.19\n",
            "answer:  Kony 2012 , similarity score with the expected answer: 0.18\n",
            "answer:  Black Box BRD , similarity score with the expected answer: 0.17\n",
            "answer:  ¿¡Revolución!? , similarity score with the expected answer: 0.15\n",
            "answer:  Farewell to Enrico Berlinguer , similarity score with the expected answer: 0.12\n",
            "answer:  The Revolution Will Not Be Televised , similarity score with the expected answer: 0.12\n",
            "answer:  We Live in Public , similarity score with the expected answer: 0.11\n",
            "answer:  Frat Party at the Pankake Festival , similarity score with the expected answer: 0.11\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.07\n",
            "The question is answered correctly!\n",
            "exit\n",
            "39\n",
            "14\n",
            "60\n",
            "The percentage of the test questions that are answered correct is: 65.00%\n",
            "The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\n",
            "regardless if the expected answer is one of these correct answer(s) or not: 23.33%\n"
          ]
        }
      ],
      "source": [
        "#Question Answering engine\n",
        "activation_relation_best_parameters_path = 'drive/MyDrive/Relation_indexes_models_best_parameters/Answerable_Questions/ELU/relation_prediction_span_encoded_not_ignoring_answerable_questions_ELU.pt'\n",
        "activation_entity_best_parameters_path =  \"drive/MyDrive/Entity_span_indexes_models_best_parameters/Answerable_Questions/ELU/entity_span_encoded_prediction_not_ignoring_answerable_questions_ELU.pt\"\n",
        "print('This is the question answering engine. Type exit to quit')\n",
        "dropout_prob = 0.3\n",
        "count_test_questions_total = 0\n",
        "count_test_questions_correct_answered = 0\n",
        "count_test_questions_answered = 0\n",
        "while(1):\n",
        "  question = input()\n",
        "  if question == \"exit\":\n",
        "    break;\n",
        "  else:\n",
        "    count_test_questions_total += 1\n",
        "  #Find the real answer, relation id and entity id of the input question from the corresponding .txt file.\n",
        "  for i in range(len(testing_questions)):\n",
        "    if testing_questions[i] == question:\n",
        "      real_question_answer_label = testing_questions_answer_labels[i]\n",
        "      real_question_entity_id = testing_questions_entity_ids[i]\n",
        "      real_question_relation_id = testing_questions_relation_ids[i]\n",
        "      break\n",
        "  question_correct_answered, question_answered = answer(question, Endict, entities, rel_answerable_vocab, len(rel_answerable_vocab), tokenizer, quests, similarity_model, max(q_lengths), \"ELU\", \"ELU\", activation_relation_best_parameters_path, activation_entity_best_parameters_path, dropout_prob, SEED, real_question_answer_label, real_question_entity_id, real_question_relation_id)\n",
        "  if question_correct_answered == 1:\n",
        "    count_test_questions_correct_answered += 1\n",
        "  if question_answered == 1:\n",
        "    count_test_questions_answered += 1\n",
        "print(count_test_questions_correct_answered)\n",
        "print(count_test_questions_answered)\n",
        "print(count_test_questions_total)\n",
        "print(\"The percentage of the test questions that are answered correct is: {:.2f}%\".format((count_test_questions_correct_answered/count_test_questions_total)*100))\n",
        "print(\"The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\\nregardless if the expected answer is one of these correct answer(s) or not: {:.2f}%\".format((count_test_questions_answered/count_test_questions_total)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e5a82b-da7c-4173-fa64-45a90adf8872",
        "id": "siZVv5z-r7sY"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the question answering engine. Type exit to quit\n",
            "Which home is an example of italianate architecture?\n",
            "R149\n",
            "italianate architecture\n",
            "Cosine similarity metric is used!\n",
            "Q615196\n",
            "answer:  Fairfield House , similarity score with the expected answer: 0.46\n",
            "answer:  Osborne House , similarity score with the expected answer: 0.41\n",
            "answer:  Hugh Glenn House , similarity score with the expected answer: 0.40\n",
            "answer:  Houses at 37–47 North Fifth Street , similarity score with the expected answer: 0.38\n",
            "answer:  Chatsworth House , similarity score with the expected answer: 0.37\n",
            "answer:  Royal Albert Hall , similarity score with the expected answer: 0.35\n",
            "answer:  Campbell-Rumsey House , similarity score with the expected answer: 0.34\n",
            "answer:  Casa Rosada , similarity score with the expected answer: 0.30\n",
            "answer:  Robinson-Schwenn Building , similarity score with the expected answer: 0.26\n",
            "answer:  Lower East Side Tenement Museum , similarity score with the expected answer: 0.21\n",
            "answer:  Criterion Hotel , similarity score with the expected answer: 0.20\n",
            "answer:  Palacio de los Leones , similarity score with the expected answer: 0.18\n",
            "answer:  Houghton County Courthouse , similarity score with the expected answer: 0.18\n",
            "answer:  Balch Hotel , similarity score with the expected answer: 0.16\n",
            "answer:  Tweed Courthouse , similarity score with the expected answer: 0.15\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what type of object is 25049 christofnorn\n",
            "P31\n",
            "25049 christofnorn\n",
            "Q1753907\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which person was born in liverpool?\n",
            "R19\n",
            "liverpool\n",
            "Q24826\n",
            "answer:  Ringo Starr , similarity score with the expected answer: 1.00\n",
            "answer:  Keith Newton , similarity score with the expected answer: 0.38\n",
            "answer:  Miles Jackson-Lipkin , similarity score with the expected answer: 0.38\n",
            "answer:  Toni Duggan , similarity score with the expected answer: 0.34\n",
            "answer:  Simon Rattle , similarity score with the expected answer: 0.32\n",
            "answer:  Kevin Nolan , similarity score with the expected answer: 0.31\n",
            "answer:  Adam F , similarity score with the expected answer: 0.30\n",
            "answer:  Richard Laurence Millington Synge , similarity score with the expected answer: 0.28\n",
            "answer:  David Johnson , similarity score with the expected answer: 0.28\n",
            "answer:  David Weatherall , similarity score with the expected answer: 0.28\n",
            "answer:  James Heneghan , similarity score with the expected answer: 0.26\n",
            "answer:  Adam Morgan , similarity score with the expected answer: 0.22\n",
            "answer:  William Ewart Gladstone , similarity score with the expected answer: 0.22\n",
            "answer:  Gertrud Luckner , similarity score with the expected answer: 0.20\n",
            "answer:  Zarqa Nawaz , similarity score with the expected answer: 0.14\n",
            "The question is answered correctly!\n",
            "What film genre is twilight considered to be?\n",
            "P136\n",
            "twilight\n",
            "Q44523\n",
            "answer:  romantic fiction , similarity score with the expected answer: 0.71\n",
            "answer:  young adult fiction , similarity score with the expected answer: 0.49\n",
            "answer:  vampire fiction , similarity score with the expected answer: 0.47\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which type of film is the bitter tea of general yen?\n",
            "P136\n",
            "the bitter tea of general yen\n",
            "Cosine similarity metric is used!\n",
            "Q568239\n",
            "answer:  drama film , similarity score with the expected answer: 1.00\n",
            "answer:  film based on literature , similarity score with the expected answer: 0.66\n",
            "answer:  romance film , similarity score with the expected answer: 0.65\n",
            "The question is answered correctly!\n",
            "What is the gender of Athina Maximou\n",
            "P21\n",
            "athina maximou\n",
            "Cosine similarity metric is used!\n",
            "Q757820\n",
            "answer:  male , similarity score with the expected answer: 0.73\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Name an Rolling Stones album\n",
            "R175\n",
            "rolling stones\n",
            "Q11036\n",
            "answer:  Metamorphosis , similarity score with the expected answer: 1.00\n",
            "answer:  Heart of Stone , similarity score with the expected answer: 0.29\n",
            "answer:  Flowers , similarity score with the expected answer: 0.25\n",
            "answer:  Through the Past, Darkly (Big Hits Vol. 2) , similarity score with the expected answer: 0.22\n",
            "answer:  The Last Time , similarity score with the expected answer: 0.15\n",
            "answer:  GRRR! , similarity score with the expected answer: 0.14\n",
            "answer:  More Hot Rocks , similarity score with the expected answer: 0.14\n",
            "answer:  (I Can't Get No) Satisfaction , similarity score with the expected answer: 0.13\n",
            "answer:  Jump Back: The Best of The Rolling Stones , similarity score with the expected answer: 0.13\n",
            "answer:  Live Licks , similarity score with the expected answer: 0.13\n",
            "answer:  Angie , similarity score with the expected answer: 0.12\n",
            "answer:  Rarities 1971–2003 , similarity score with the expected answer: 0.11\n",
            "answer:  Sucking in the Seventies , similarity score with the expected answer: 0.09\n",
            "answer:  No Security , similarity score with the expected answer: 0.06\n",
            "answer:  Fingerprint File , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Who directed woody meets davy crewcut\n",
            "P57\n",
            "woody meets davy crewcut\n",
            "Q8033685\n",
            "answer:  Alex Lovy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "who was the first NSW female Minister of Education died from cancer\n",
            "R509\n",
            "died from cancer\n",
            "Cosine similarity metric is used!\n",
            "Q12078\n",
            "answer:  Kathleen Lonsdale , similarity score with the expected answer: 0.46\n",
            "answer:  Jude Milhon , similarity score with the expected answer: 0.39\n",
            "answer:  Ivory Joe Hunter , similarity score with the expected answer: 0.36\n",
            "answer:  Ivo Lapenna , similarity score with the expected answer: 0.33\n",
            "answer:  Henriette Avram , similarity score with the expected answer: 0.31\n",
            "answer:  Danielle Bunten Berry , similarity score with the expected answer: 0.29\n",
            "answer:  Georges Brassens , similarity score with the expected answer: 0.28\n",
            "answer:  Harry Mulisch , similarity score with the expected answer: 0.28\n",
            "answer:  Marcel Doret , similarity score with the expected answer: 0.28\n",
            "answer:  Juan Antonio Rios , similarity score with the expected answer: 0.26\n",
            "answer:  Michel Rocard , similarity score with the expected answer: 0.24\n",
            "answer:  Robert Mugabe , similarity score with the expected answer: 0.23\n",
            "answer:  Yann-Fañch Kemener , similarity score with the expected answer: 0.12\n",
            "answer:  Pierre Desproges , similarity score with the expected answer: 0.09\n",
            "answer:  Elder Paisios of Mount Athos , similarity score with the expected answer: 0.00\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What position does denis shcherbak play\n",
            "P413\n",
            "denis shcherbak\n",
            "Q4528782\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does the show un refugio para el amor originate from\n",
            "P495\n",
            "un refugio para el amor\n",
            "Cosine similarity metric is used!\n",
            "Q1068093\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what alternative rock band from Chicago is the author of of the blue colour of the sky\n",
            "P175\n",
            "chicago\n",
            "Q1297\n",
            "Sorry, no answer available\n",
            "who is the artist that performed on the album sample and hold: attack decay sustain release?\n",
            "P175\n",
            "sample and hold\n",
            "Cosine similarity metric is used!\n",
            "Q7410135\n",
            "answer:  Simian Mobile Disco , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "where john brewster jr. was born\n",
            "P19\n",
            "where john brewster jr\n",
            "Cosine similarity metric is used!\n",
            "Q6223118\n",
            "answer:  Hampton , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a multiplayer game?\n",
            "R404\n",
            "a multiplayer game\n",
            "Cosine similarity metric is used!\n",
            "Q6895044\n",
            "answer:  Heroes of Might and Magic V: Tribes of the East , similarity score with the expected answer: 0.55\n",
            "answer:  Commandos 2: Men of Courage , similarity score with the expected answer: 0.49\n",
            "answer:  Heroes of Might and Magic V: Hammers of Fate , similarity score with the expected answer: 0.45\n",
            "answer:  Heroes of Might and Magic V , similarity score with the expected answer: 0.42\n",
            "answer:  Uncharted 2: Among Thieves , similarity score with the expected answer: 0.41\n",
            "answer:  Civilization III , similarity score with the expected answer: 0.40\n",
            "answer:  Civilization IV , similarity score with the expected answer: 0.37\n",
            "answer:  Uncharted 3: Drake's Deception , similarity score with the expected answer: 0.34\n",
            "answer:  Civilization V , similarity score with the expected answer: 0.32\n",
            "answer:  Super Mario Bros. , similarity score with the expected answer: 0.27\n",
            "answer:  Donkey Kong , similarity score with the expected answer: 0.27\n",
            "answer:  Freedom Force vs the 3rd Reich , similarity score with the expected answer: 0.22\n",
            "answer:  Grand Theft Auto V , similarity score with the expected answer: 0.17\n",
            "answer:  Need for Speed: Shift , similarity score with the expected answer: 0.11\n",
            "answer:  Football Manager , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which company produced hot enough for june\n",
            "P272\n",
            "hot enough for june\n",
            "Cosine similarity metric is used!\n",
            "Q12124859\n",
            "answer:  Rank Organisation , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "is jose figueroa alcorta from argentina or costa rica\n",
            "P27\n",
            "jose figueroa alcorta\n",
            "Q442729\n",
            "answer:  Argentina , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What kind of game is microsoft international soccer 2000\n",
            "P136\n",
            "microsoft international soccer 2000\n",
            "Q3312381\n",
            "answer:  association football video game , similarity score with the expected answer: 0.81\n",
            "The question is answered correctly!\n",
            "who is the composer of the song liar?\n",
            "P86\n",
            "liar\n",
            "Q6540228\n",
            "Sorry, no answer available\n",
            "Joshua Kimmich is member of which sports team?\n",
            "P641\n",
            "joshua kimmich\n",
            "Q13865408\n",
            "answer:  association football , similarity score with the expected answer: 0.50\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the name of a folk rock singer (or group)?\n",
            "R136\n",
            "folk rock\n",
            "Q186472\n",
            "answer:  Neil Young , similarity score with the expected answer: 1.00\n",
            "answer:  Paul Simon , similarity score with the expected answer: 0.53\n",
            "answer:  Bob Dylan , similarity score with the expected answer: 0.48\n",
            "answer:  Alan Stivell , similarity score with the expected answer: 0.44\n",
            "answer:  Leonard Cohen , similarity score with the expected answer: 0.44\n",
            "answer:  Marcus Mumford , similarity score with the expected answer: 0.39\n",
            "answer:  Amy Macdonald , similarity score with the expected answer: 0.37\n",
            "answer:  George Harrison , similarity score with the expected answer: 0.36\n",
            "answer:  The Beatles , similarity score with the expected answer: 0.31\n",
            "answer:  Led Zeppelin , similarity score with the expected answer: 0.28\n",
            "answer:  Cher , similarity score with the expected answer: 0.22\n",
            "answer:  Tri Yann , similarity score with the expected answer: 0.22\n",
            "answer:  Denez Prigent , similarity score with the expected answer: 0.16\n",
            "answer:  Tsvety , similarity score with the expected answer: 0.10\n",
            "answer:  Iļģi , similarity score with the expected answer: 0.06\n",
            "The question is answered correctly!\n",
            "Who was born in dakar?\n",
            "R19\n",
            "dakar\n",
            "Q3718\n",
            "answer:  Mamadou Diabang , similarity score with the expected answer: 0.50\n",
            "answer:  Lamine Diack , similarity score with the expected answer: 0.41\n",
            "answer:  Bineta Diedhiou , similarity score with the expected answer: 0.40\n",
            "answer:  Abdoul Mbaye , similarity score with the expected answer: 0.38\n",
            "answer:  Patrick Vieira , similarity score with the expected answer: 0.38\n",
            "answer:  Pape Abdou Camara , similarity score with the expected answer: 0.37\n",
            "answer:  Mouhamadou Dabo , similarity score with the expected answer: 0.36\n",
            "answer:  Idrissa Gueye , similarity score with the expected answer: 0.35\n",
            "answer:  Pape Alioune Diouf , similarity score with the expected answer: 0.34\n",
            "answer:  José Brito , similarity score with the expected answer: 0.34\n",
            "answer:  Mansour Gueye , similarity score with the expected answer: 0.33\n",
            "answer:  Patrice Evra , similarity score with the expected answer: 0.33\n",
            "answer:  Mame Biram Diouf , similarity score with the expected answer: 0.32\n",
            "answer:  Boniface N'Dong , similarity score with the expected answer: 0.27\n",
            "answer:  Henri Saivet , similarity score with the expected answer: 0.25\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "where did edward i. edwards died\n",
            "P20\n",
            "edward i edwards\n",
            "Cosine similarity metric is used!\n",
            "Q436902\n",
            "answer:  Jersey City , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the sex of david swift?\n",
            "P21\n",
            "david swift\n",
            "Q5240208\n",
            "answer:  male , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What language is mission to caracas written in\n",
            "P364\n",
            "mission to caracas\n",
            "Cosine similarity metric is used!\n",
            "Q6878840\n",
            "answer:  French , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what genre is the album why is there air?\n",
            "P136\n",
            "why is there air\n",
            "Cosine similarity metric is used!\n",
            "Q7997809\n",
            "answer:  stand-up comedy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is chad mustard's nationality\n",
            "P27\n",
            "chad mustard\n",
            "Q5066318\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is an instrument played by carl jackson\n",
            "P1303\n",
            "carl jackson\n",
            "Q5040368\n",
            "answer:  guitar , similarity score with the expected answer: 1.00\n",
            "answer:  mandolin , similarity score with the expected answer: 0.62\n",
            "answer:  banjo , similarity score with the expected answer: 0.57\n",
            "The question is answered correctly!\n",
            "Which is Aristotle Onassis profession?\n",
            "P106\n",
            "aristotle onassis\n",
            "Q180455\n",
            "answer:  ship-owner , similarity score with the expected answer: 1.00\n",
            "answer:  businessperson , similarity score with the expected answer: 0.45\n",
            "answer:  entrepreneur , similarity score with the expected answer: 0.33\n",
            "The question is answered correctly!\n",
            "what genre of music does bo diddley play?\n",
            "P136\n",
            "bo diddley\n",
            "Q10431795\n",
            "Sorry, no answer available\n",
            "Which genre of music was the album duck rock labeled?\n",
            "P136\n",
            "duck rock\n",
            "Q910692\n",
            "answer:  new wave , similarity score with the expected answer: 1.00\n",
            "answer:  rock music , similarity score with the expected answer: 0.27\n",
            "answer:  hip hop music , similarity score with the expected answer: 0.16\n",
            "The question is answered correctly!\n",
            "what is Michael Ballack's country of nationality\n",
            "P27\n",
            "michael ballack\n",
            "Q11948\n",
            "answer:  Germany , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what football position does dorin dickerson play at?\n",
            "P413\n",
            "dorin dickerson\n",
            "Q3037050\n",
            "answer:  wide receiver , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country is purple people eater filmed in?\n",
            "P495\n",
            "purple people eater\n",
            "Q3410974\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "idris phillips follows this major religion.\n",
            "P140\n",
            "idris phillips\n",
            "Q16192877\n",
            "answer:  Islam , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what instrument does ashwin sood play?\n",
            "P1303\n",
            "ashwin sood\n",
            "Q4806196\n",
            "answer:  drum kit , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Where was gunnar johansen born in Denmark?\n",
            "P19\n",
            "gunnar johansen\n",
            "Q445899\n",
            "answer:  Copenhagen , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the country of origin of the show tok! tok! tok! isang milyon pasok!\n",
            "P495\n",
            "tok tok\n",
            "Q17034570\n",
            "answer:  Egypt , similarity score with the expected answer: 0.37\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the political ideology behind the german free-minded party?\n",
            "P1142\n",
            "german free - minded party\n",
            "Cosine similarity metric is used!\n",
            "Q560777\n",
            "answer:  progressivism , similarity score with the expected answer: 1.00\n",
            "answer:  liberalism , similarity score with the expected answer: 0.42\n",
            "answer:  laicism , similarity score with the expected answer: 0.31\n",
            "The question is answered correctly!\n",
            "Name an territorial entity which is contained in England\n",
            "R17\n",
            "england\n",
            "Q21\n",
            "answer:  Cornish English , similarity score with the expected answer: 0.39\n",
            "answer:  Fawcett family , similarity score with the expected answer: 0.17\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what is a silent film from 1927\n",
            "R136\n",
            "silent film\n",
            "Q226730\n",
            "answer:  Modern Times , similarity score with the expected answer: 0.34\n",
            "answer:  King of the Circus , similarity score with the expected answer: 0.28\n",
            "answer:  The Broken Coin , similarity score with the expected answer: 0.28\n",
            "answer:  The Green Archer , similarity score with the expected answer: 0.26\n",
            "answer:  The Hawk's Trail , similarity score with the expected answer: 0.25\n",
            "answer:  The Pleasure Garden , similarity score with the expected answer: 0.24\n",
            "answer:  The Screaming Shadow , similarity score with the expected answer: 0.24\n",
            "answer:  Daredevil Jack , similarity score with the expected answer: 0.21\n",
            "answer:  Baseball and Bloomers , similarity score with the expected answer: 0.19\n",
            "answer:  Das wandernde Bild , similarity score with the expected answer: 0.19\n",
            "answer:  Eugene Onegin , similarity score with the expected answer: 0.19\n",
            "answer:  Symphonie diagonale , similarity score with the expected answer: 0.18\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.16\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.12\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.09\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "The power rangers dino thunder game was published by what American company?\n",
            "P123\n",
            "the power rangers dino thunder\n",
            "Cosine similarity metric is used!\n",
            "Q11888796\n",
            "answer:  THQ , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which was the country of citizehship of christopher robinson\n",
            "P27\n",
            "citizehship of christopher robinson\n",
            "Cosine similarity metric is used!\n",
            "Q370264\n",
            "answer:  Canada , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "Which position was David Beckham played\n",
            "P413\n",
            "david beckham\n",
            "Q10520\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is the second level division of the division crixas do tocantins\n",
            "P17\n",
            "crixas do\n",
            "Cosine similarity metric is used!\n",
            "Q1801175\n",
            "answer:  Brazil , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which film was directed by ian iqbal rashid\n",
            "R57\n",
            "ian iqbal rashid\n",
            "Q15461094\n",
            "answer:  Touch of Pink , similarity score with the expected answer: 1.00\n",
            "answer:  How She Move , similarity score with the expected answer: 0.23\n",
            "The question is answered correctly!\n",
            "Which genre of book is bin laden: the man who declared war on america?\n",
            "P136\n",
            "bin laden : the man who declared war\n",
            "Cosine similarity metric is used!\n",
            "Q4913778\n",
            "answer:  biography , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does dany saadia belong to\n",
            "P27\n",
            "dany saadia\n",
            "Q5221412\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is largemouth bass\n",
            "P136\n",
            "largemouth bass\n",
            "Q755105\n",
            "Sorry, no answer available\n",
            "does british music band crawler play blues-rock or classical\n",
            "P136\n",
            "crawler\n",
            "Q108882180\n",
            "Sorry, no answer available\n",
            "what river does the neville island bridge cross\n",
            "P17\n",
            "neville island bridge\n",
            "Q7004736\n",
            "answer:  United States of America , similarity score with the expected answer: 0.28\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what was the country of origin of the tv show sidewalks entertainment\n",
            "P495\n",
            "show sidewalks\n",
            "Cosine similarity metric is used!\n",
            "Q7508530\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which notable person has Rome as place of death\n",
            "P20\n",
            "rome\n",
            "Q220\n",
            "Sorry, no answer available\n",
            "what is the category of the celestial object 1241 dysona\n",
            "P31\n",
            "1241 dysona\n",
            "Q137259\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a city in yolo county in california\n",
            "R131\n",
            "yolo county\n",
            "Q109709\n",
            "answer:  Coast Starlight , similarity score with the expected answer: 0.23\n",
            "answer:  Capitol Corridor , similarity score with the expected answer: 0.20\n",
            "answer:  California State Route 84 , similarity score with the expected answer: 0.16\n",
            "answer:  California State Route 16 , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 5 in California , similarity score with the expected answer: 0.15\n",
            "answer:  West Sacramento , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 505 , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 113 , similarity score with the expected answer: 0.14\n",
            "answer:  Davis , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 275 , similarity score with the expected answer: 0.13\n",
            "answer:  California State Route 128 , similarity score with the expected answer: 0.11\n",
            "answer:  Interstate 80 in California , similarity score with the expected answer: 0.10\n",
            "answer:  Woodland , similarity score with the expected answer: 0.10\n",
            "answer:  California State Route 45 , similarity score with the expected answer: 0.07\n",
            "answer:  U.S. Route 50 in California , similarity score with the expected answer: -0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which place was named after john radcliffe (english physician)\n",
            "R138\n",
            "john radcliffe\n",
            "Q922508\n",
            "answer:  John Radcliffe Hospital , similarity score with the expected answer: 1.00\n",
            "answer:  Radcliffe Infirmary , similarity score with the expected answer: 0.74\n",
            "answer:  Radcliffe Camera , similarity score with the expected answer: 0.58\n",
            "answer:  The Radcliffe Trust , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Square , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Science Library , similarity score with the expected answer: 0.52\n",
            "answer:  Radcliffe Quadrangle , similarity score with the expected answer: 0.49\n",
            "answer:  Radcliffe Observatory , similarity score with the expected answer: 0.48\n",
            "The question is answered correctly!\n",
            "What is Albert Einstein occupation?\n",
            "P106\n",
            "albert einstein\n",
            "Q937\n",
            "answer:  physicist , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which is the film's crying freeman country of origin?\n",
            "P495\n",
            "crying freeman\n",
            "Q1117884\n",
            "answer:  Japan , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "what kind of music is played on film life and death of an american fourtracker\n",
            "P86\n",
            "life and death of an\n",
            "Cosine similarity metric is used!\n",
            "Q1546792\n",
            "answer:  Allan Gray , similarity score with the expected answer: 0.23\n",
            "The question is not answered correctly!\n",
            "what's the name of an documentary film\n",
            "R136\n",
            "documentary film\n",
            "Q93204\n",
            "answer:  Visions of Light , similarity score with the expected answer: 1.00\n",
            "answer:  Special Effects: Anything Can Happen , similarity score with the expected answer: 0.36\n",
            "answer:  Fellini: A Director's Notebook , similarity score with the expected answer: 0.24\n",
            "answer:  The Clowns , similarity score with the expected answer: 0.23\n",
            "answer:  Isle of Flowers , similarity score with the expected answer: 0.20\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.19\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.19\n",
            "answer:  Kony 2012 , similarity score with the expected answer: 0.18\n",
            "answer:  Black Box BRD , similarity score with the expected answer: 0.17\n",
            "answer:  ¿¡Revolución!? , similarity score with the expected answer: 0.15\n",
            "answer:  Farewell to Enrico Berlinguer , similarity score with the expected answer: 0.12\n",
            "answer:  The Revolution Will Not Be Televised , similarity score with the expected answer: 0.12\n",
            "answer:  We Live in Public , similarity score with the expected answer: 0.11\n",
            "answer:  Frat Party at the Pankake Festival , similarity score with the expected answer: 0.11\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.07\n",
            "The question is answered correctly!\n",
            "exit\n",
            "40\n",
            "13\n",
            "60\n",
            "The percentage of the test questions that are answered correct is: 66.67%\n",
            "The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\n",
            "regardless if the expected answer is one of these correct answer(s) or not: 21.67%\n"
          ]
        }
      ],
      "source": [
        "#Question Answering engine\n",
        "activation_relation_best_parameters_path = 'drive/MyDrive/Relation_indexes_models_best_parameters/Answerable_Questions/ELU/relation_prediction_cosine_similarity_answerable_questions_ELU.pt'\n",
        "activation_entity_best_parameters_path =  \"drive/MyDrive/Entity_span_indexes_models_best_parameters/Answerable_Questions/Softplus/entity_span_prediction_cosine_similarity_answerable_questions_Softplus.pt\"\n",
        "print('This is the question answering engine. Type exit to quit')\n",
        "dropout_prob = 0.3\n",
        "count_test_questions_total = 0\n",
        "count_test_questions_correct_answered = 0\n",
        "count_test_questions_answered = 0\n",
        "while(1):\n",
        "  question = input()\n",
        "  if question == \"exit\":\n",
        "    break;\n",
        "  else:\n",
        "    count_test_questions_total += 1\n",
        "  #Find the real answer, relation id and entity id of the input question from the corresponding .txt file.\n",
        "  for i in range(len(testing_questions)):\n",
        "    if testing_questions[i] == question:\n",
        "      real_question_answer_label = testing_questions_answer_labels[i]\n",
        "      real_question_entity_id = testing_questions_entity_ids[i]\n",
        "      real_question_relation_id = testing_questions_relation_ids[i]\n",
        "      break\n",
        "  question_correct_answered, question_answered = answer(question, Endict, entities, rel_answerable_vocab, len(rel_answerable_vocab), tokenizer, quests, similarity_model, max(q_lengths), \"ELU\", \"Softplus\", activation_relation_best_parameters_path, activation_entity_best_parameters_path, dropout_prob, SEED, real_question_answer_label, real_question_entity_id, real_question_relation_id)\n",
        "  if question_correct_answered == 1:\n",
        "    count_test_questions_correct_answered += 1\n",
        "  if question_answered == 1:\n",
        "    count_test_questions_answered += 1\n",
        "print(count_test_questions_correct_answered)\n",
        "print(count_test_questions_answered)\n",
        "print(count_test_questions_total)\n",
        "print(\"The percentage of the test questions that are answered correct is: {:.2f}%\".format((count_test_questions_correct_answered/count_test_questions_total)*100))\n",
        "print(\"The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\\nregardless if the expected answer is one of these correct answer(s) or not: {:.2f}%\".format((count_test_questions_answered/count_test_questions_total)*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0771c1f-7bcc-42b5-dd44-1128ac5679a0",
        "id": "sYO_DJONwZJP"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the question answering engine. Type exit to quit\n",
            "Which home is an example of italianate architecture?\n",
            "R149\n",
            "italianate architecture\n",
            "Cosine similarity metric is used!\n",
            "Q615196\n",
            "answer:  Fairfield House , similarity score with the expected answer: 0.46\n",
            "answer:  Osborne House , similarity score with the expected answer: 0.41\n",
            "answer:  Hugh Glenn House , similarity score with the expected answer: 0.40\n",
            "answer:  Houses at 37–47 North Fifth Street , similarity score with the expected answer: 0.38\n",
            "answer:  Chatsworth House , similarity score with the expected answer: 0.37\n",
            "answer:  Royal Albert Hall , similarity score with the expected answer: 0.35\n",
            "answer:  Campbell-Rumsey House , similarity score with the expected answer: 0.34\n",
            "answer:  Casa Rosada , similarity score with the expected answer: 0.30\n",
            "answer:  Robinson-Schwenn Building , similarity score with the expected answer: 0.26\n",
            "answer:  Lower East Side Tenement Museum , similarity score with the expected answer: 0.21\n",
            "answer:  Criterion Hotel , similarity score with the expected answer: 0.20\n",
            "answer:  Palacio de los Leones , similarity score with the expected answer: 0.18\n",
            "answer:  Houghton County Courthouse , similarity score with the expected answer: 0.18\n",
            "answer:  Balch Hotel , similarity score with the expected answer: 0.16\n",
            "answer:  Tweed Courthouse , similarity score with the expected answer: 0.15\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what type of object is 25049 christofnorn\n",
            "P31\n",
            "25049 christofnorn\n",
            "Q1753907\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which person was born in liverpool?\n",
            "R19\n",
            "liverpool\n",
            "Q24826\n",
            "answer:  Ringo Starr , similarity score with the expected answer: 1.00\n",
            "answer:  Keith Newton , similarity score with the expected answer: 0.38\n",
            "answer:  Miles Jackson-Lipkin , similarity score with the expected answer: 0.38\n",
            "answer:  Toni Duggan , similarity score with the expected answer: 0.34\n",
            "answer:  Simon Rattle , similarity score with the expected answer: 0.32\n",
            "answer:  Kevin Nolan , similarity score with the expected answer: 0.31\n",
            "answer:  Adam F , similarity score with the expected answer: 0.30\n",
            "answer:  Richard Laurence Millington Synge , similarity score with the expected answer: 0.28\n",
            "answer:  David Johnson , similarity score with the expected answer: 0.28\n",
            "answer:  David Weatherall , similarity score with the expected answer: 0.28\n",
            "answer:  James Heneghan , similarity score with the expected answer: 0.26\n",
            "answer:  Adam Morgan , similarity score with the expected answer: 0.22\n",
            "answer:  William Ewart Gladstone , similarity score with the expected answer: 0.22\n",
            "answer:  Gertrud Luckner , similarity score with the expected answer: 0.20\n",
            "answer:  Zarqa Nawaz , similarity score with the expected answer: 0.14\n",
            "The question is answered correctly!\n",
            "What film genre is twilight considered to be?\n",
            "P136\n",
            "twilight\n",
            "Q44523\n",
            "answer:  romantic fiction , similarity score with the expected answer: 0.71\n",
            "answer:  young adult fiction , similarity score with the expected answer: 0.49\n",
            "answer:  vampire fiction , similarity score with the expected answer: 0.47\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which type of film is the bitter tea of general yen?\n",
            "P136\n",
            "the bitter tea of general yen\n",
            "Cosine similarity metric is used!\n",
            "Q568239\n",
            "answer:  drama film , similarity score with the expected answer: 1.00\n",
            "answer:  film based on literature , similarity score with the expected answer: 0.66\n",
            "answer:  romance film , similarity score with the expected answer: 0.65\n",
            "The question is answered correctly!\n",
            "What is the gender of Athina Maximou\n",
            "P21\n",
            "athina maximou\n",
            "Cosine similarity metric is used!\n",
            "Q757820\n",
            "answer:  male , similarity score with the expected answer: 0.73\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Name an Rolling Stones album\n",
            "R175\n",
            "rolling stones\n",
            "Q11036\n",
            "answer:  Metamorphosis , similarity score with the expected answer: 1.00\n",
            "answer:  Heart of Stone , similarity score with the expected answer: 0.29\n",
            "answer:  Flowers , similarity score with the expected answer: 0.25\n",
            "answer:  Through the Past, Darkly (Big Hits Vol. 2) , similarity score with the expected answer: 0.22\n",
            "answer:  The Last Time , similarity score with the expected answer: 0.15\n",
            "answer:  GRRR! , similarity score with the expected answer: 0.14\n",
            "answer:  More Hot Rocks , similarity score with the expected answer: 0.14\n",
            "answer:  (I Can't Get No) Satisfaction , similarity score with the expected answer: 0.13\n",
            "answer:  Jump Back: The Best of The Rolling Stones , similarity score with the expected answer: 0.13\n",
            "answer:  Live Licks , similarity score with the expected answer: 0.13\n",
            "answer:  Angie , similarity score with the expected answer: 0.12\n",
            "answer:  Rarities 1971–2003 , similarity score with the expected answer: 0.11\n",
            "answer:  Sucking in the Seventies , similarity score with the expected answer: 0.09\n",
            "answer:  No Security , similarity score with the expected answer: 0.06\n",
            "answer:  Fingerprint File , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "Who directed woody meets davy crewcut\n",
            "P57\n",
            "woody meets davy crewcut\n",
            "Q8033685\n",
            "answer:  Alex Lovy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "who was the first NSW female Minister of Education died from cancer\n",
            "R509\n",
            "of education\n",
            "Q7078749\n",
            "Sorry, no answer available\n",
            "What position does denis shcherbak play\n",
            "P413\n",
            "denis shcherbak\n",
            "Q4528782\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does the show un refugio para el amor originate from\n",
            "P495\n",
            "un refugio para el amor\n",
            "Cosine similarity metric is used!\n",
            "Q1068093\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what alternative rock band from Chicago is the author of of the blue colour of the sky\n",
            "P175\n",
            "chicago is the author of of the\n",
            "Cosine similarity metric is used!\n",
            "Q5095740\n",
            "Sorry, no answer available\n",
            "who is the artist that performed on the album sample and hold: attack decay sustain release?\n",
            "P175\n",
            "sample and\n",
            "Cosine similarity metric is used!\n",
            "Q7410135\n",
            "answer:  Simian Mobile Disco , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "where john brewster jr. was born\n",
            "P19\n",
            "where john brewster jr\n",
            "Cosine similarity metric is used!\n",
            "Q6223118\n",
            "answer:  Hampton , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a multiplayer game?\n",
            "R404\n",
            "a multiplayer game\n",
            "Cosine similarity metric is used!\n",
            "Q6895044\n",
            "answer:  Heroes of Might and Magic V: Tribes of the East , similarity score with the expected answer: 0.55\n",
            "answer:  Commandos 2: Men of Courage , similarity score with the expected answer: 0.49\n",
            "answer:  Heroes of Might and Magic V: Hammers of Fate , similarity score with the expected answer: 0.45\n",
            "answer:  Heroes of Might and Magic V , similarity score with the expected answer: 0.42\n",
            "answer:  Uncharted 2: Among Thieves , similarity score with the expected answer: 0.41\n",
            "answer:  Civilization III , similarity score with the expected answer: 0.40\n",
            "answer:  Civilization IV , similarity score with the expected answer: 0.37\n",
            "answer:  Uncharted 3: Drake's Deception , similarity score with the expected answer: 0.34\n",
            "answer:  Civilization V , similarity score with the expected answer: 0.32\n",
            "answer:  Super Mario Bros. , similarity score with the expected answer: 0.27\n",
            "answer:  Donkey Kong , similarity score with the expected answer: 0.27\n",
            "answer:  Freedom Force vs the 3rd Reich , similarity score with the expected answer: 0.22\n",
            "answer:  Grand Theft Auto V , similarity score with the expected answer: 0.17\n",
            "answer:  Need for Speed: Shift , similarity score with the expected answer: 0.11\n",
            "answer:  Football Manager , similarity score with the expected answer: 0.03\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which company produced hot enough for june\n",
            "P272\n",
            "hot enough for june\n",
            "Cosine similarity metric is used!\n",
            "Q12124859\n",
            "answer:  Rank Organisation , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "is jose figueroa alcorta from argentina or costa rica\n",
            "P27\n",
            "jose figueroa alcorta\n",
            "Q442729\n",
            "answer:  Argentina , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What kind of game is microsoft international soccer 2000\n",
            "P136\n",
            "microsoft international soccer 2000\n",
            "Q3312381\n",
            "answer:  association football video game , similarity score with the expected answer: 0.81\n",
            "The question is answered correctly!\n",
            "who is the composer of the song liar?\n",
            "P86\n",
            "liar\n",
            "Q6540228\n",
            "Sorry, no answer available\n",
            "Joshua Kimmich is member of which sports team?\n",
            "P641\n",
            "joshua kimmich\n",
            "Q13865408\n",
            "answer:  association football , similarity score with the expected answer: 0.50\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "What is the name of a folk rock singer (or group)?\n",
            "R136\n",
            "folk rock\n",
            "Q186472\n",
            "answer:  Neil Young , similarity score with the expected answer: 1.00\n",
            "answer:  Paul Simon , similarity score with the expected answer: 0.53\n",
            "answer:  Bob Dylan , similarity score with the expected answer: 0.48\n",
            "answer:  Alan Stivell , similarity score with the expected answer: 0.44\n",
            "answer:  Leonard Cohen , similarity score with the expected answer: 0.44\n",
            "answer:  Marcus Mumford , similarity score with the expected answer: 0.39\n",
            "answer:  Amy Macdonald , similarity score with the expected answer: 0.37\n",
            "answer:  George Harrison , similarity score with the expected answer: 0.36\n",
            "answer:  The Beatles , similarity score with the expected answer: 0.31\n",
            "answer:  Led Zeppelin , similarity score with the expected answer: 0.28\n",
            "answer:  Cher , similarity score with the expected answer: 0.22\n",
            "answer:  Tri Yann , similarity score with the expected answer: 0.22\n",
            "answer:  Denez Prigent , similarity score with the expected answer: 0.16\n",
            "answer:  Tsvety , similarity score with the expected answer: 0.10\n",
            "answer:  Iļģi , similarity score with the expected answer: 0.06\n",
            "The question is answered correctly!\n",
            "Who was born in dakar?\n",
            "R19\n",
            "dakar\n",
            "Q3718\n",
            "answer:  Mamadou Diabang , similarity score with the expected answer: 0.50\n",
            "answer:  Lamine Diack , similarity score with the expected answer: 0.41\n",
            "answer:  Bineta Diedhiou , similarity score with the expected answer: 0.40\n",
            "answer:  Abdoul Mbaye , similarity score with the expected answer: 0.38\n",
            "answer:  Patrick Vieira , similarity score with the expected answer: 0.38\n",
            "answer:  Pape Abdou Camara , similarity score with the expected answer: 0.37\n",
            "answer:  Mouhamadou Dabo , similarity score with the expected answer: 0.36\n",
            "answer:  Idrissa Gueye , similarity score with the expected answer: 0.35\n",
            "answer:  Pape Alioune Diouf , similarity score with the expected answer: 0.34\n",
            "answer:  José Brito , similarity score with the expected answer: 0.34\n",
            "answer:  Mansour Gueye , similarity score with the expected answer: 0.33\n",
            "answer:  Patrice Evra , similarity score with the expected answer: 0.33\n",
            "answer:  Mame Biram Diouf , similarity score with the expected answer: 0.32\n",
            "answer:  Boniface N'Dong , similarity score with the expected answer: 0.27\n",
            "answer:  Henri Saivet , similarity score with the expected answer: 0.25\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "where did edward i. edwards died\n",
            "P20\n",
            "edward i edwards\n",
            "Cosine similarity metric is used!\n",
            "Q436902\n",
            "answer:  Jersey City , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the sex of david swift?\n",
            "P21\n",
            "david swift\n",
            "Q5240208\n",
            "answer:  male , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What language is mission to caracas written in\n",
            "P364\n",
            "mission to caracas\n",
            "Cosine similarity metric is used!\n",
            "Q6878840\n",
            "answer:  French , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what genre is the album why is there air?\n",
            "P136\n",
            "why is there air\n",
            "Cosine similarity metric is used!\n",
            "Q7997809\n",
            "answer:  stand-up comedy , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is chad mustard's nationality\n",
            "P27\n",
            "chad mustard\n",
            "Q5066318\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is an instrument played by carl jackson\n",
            "P1303\n",
            "carl jackson\n",
            "Q5040368\n",
            "answer:  guitar , similarity score with the expected answer: 1.00\n",
            "answer:  mandolin , similarity score with the expected answer: 0.62\n",
            "answer:  banjo , similarity score with the expected answer: 0.57\n",
            "The question is answered correctly!\n",
            "Which is Aristotle Onassis profession?\n",
            "P106\n",
            "aristotle onassis\n",
            "Q180455\n",
            "answer:  ship-owner , similarity score with the expected answer: 1.00\n",
            "answer:  businessperson , similarity score with the expected answer: 0.45\n",
            "answer:  entrepreneur , similarity score with the expected answer: 0.33\n",
            "The question is answered correctly!\n",
            "what genre of music does bo diddley play?\n",
            "P136\n",
            "bo diddley\n",
            "Q10431795\n",
            "Sorry, no answer available\n",
            "Which genre of music was the album duck rock labeled?\n",
            "P136\n",
            "duck rock\n",
            "Q910692\n",
            "answer:  new wave , similarity score with the expected answer: 1.00\n",
            "answer:  rock music , similarity score with the expected answer: 0.27\n",
            "answer:  hip hop music , similarity score with the expected answer: 0.16\n",
            "The question is answered correctly!\n",
            "what is Michael Ballack's country of nationality\n",
            "P27\n",
            "michael ballack\n",
            "Q11948\n",
            "answer:  Germany , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what football position does dorin dickerson play at?\n",
            "P413\n",
            "dorin dickerson\n",
            "Q3037050\n",
            "answer:  wide receiver , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country is purple people eater filmed in?\n",
            "P495\n",
            "purple people eater\n",
            "Q3410974\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "idris phillips follows this major religion.\n",
            "P140\n",
            "idris phillips\n",
            "Q16192877\n",
            "answer:  Islam , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what instrument does ashwin sood play?\n",
            "P1303\n",
            "ashwin sood\n",
            "Q4806196\n",
            "answer:  drum kit , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Where was gunnar johansen born in Denmark?\n",
            "P19\n",
            "gunnar johansen\n",
            "Q445899\n",
            "answer:  Copenhagen , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the country of origin of the show tok! tok! tok! isang milyon pasok!\n",
            "P495\n",
            "##k tok\n",
            "Cosine similarity metric is used!\n",
            "Q7813436\n",
            "answer:  Philippines , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "What is the political ideology behind the german free-minded party?\n",
            "P1142\n",
            "free - minded party\n",
            "Cosine similarity metric is used!\n",
            "Q560777\n",
            "answer:  progressivism , similarity score with the expected answer: 1.00\n",
            "answer:  liberalism , similarity score with the expected answer: 0.42\n",
            "answer:  laicism , similarity score with the expected answer: 0.31\n",
            "The question is answered correctly!\n",
            "Name an territorial entity which is contained in England\n",
            "R17\n",
            "england\n",
            "Q21\n",
            "answer:  Cornish English , similarity score with the expected answer: 0.39\n",
            "answer:  Fawcett family , similarity score with the expected answer: 0.17\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what is a silent film from 1927\n",
            "R136\n",
            "silent film\n",
            "Q226730\n",
            "answer:  Modern Times , similarity score with the expected answer: 0.34\n",
            "answer:  King of the Circus , similarity score with the expected answer: 0.28\n",
            "answer:  The Broken Coin , similarity score with the expected answer: 0.28\n",
            "answer:  The Green Archer , similarity score with the expected answer: 0.26\n",
            "answer:  The Hawk's Trail , similarity score with the expected answer: 0.25\n",
            "answer:  The Pleasure Garden , similarity score with the expected answer: 0.24\n",
            "answer:  The Screaming Shadow , similarity score with the expected answer: 0.24\n",
            "answer:  Daredevil Jack , similarity score with the expected answer: 0.21\n",
            "answer:  Baseball and Bloomers , similarity score with the expected answer: 0.19\n",
            "answer:  Das wandernde Bild , similarity score with the expected answer: 0.19\n",
            "answer:  Eugene Onegin , similarity score with the expected answer: 0.19\n",
            "answer:  Symphonie diagonale , similarity score with the expected answer: 0.18\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.16\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.12\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.09\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "The power rangers dino thunder game was published by what American company?\n",
            "P123\n",
            "the power rangers dino thunder\n",
            "Cosine similarity metric is used!\n",
            "Q11888796\n",
            "answer:  THQ , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which was the country of citizehship of christopher robinson\n",
            "P27\n",
            "citizehship of christopher robinson\n",
            "Cosine similarity metric is used!\n",
            "Q370264\n",
            "answer:  Canada , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "Which position was David Beckham played\n",
            "P413\n",
            "david beckham\n",
            "Q10520\n",
            "answer:  midfielder , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is the second level division of the division crixas do tocantins\n",
            "P17\n",
            "crixas\n",
            "Q177030\n",
            "answer:  Brazil , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "Which film was directed by ian iqbal rashid\n",
            "R57\n",
            "ian iqbal rashid\n",
            "Q15461094\n",
            "answer:  Touch of Pink , similarity score with the expected answer: 1.00\n",
            "answer:  How She Move , similarity score with the expected answer: 0.23\n",
            "The question is answered correctly!\n",
            "Which genre of book is bin laden: the man who declared war on america?\n",
            "P136\n",
            "bin laden : the man who declared war\n",
            "Cosine similarity metric is used!\n",
            "Q4913778\n",
            "answer:  biography , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which country does dany saadia belong to\n",
            "P27\n",
            "dany saadia\n",
            "Q5221412\n",
            "answer:  Mexico , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is largemouth bass\n",
            "P136\n",
            "largemouth bass\n",
            "Q755105\n",
            "Sorry, no answer available\n",
            "does british music band crawler play blues-rock or classical\n",
            "P136\n",
            "crawler\n",
            "Q108882180\n",
            "Sorry, no answer available\n",
            "what river does the neville island bridge cross\n",
            "P17\n",
            "neville island bridge\n",
            "Q7004736\n",
            "answer:  United States of America , similarity score with the expected answer: 0.28\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "what was the country of origin of the tv show sidewalks entertainment\n",
            "P495\n",
            "show sidewalks entertainment\n",
            "Cosine similarity metric is used!\n",
            "Q7508530\n",
            "answer:  United States of America , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "Which notable person has Rome as place of death\n",
            "P20\n",
            "rome\n",
            "Q220\n",
            "Sorry, no answer available\n",
            "what is the category of the celestial object 1241 dysona\n",
            "P31\n",
            "1241 dysona\n",
            "Q137259\n",
            "answer:  asteroid , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "what is a city in yolo county in california\n",
            "R131\n",
            "yolo county\n",
            "Q109709\n",
            "answer:  Coast Starlight , similarity score with the expected answer: 0.23\n",
            "answer:  Capitol Corridor , similarity score with the expected answer: 0.20\n",
            "answer:  California State Route 84 , similarity score with the expected answer: 0.16\n",
            "answer:  California State Route 16 , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 5 in California , similarity score with the expected answer: 0.15\n",
            "answer:  West Sacramento , similarity score with the expected answer: 0.15\n",
            "answer:  Interstate 505 , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 113 , similarity score with the expected answer: 0.14\n",
            "answer:  Davis , similarity score with the expected answer: 0.14\n",
            "answer:  California State Route 275 , similarity score with the expected answer: 0.13\n",
            "answer:  California State Route 128 , similarity score with the expected answer: 0.11\n",
            "answer:  Interstate 80 in California , similarity score with the expected answer: 0.10\n",
            "answer:  Woodland , similarity score with the expected answer: 0.10\n",
            "answer:  California State Route 45 , similarity score with the expected answer: 0.07\n",
            "answer:  U.S. Route 50 in California , similarity score with the expected answer: -0.01\n",
            "The question is answered with either only correct answers or only incorrect answers or with both of them,\n",
            "which are different and either some or all of them have cosine similarity score with the expected answer significantly lower than 0.8,\n",
            "regardless if the expected answer is one of the possible correct answers or not!\n",
            "which place was named after john radcliffe (english physician)\n",
            "R138\n",
            "john radcliffe\n",
            "Q922508\n",
            "answer:  John Radcliffe Hospital , similarity score with the expected answer: 1.00\n",
            "answer:  Radcliffe Infirmary , similarity score with the expected answer: 0.74\n",
            "answer:  Radcliffe Camera , similarity score with the expected answer: 0.58\n",
            "answer:  The Radcliffe Trust , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Square , similarity score with the expected answer: 0.58\n",
            "answer:  Radcliffe Science Library , similarity score with the expected answer: 0.52\n",
            "answer:  Radcliffe Quadrangle , similarity score with the expected answer: 0.49\n",
            "answer:  Radcliffe Observatory , similarity score with the expected answer: 0.48\n",
            "The question is answered correctly!\n",
            "What is Albert Einstein occupation?\n",
            "P106\n",
            "albert einstein\n",
            "Q937\n",
            "answer:  physicist , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly!\n",
            "which is the film's crying freeman country of origin?\n",
            "P495\n",
            "crying freeman\n",
            "Q1117884\n",
            "answer:  Japan , similarity score with the expected answer: 1.00\n",
            "The question is answered correctly, although either entity id or relation id is not predicted correctly!\n",
            "what kind of music is played on film life and death of an american fourtracker\n",
            "P86\n",
            "life and death of\n",
            "Cosine similarity metric is used!\n",
            "Q6545292\n",
            "Sorry, no answer available\n",
            "what's the name of an documentary film\n",
            "R136\n",
            "documentary film\n",
            "Q93204\n",
            "answer:  Visions of Light , similarity score with the expected answer: 1.00\n",
            "answer:  Special Effects: Anything Can Happen , similarity score with the expected answer: 0.36\n",
            "answer:  Fellini: A Director's Notebook , similarity score with the expected answer: 0.24\n",
            "answer:  The Clowns , similarity score with the expected answer: 0.23\n",
            "answer:  Isle of Flowers , similarity score with the expected answer: 0.20\n",
            "answer:  Konungens af Siam landstigning vid Logårdstrappan , similarity score with the expected answer: 0.19\n",
            "answer:  Kørsel med Grønlandske Hunde , similarity score with the expected answer: 0.19\n",
            "answer:  Kony 2012 , similarity score with the expected answer: 0.18\n",
            "answer:  Black Box BRD , similarity score with the expected answer: 0.17\n",
            "answer:  ¿¡Revolución!? , similarity score with the expected answer: 0.15\n",
            "answer:  Farewell to Enrico Berlinguer , similarity score with the expected answer: 0.12\n",
            "answer:  The Revolution Will Not Be Televised , similarity score with the expected answer: 0.12\n",
            "answer:  We Live in Public , similarity score with the expected answer: 0.11\n",
            "answer:  Frat Party at the Pankake Festival , similarity score with the expected answer: 0.11\n",
            "answer:  Workers Leaving the Lumière Factory , similarity score with the expected answer: 0.07\n",
            "The question is answered correctly!\n",
            "exit\n",
            "41\n",
            "11\n",
            "60\n",
            "The percentage of the test questions that are answered correct is: 68.33%\n",
            "The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\n",
            "regardless if the expected answer is one of these correct answer(s) or not: 18.33%\n"
          ]
        }
      ],
      "source": [
        "#Question Answering engine\n",
        "activation_relation_best_parameters_path = 'drive/MyDrive/Relation_indexes_models_best_parameters/Answerable_Questions/ELU/relation_prediction_jaccard_similarity_answerable_questions_ELU.pt'\n",
        "activation_entity_best_parameters_path =  \"drive/MyDrive/Entity_span_indexes_models_best_parameters/Answerable_Questions/Softplus/entity_span_prediction_jaccard_similarity_answerable_questions_Softplus.pt\"\n",
        "print('This is the question answering engine. Type exit to quit')\n",
        "dropout_prob = 0.3\n",
        "count_test_questions_total = 0\n",
        "count_test_questions_correct_answered = 0\n",
        "count_test_questions_answered = 0\n",
        "while(1):\n",
        "  question = input()\n",
        "  if question == \"exit\":\n",
        "    break;\n",
        "  else:\n",
        "    count_test_questions_total += 1\n",
        "  #Find the real answer, relation id and entity id of the input question from the corresponding .txt file.\n",
        "  for i in range(len(testing_questions)):\n",
        "    if testing_questions[i] == question:\n",
        "      real_question_answer_label = testing_questions_answer_labels[i]\n",
        "      real_question_entity_id = testing_questions_entity_ids[i]\n",
        "      real_question_relation_id = testing_questions_relation_ids[i]\n",
        "      break\n",
        "  question_correct_answered, question_answered = answer(question, Endict, entities, rel_answerable_vocab, len(rel_answerable_vocab), tokenizer, quests, similarity_model, max(q_lengths), \"ELU\", \"Softplus\", activation_relation_best_parameters_path, activation_entity_best_parameters_path, dropout_prob, SEED, real_question_answer_label, real_question_entity_id, real_question_relation_id)\n",
        "  if question_correct_answered == 1:\n",
        "    count_test_questions_correct_answered += 1\n",
        "  if question_answered == 1:\n",
        "    count_test_questions_answered += 1\n",
        "print(count_test_questions_correct_answered)\n",
        "print(count_test_questions_answered)\n",
        "print(count_test_questions_total)\n",
        "print(\"The percentage of the test questions that are answered correct is: {:.2f}%\".format((count_test_questions_correct_answered/count_test_questions_total)*100))\n",
        "print(\"The percentage of the test questions that are answered either with either only correct or only incorrect answers or both of them,\\nregardless if the expected answer is one of these correct answer(s) or not: {:.2f}%\".format((count_test_questions_answered/count_test_questions_total)*100))"
      ]
    }
  ]
}
