{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**I import some useful libraries in python.**"
      ],
      "metadata": {
        "id": "ktn6WZIbBp5N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqFOGp2zILSz",
        "outputId": "f766de70-efde-4e78-8b0c-90a223936e3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import csv\n",
        "!pip install unidecode\n",
        "from unidecode import unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTsXzP8XpIsQ"
      },
      "source": [
        "**I mount google drive because all the files (for example .csv) that i used for the implementation of my thesis are saved on my google drive.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qShrK9odXOrW",
        "outputId": "71320156-6ece-490c-ceb4-d0a155c34568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-cXjwcA6rsv"
      },
      "source": [
        "**Reading the test dataset that includes answerable and non-answerable questions over wikidata and the corresponding test dataset that includes only answerable questions over wikidata that are in .txt file format and droping of the column of their answers ids.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "test_dataset = pd.read_csv('annotated_wd_data_test.txt', sep=\"\\t\", names=['entity_id','relation_id', 'answer', 'Question']) #read test dataset\n",
        "test_answerable_dataset = pd.read_csv('annotated_wd_data_test_answerable.txt', sep=\"\\t\", names=['entity_id','relation_id', 'answer', 'Question']) #read test dataset\n",
        "test_dataset = test_dataset.drop(labels='answer', axis=1) #drop answer\n",
        "test_answerable_dataset = test_answerable_dataset.drop(labels='answer', axis=1) #drop answer"
      ],
      "metadata": {
        "id": "2y3aSrC7OrFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I made some preprocessing for each question by creating the function preprocessing, which takes as argument the text (in this case the question) and performs accent removal, as well as punctuation mark removal (period, question mark, exclamation mark), s removal with apostrophe('s) and comma(,) removal.Finally this function, which is shown below, returns the original text with the above mentioned processing.**"
      ],
      "metadata": {
        "id": "BCFzPH1ltm3u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yGYRFAmXUyg"
      },
      "outputs": [],
      "source": [
        "def Preprocessing(text):\n",
        "    text = unidecode(text.replace(\"?\", \"\").replace(\"'s\", \"\").replace(\".\", \"\").replace(\"!\", \"\").replace(\",\", \"\"))\n",
        "    return text\n",
        "\n",
        "test_dataset['Question'] = test_dataset['Question'].apply(lambda x:Preprocessing(x))\n",
        "test_answerable_dataset['Question'] = test_answerable_dataset['Question'].apply(lambda x:Preprocessing(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The SPARQLWrapper library is downloaded, which contributes to the generation of SPARQL queries, in order to find the entity labels.**"
      ],
      "metadata": {
        "id": "KXmlWHObtyuO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WQm8KmD7hhY",
        "outputId": "2c67e547-bb4f-4ed8-b7e2-952c54639416"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sparqlwrapper\n",
            "  Downloading SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting rdflib>=6.1.1 (from sparqlwrapper)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib>=6.1.1->sparqlwrapper)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing<4,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from rdflib>=6.1.1->sparqlwrapper) (3.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->sparqlwrapper) (1.16.0)\n",
            "Installing collected packages: isodate, rdflib, sparqlwrapper\n",
            "Successfully installed isodate-0.6.1 rdflib-7.0.0 sparqlwrapper-2.0.0\n"
          ]
        }
      ],
      "source": [
        "#agent='WDQS-example Python'\n",
        "#Chicobot-Agent\n",
        "!pip install sparqlwrapper\n",
        "import sys\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON, CSV\n",
        "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent= \"WDQS-example Python/%s.%s\" % (sys.version_info[0], sys.version_info[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The function find\\_divisors which receives as an argument the length of either the SimpleQuestions training or the SimpleQuestions validation dataset and returns the divisors of this number, has as aim to find the divisors of the lengths of of the full SimpleQuestions test dataset, so that it is then possible to get the entity labels from SPARQL as quickly as possible.**"
      ],
      "metadata": {
        "id": "5qt4QghWVy6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_divisors(a):\n",
        "    divisors = []\n",
        "    for i in range(1, a + 1):\n",
        "        if a % i == 0:\n",
        "            divisors.append(i)\n",
        "    return divisors\n",
        "\n",
        "# Example usage\n",
        "number_to_check_1 = len(test_dataset)\n",
        "number_to_check_2 = len(test_answerable_dataset)\n",
        "result_1 = find_divisors(number_to_check_1)\n",
        "result_2 = find_divisors(number_to_check_2)\n",
        "print(f\"The divisors of {number_to_check_1} are: {result_1}\")\n",
        "print(f\"The divisors of {number_to_check_2} are: {result_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N8VQP47g5uq",
        "outputId": "2bd01e9c-587f-48eb-a718-67438cd5ed76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The divisors of 9961 are: [1, 7, 1423, 9961]\n",
            "The divisors of 5622 are: [1, 2, 3, 6, 937, 1874, 2811, 5622]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huVZKUTl7MSj"
      },
      "source": [
        "**The SPARQL Queries below found from wikidata the entity labels and the entity ids for each entity id (of course for each question) of the SimpleQuestions for both test dataset that includes answerable and non-answerable questions over wikidata and for the test dataset that includes only answerable questions over wikidata.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5yt-fziZO5j"
      },
      "outputs": [],
      "source": [
        "test_entity_names = []\n",
        "test_entity_ids = []\n",
        "for i in range(0,len(test_dataset),7):  #retrieve training set entities' corresponding ids\n",
        "  str = \"\"\n",
        "  for entity_id in test_dataset['entity_id'][i:i+7]:\n",
        "   str = str + \"wd:\" + entity_id + \" \"\n",
        "  sparql.setQuery(\"\"\"\n",
        "  SELECT ?item ?itemLabel\n",
        "  WHERE\n",
        "  {\n",
        "    VALUES ?item {\"\"\" + str + \"\"\"}\n",
        "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
        "  }\n",
        "\"\"\")\n",
        "  sparql.setReturnFormat(JSON)\n",
        "  results = sparql.query().convert()\n",
        "  test_results_df = pd.json_normalize(results['results']['bindings'])\n",
        "  for j in test_results_df['item.value']:\n",
        "      test_entity_ids.append(j)\n",
        "  for j in test_results_df['itemLabel.value']:\n",
        "      test_entity_names.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_answerable_entity_names = []\n",
        "test_answerable_entity_ids = []\n",
        "for i in range(0,len(test_answerable_dataset),3):  #retrieve training set entities' corresponding ids\n",
        "  str = \"\"\n",
        "  for entity_id in test_answerable_dataset['entity_id'][i:i+3]:\n",
        "   str = str + \"wd:\" + entity_id + \" \"\n",
        "  sparql.setQuery(\"\"\"\n",
        "  SELECT ?item ?itemLabel\n",
        "  WHERE\n",
        "  {\n",
        "    VALUES ?item {\"\"\" + str + \"\"\"}\n",
        "    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n",
        "  }\n",
        "\"\"\")\n",
        "  sparql.setReturnFormat(JSON)\n",
        "  results = sparql.query().convert()\n",
        "  test_answerable_results_df = pd.json_normalize(results['results']['bindings'])\n",
        "  for j in test_answerable_results_df['item.value']:\n",
        "      test_answerable_entity_ids.append(j)\n",
        "  for j in test_answerable_results_df['itemLabel.value']:\n",
        "      test_answerable_entity_names.append(j)"
      ],
      "metadata": {
        "id": "NHsRPajyu43f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P743BCFh69j-"
      },
      "source": [
        "**Creation of the corresponding lists containing the questions, the entity labels, the relation ids and the entity ids of the initial SimpleQuestions test dataset, either this dataset includes answerable and answerable questions over wikidata questions or only answerable questions over wikidata.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset_questions = test_dataset['Question'].to_list()\n",
        "test_dataset_entity_ids = test_dataset['entity_id'].to_list()\n",
        "test_dataset_answerable_questions = test_answerable_dataset['Question'].to_list()\n",
        "test_dataset_answerable_entity_ids = test_answerable_dataset['entity_id'].to_list()"
      ],
      "metadata": {
        "id": "Q0ABspHgQgtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C-4SI4k76p2"
      },
      "source": [
        "**The entity ids that are occurred from SPARQL are expressions that contain an encoded name, for example for the question of the SimpleQuestions (full) training dataset \"who is a musician born in detroit\", the entity id that occurred is https://www.wikidata.org/wiki/Q12439, which is related with Detroit (Q12439, if i search in wikidata).**\n",
        "\n",
        "**So the python function entity\\_ids is created with the aim to split the full expression with the entity id, such as the example above and to keep the encoded name, i.e named start from \"Q\" (\"Q12439\" in the above example).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WBxpijLGuTA",
        "outputId": "0193a0da-61d3-4661-8c57-86d8c1515d11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9969\n", 
            "5626\n", 
            "9961\n",
            "5622\n"
          ]
        }
      ],
      "source": [
        "#Split Spaqrl URI's in order to get the entity ids\n",
        "import os\n",
        "def enitity_ids(ids): #get ids from sparql query ids\n",
        " entity_ids = []\n",
        " for i in range(len(ids)):\n",
        "   entity_ids.append(ids[i].split(os.path.sep)[-1])\n",
        " return entity_ids\n",
        "test_ids = enitity_ids(test_entity_ids)\n",
        "test_answerable_ids = enitity_ids(test_answerable_entity_ids)\n",
        "print(len(test_ids))\n",
        "print(len(test_answerable_ids))\n",
        "print(len(test_dataset['entity_id']))\n",
        "print(len(test_answerable_dataset['entity_id']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUgrO7ad8HFT"
      },
      "source": [
        "**The function labels from which i confirm the entity id of each question, which occurred from SPARQL, through the entity id obtained for each question from the transfer of SimpleQuestions from Freebase to Wikidata. This function takes as arguments the list of questions, the list of the entity ids both from the corresponding SimpleQuestions dataset column and from the entity\\_ids function and the list of entity labels occured from SPARQL.**\n",
        "\n",
        "**Essentially i assigned to each question and entity id its corresponding entity label by searching in the list of test entity ids obtained from SPARQL. If any of these entity ids exist in the SimpleQuestions training and validation entity labels lists, that are created before and matching the entity label and thus a new column with entity labels for the training and the validation dataset.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator as op\n",
        "def labels(questions, entity_id_dataset, entity_ids, entity_names):# entity_ids and dataset must have the same length\n",
        "#In this step we find the entity ids from the initial dataset to the list occured from Sparql Query\n",
        "#for each of the train and validation dataset.\n",
        "#This will become the train or validation data new column, containing entities' labels\n",
        "\n",
        "  label_df_column = []\n",
        "  for entity_id in entity_id_dataset:\n",
        "   j=0\n",
        "   for ent in entity_ids: #find its id on list\n",
        "    if entity_id == ent:\n",
        "      label_df_column.append(entity_names[j]) #and find corresponding label\n",
        "      break\n",
        "    j += 1\n",
        "  return label_df_column\n",
        "\n",
        "\n",
        "test_dataset['entity_label'] = labels(test_dataset_questions, test_dataset_entity_ids, test_ids, test_entity_names)\n",
        "print(test_dataset['entity_label'], len(test_dataset['entity_label']))\n",
        "test_answerable_dataset['entity_label'] = labels(test_dataset_answerable_questions, test_dataset_answerable_entity_ids, test_answerable_ids, test_answerable_entity_names)\n",
        "print(test_answerable_dataset['entity_label'], len(test_answerable_dataset['entity_label']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuuV-rzY03gK",
        "outputId": "5c604846-27f9-4eb9-d3b6-1182f8a34294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0            Harder ... Faster\n",
            "1                  Alex Golfis\n",
            "2                     Phil Hay\n",
            "3                Roger Marquis\n",
            "4                   Yves Klein\n",
            "                 ...          \n",
            "9956            Doctor Faustus\n",
            "9957             Oklahoma City\n",
            "9958               2974 Holden\n",
            "9959    Snow Falling on Cedars\n",
            "9960           Lucille Clifton\n",
            "Name: entity_label, Length: 9961, dtype: object 9961\n",
            "0           Roger Marquis\n",
            "1              Yves Klein\n",
            "2            Carlos Gómez\n",
            "3       Engelbert Zaschka\n",
            "4           Pee Wee Reese\n",
            "              ...        \n",
            "5617            Barcelona\n",
            "5618             Jun Lana\n",
            "5619      Gunnar Johansen\n",
            "5620          2974 Holden\n",
            "5621      Lucille Clifton\n",
            "Name: entity_label, Length: 5622, dtype: object 5622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MX8blLbJ8RjM"
      },
      "source": [
        "**The preprocessing of the entity labels column occurred from labels function is made through function Preprocessing that is created previously. The reindexing of the columns (entity id, relation id, questions, entity label) of the initial SimpleQuestions dataset (either full or the dataset containing only questions that are answerable over wikidata),in order to include the entity labels as a new column in the initial SimpleQuestions dataset, is achieved by using the reindex() method from pandas.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset['entity_label'] = test_dataset['entity_label'].apply(lambda x:Preprocessing(x))\n",
        "new_columns = [\"entity_id\",\"entity_label\",\"relation_id\",\"Question\"]\n",
        "test_dataset = test_dataset.reindex(columns=new_columns)\n",
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IX826KQcRZZg",
        "outputId": "dd7e2045-ec84-4d2c-ee65-68a5d61f0305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      entity_id            entity_label relation_id  \\\n",
            "0      Q5487302          Harder  Faster        P136   \n",
            "1     Q16330302             Alex Golfis         P19   \n",
            "2     Q16225521                Phil Hay         R58   \n",
            "3      Q7358590           Roger Marquis         P20   \n",
            "4       Q154335              Yves Klein        P509   \n",
            "...         ...                     ...         ...   \n",
            "9956   Q1447249          Doctor Faustus        P170   \n",
            "9957     Q34863           Oklahoma City        R276   \n",
            "9958    Q582715             2974 Holden         P31   \n",
            "9959    Q582147  Snow Falling on Cedars        P136   \n",
            "9960    Q458750         Lucille Clifton         P27   \n",
            "\n",
            "                                               Question  \n",
            "0                  Which genre of album is harderfaster  \n",
            "1                     what city was alex golfis born in  \n",
            "2                   what film is by the writer phil hay  \n",
            "3                           Where did roger marquis die  \n",
            "4             what was the cause of death of yves klein  \n",
            "...                                                 ...  \n",
            "9956  who was the creator of the fictional character...  \n",
            "9957  what a college sporting event that took place ...  \n",
            "9958               what celestial object is 2974 holden  \n",
            "9959  what is the film genre for snow falling on cedars  \n",
            "9960                what nationality is lucille clifton  \n",
            "\n",
            "[9961 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_answerable_dataset['entity_label'] = test_answerable_dataset['entity_label'].apply(lambda x:Preprocessing(x))\n",
        "new_columns = [\"entity_id\",\"entity_label\",\"relation_id\",\"Question\"]\n",
        "test_answerable_dataset = test_answerable_dataset.reindex(columns=new_columns)\n",
        "print(test_answerable_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPEA7xeIvuYF",
        "outputId": "e9304aad-769c-49ea-97cc-3745ad322773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     entity_id       entity_label relation_id  \\\n",
            "0     Q7358590      Roger Marquis         P20   \n",
            "1      Q154335         Yves Klein        P509   \n",
            "2     Q2747238       Carlos Gomez        P413   \n",
            "3       Q62498  Engelbert Zaschka         P21   \n",
            "4      Q182485      Pee Wee Reese        P413   \n",
            "...        ...                ...         ...   \n",
            "5617     Q1492          Barcelona         R19   \n",
            "5618  Q2870425           Jun Lana       R1431   \n",
            "5619   Q445899    Gunnar Johansen         P19   \n",
            "5620   Q582715        2974 Holden         P31   \n",
            "5621   Q458750    Lucille Clifton         P27   \n",
            "\n",
            "                                               Question  \n",
            "0                           Where did roger marquis die  \n",
            "1             what was the cause of death of yves klein  \n",
            "2                  What position does carlos gomez play  \n",
            "3                  how does engelbert zaschka identify   \n",
            "4     what position does pee wee reese play in baseball  \n",
            "...                                                 ...  \n",
            "5617  Who is a notable figure that was born in barce...  \n",
            "5618          what films have been produced by jun lana  \n",
            "5619          Where was gunnar johansen born in Denmark  \n",
            "5620               what celestial object is 2974 holden  \n",
            "5621                what nationality is lucille clifton  \n",
            "\n",
            "[5622 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creation of the corresponding .csv files for the SimpleQuestions test dataset both for the case if this dataset includes answerable and non-answerable over wikidata questions and for the case if this dataset includes only answerable questions over wikidata respectively through pandas method to_csv().**"
      ],
      "metadata": {
        "id": "z1uoyqIIaHi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "test_csv_name = \"drive/MyDrive/test_dataset.csv\"\n",
        "test_dataset.to_csv(test_csv_name, index=False)\n",
        "test_answerable_csv_name = \"drive/MyDrive/test_answerable_dataset.csv\"\n",
        "test_answerable_dataset.to_csv(test_answerable_csv_name, index=False)\n",
        "print(test_dataset)\n",
        "print(test_answerable_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFV4EPvx0LCD",
        "outputId": "cc2b5306-5860-4bd5-919f-c85b3982b4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      entity_id            entity_label relation_id  \\\n",
            "0      Q5487302          Harder  Faster        P136   \n",
            "1     Q16330302             Alex Golfis         P19   \n",
            "2     Q16225521                Phil Hay         R58   \n",
            "3      Q7358590           Roger Marquis         P20   \n",
            "4       Q154335              Yves Klein        P509   \n",
            "...         ...                     ...         ...   \n",
            "9956   Q1447249          Doctor Faustus        P170   \n",
            "9957     Q34863           Oklahoma City        R276   \n",
            "9958    Q582715             2974 Holden         P31   \n",
            "9959    Q582147  Snow Falling on Cedars        P136   \n",
            "9960    Q458750         Lucille Clifton         P27   \n",
            "\n",
            "                                               Question  \n",
            "0                  Which genre of album is harderfaster  \n",
            "1                     what city was alex golfis born in  \n",
            "2                   what film is by the writer phil hay  \n",
            "3                           Where did roger marquis die  \n",
            "4             what was the cause of death of yves klein  \n",
            "...                                                 ...  \n",
            "9956  who was the creator of the fictional character...  \n",
            "9957  what a college sporting event that took place ...  \n",
            "9958               what celestial object is 2974 holden  \n",
            "9959  what is the film genre for snow falling on cedars  \n",
            "9960                what nationality is lucille clifton  \n",
            "\n",
            "[9961 rows x 4 columns]\n",
            "     entity_id       entity_label relation_id  \\\n",
            "0     Q7358590      Roger Marquis         P20   \n",
            "1      Q154335         Yves Klein        P509   \n",
            "2     Q2747238       Carlos Gomez        P413   \n",
            "3       Q62498  Engelbert Zaschka         P21   \n",
            "4      Q182485      Pee Wee Reese        P413   \n",
            "...        ...                ...         ...   \n",
            "5617     Q1492          Barcelona         R19   \n",
            "5618  Q2870425           Jun Lana       R1431   \n",
            "5619   Q445899    Gunnar Johansen         P19   \n",
            "5620   Q582715        2974 Holden         P31   \n",
            "5621   Q458750    Lucille Clifton         P27   \n",
            "\n",
            "                                               Question  \n",
            "0                           Where did roger marquis die  \n",
            "1             what was the cause of death of yves klein  \n",
            "2                  What position does carlos gomez play  \n",
            "3                  how does engelbert zaschka identify   \n",
            "4     what position does pee wee reese play in baseball  \n",
            "...                                                 ...  \n",
            "5617  Who is a notable figure that was born in barce...  \n",
            "5618          what films have been produced by jun lana  \n",
            "5619          Where was gunnar johansen born in Denmark  \n",
            "5620               what celestial object is 2974 holden  \n",
            "5621                what nationality is lucille clifton  \n",
            "\n",
            "[5622 rows x 4 columns]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
